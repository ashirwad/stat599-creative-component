<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ashirwad Barnwal" />

<meta name="date" content="2020-10-21" />

<title>Stroke trial modeling result</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">stat599-creative-component</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ashirwad/stat599-creative-component">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Stroke trial modeling result</h1>
<h4 class="author">Ashirwad Barnwal</h4>
<h4 class="date">10/21/2020</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2022-04-13
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong>
<code>stat599-creative-component/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.0). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20200920code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20200920)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20200920code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20200920)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongdetected">
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> <strong>Cache:</strong> detected </a>
</p>
</div>
<div id="strongCachestrongdetected" class="panel-collapse collapse">
<div class="panel-body">
The following chunks had caches available:
<ul>
<li>
base-rec
</li>
<li>
cntrl-grid
</li>
<li>
ist-fdead-asp-lhep-smry
</li>
<li>
ist-fdead-asp-lhep
</li>
<li>
ist-fdead-asp-mhep-smry
</li>
<li>
ist-fdead-asp-mhep
</li>
<li>
ist-fdead-asp-nhep-smry
</li>
<li>
ist-fdead-asp-nhep
</li>
<li>
ist-fdead-nasp-lhep-smry
</li>
<li>
ist-fdead-nasp-lhep
</li>
<li>
ist-fdead-nasp-mhep-smry
</li>
<li>
ist-fdead-nasp-mhep
</li>
<li>
ist-fdead-nasp-nhep-smry
</li>
<li>
ist-fdead-nasp-nhep
</li>
<li>
ist-fdead-smry
</li>
<li>
ist-fdead
</li>
<li>
ist-raw
</li>
<li>
ist-splits
</li>
<li>
ist
</li>
<li>
nnet-auc
</li>
<li>
nnet-final-res
</li>
<li>
nnet-final-spec
</li>
<li>
nnet-final-wflow
</li>
<li>
nnet-res
</li>
<li>
nnet-spec
</li>
<li>
nnet-wflow
</li>
<li>
norm-rec
</li>
<li>
rf-auc
</li>
<li>
rf-final-res
</li>
<li>
rf-final-spec
</li>
<li>
rf-final-wflow
</li>
<li>
rf-res
</li>
<li>
rf-spec
</li>
<li>
rf-wflow
</li>
<li>
roc-curves
</li>
<li>
session-info-chunk-inserted-by-workflowr
</li>
<li>
st-css
</li>
<li>
xgb-auc
</li>
<li>
xgb-final-res
</li>
<li>
xgb-final-spec
</li>
<li>
xgb-final-wflow
</li>
<li>
xgb-grid
</li>
<li>
xgb-res
</li>
<li>
xgb-spec
</li>
<li>
xgb-wflow
</li>
</ul>
<p>To ensure reproducibility of the results, delete the cache directory
<code>tlverse_cache</code> and re-run the analysis. To have workflowr
automatically delete the cache directory prior to building the file, set
<code>delete_cache = TRUE</code> when running <code>wflow_build()</code>
or <code>wflow_publish()</code>.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomashirwadstat599creativecomponenttree47276d8e099bea0604eda89d54365ce46f612f95targetblank47276d8a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/ashirwad/stat599-creative-component/tree/47276d8e099bea0604eda89d54365ce46f612f95" target="_blank">47276d8</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomashirwadstat599creativecomponenttree47276d8e099bea0604eda89d54365ce46f612f95targetblank47276d8a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/ashirwad/stat599-creative-component/tree/47276d8e099bea0604eda89d54365ce46f612f95" target="_blank">47276d8</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/tlverse_cache/
    Ignored:    renv/library/
    Ignored:    renv/python/
    Ignored:    renv/staging/

Untracked files:
    Untracked:  analysis/eda.Rmd
    Untracked:  analysis/img/
    Untracked:  data/IST_country_codes.csv
    Untracked:  extras/
    Untracked:  output/figures/
    Untracked:  output/ist_model_st.rds
    Untracked:  output/rds-files/
    Untracked:  output/tables/
    Untracked:  patient-level-prediction/
    Untracked:  slide/
    Untracked:  testing-ideas/

Unstaged changes:
    Modified:   .Rprofile
    Modified:   analysis/_site.yml
    Modified:   code/custom-funs.R
    Modified:   renv.lock
    Modified:   renv/activate.R

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/tlverse.Rmd</code>) and HTML
(<code>docs/tlverse.html</code>) files. If you’ve configured a remote
Git repository (see <code>?wflow_git_remote</code>), click on the
hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/47276d8e099bea0604eda89d54365ce46f612f95/analysis/tlverse.Rmd" target="_blank">47276d8</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-13
</td>
<td>
Move ploting fun for local prof to the script
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/94f0333bfe5a529ca43334f7464feb05c1a30b38/analysis/tlverse.Rmd" target="_blank">94f0333</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-13
</td>
<td>
Add section on residual diagnostics
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/c57fdcd0885e4fb9e047d903343378e4201b3095/analysis/tlverse.Rmd" target="_blank">c57fdcd</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-13
</td>
<td>
Compute shap attributions and plot them
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/3fe21d7420d85e80c993055ae5a0042ea2837299/analysis/tlverse.Rmd" target="_blank">3fe21d7</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Add global interpretation for age and rsbp
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/082fef1d6f04965973a4688a664bf738b45c3989/analysis/tlverse.Rmd" target="_blank">082fef1</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Export vip plot for slides
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/413a8de662aed4e091e9eedaaf875dbb384dc138/analysis/tlverse.Rmd" target="_blank">413a8de</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Create explainer for XGBoost
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/b53e7550e213409858c5a2cd5f588f77aef371f0/analysis/tlverse.Rmd" target="_blank">b53e755</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Add explainer for neural network
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/77a2c8f287a3635fbf2c92d9d2c1db4d00bcb65a/analysis/tlverse.Rmd" target="_blank">77a2c8f</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Convert ROC-AUC curve to plotly
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/aa4dadb9d4d609685937448f082359e7d9774c5e/analysis/tlverse.Rmd" target="_blank">aa4dadb</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Change outcome variable to dead or dependent
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/c44efa0a0968f577f755dd7ba4783d6e901083c9/analysis/tlverse.Rmd" target="_blank">c44efa0</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Use updated IST data for partitioning
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/94a15cb5239b947193fa18b5a18a9d5536c91448/analysis/tlverse.Rmd" target="_blank">94a15cb</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-12
</td>
<td>
Import cleaned IST data
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/20647e4f03b2e94a5dfe38e4439c4f878bfcf871/analysis/tlverse.Rmd" target="_blank">20647e4</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-03
</td>
<td>
Add section on local interpretation for rf
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/a0cfb711e6335b4259311aad97a24ac5f84d329d/analysis/tlverse.Rmd" target="_blank">a0cfb71</a>
</td>
<td>
ashirwad
</td>
<td>
2022-03-30
</td>
<td>
Add random forest explainer
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/37eeea7acb212d5da3e7766e2efe1be9f07f57ee/analysis/tlverse.Rmd" target="_blank">37eeea7</a>
</td>
<td>
ashirwad
</td>
<td>
2022-03-25
</td>
<td>
Add libraries for model explanation
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/0deb201014b4b2bff3123f1b4d25c85698964090/analysis/tlverse.Rmd" target="_blank">0deb201</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Fix outcome for roc-auc calculation
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/5e30e5deb51b2376e64ba676216250998edb6cb1/analysis/tlverse.Rmd" target="_blank">5e30e5d</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Don’t use stacking
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/e905ff10683748a6c19b739073a94f3da80c6c9c/analysis/tlverse.Rmd" target="_blank">e905ff1</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Cleanup setup chunk
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/c5365387dac48b83d59f1105db1b88a08f461464/analysis/tlverse.Rmd" target="_blank">c536538</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Remove descr stat for nested data (one per trt)
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/c5041723e137aefeeebfdcfe6a60eb979cdce5f8/analysis/tlverse.Rmd" target="_blank">c504172</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Remove helpers to handle nested data frames
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/e87128a02f9ee5fe4271b8558ed65649107d365d/analysis/tlverse.Rmd" target="_blank">e87128a</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-22
</td>
<td>
Remove sections on light gbm and catboost
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/d285fc0a0a0919c2304be8aa545e26a6cb88156f/analysis/tlverse.Rmd" target="_blank">d285fc0</a>
</td>
<td>
ashirwad
</td>
<td>
2021-12-21
</td>
<td>
Use dep/not-dep as outcome variable
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/5f21166f3cbfe9d6a0095f5201db5cf8a83119df/analysis/tlverse.Rmd" target="_blank">5f21166</a>
</td>
<td>
ashirwad
</td>
<td>
2021-06-17
</td>
<td>
Replace FDEAD with OCCODE as the response
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/4176a401fd5c5e594301e8c8850db7078bddee00/analysis/tlverse.Rmd" target="_blank">4176a40</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Fit and evaluate the final best catboost model
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/3d61adca0a6c7401c692eed1678a16928165ed60/analysis/tlverse.Rmd" target="_blank">3d61adc</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Create final catboost workflow
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/1d90315692a1a67231448cb0b0cef589520a9c4c/analysis/tlverse.Rmd" target="_blank">1d90315</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Finalize best catboost model
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/5b03ead41c7e6f12569fb57e0a6c75e33f0d9311/analysis/tlverse.Rmd" target="_blank">5b03ead</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Tune catboost model
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/b674829ae8b00711dd4aa4242ba20212b60ece2a/analysis/tlverse.Rmd" target="_blank">b674829</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Add catboost workflow
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/3158a7a7114301a471e3cd70edfe4fea5ceb6665/analysis/tlverse.Rmd" target="_blank">3158a7a</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Add catboost specification
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/99958fcabb20c742b0e4e95fc63a5b18a751fbf5/analysis/tlverse.Rmd" target="_blank">99958fc</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-07
</td>
<td>
Add light gbm workflow
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/ead40c19310505d921e8b9ad1f59215ccd364fd7/analysis/tlverse.Rmd" target="_blank">ead40c1</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-06
</td>
<td>
Tune light gbm model
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/d42342678249e383bb01617cadb5aea33c4d5c9a/analysis/tlverse.Rmd" target="_blank">d423426</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-06
</td>
<td>
Add light gbm specification
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/bbbc582efbda85f9381ea44ef80d825bd8707e0b/analysis/tlverse.Rmd" target="_blank">bbbc582</a>
</td>
<td>
ashirwad
</td>
<td>
2021-05-06
</td>
<td>
Add funs to fit models to each treatment group
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/b66621a3e72b963ed625413f9aac051c5fd6172c/analysis/tlverse.Rmd" target="_blank">b66621a</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-27
</td>
<td>
Generate roc curves
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/dadefb7c195ec6290006d2dc4d5620613703528a/analysis/tlverse.Rmd" target="_blank">dadefb7</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-27
</td>
<td>
Fit final best models
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/2c892f1eb68a2dc4ffee556acfa62a0816c63f64/analysis/tlverse.Rmd" target="_blank">2c892f1</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-26
</td>
<td>
Create final workflows
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/2ea684e4c59cf57a5467904043d9a45773663ae7/analysis/tlverse.Rmd" target="_blank">2ea684e</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-26
</td>
<td>
Identify best models
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/317cf0668243076c32b7d7d22d3bfabdb426030c/analysis/tlverse.Rmd" target="_blank">317cf06</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-26
</td>
<td>
Perform model tuning
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/3ad00b6771ce298c103cbbf12ba113b609ba2c15/analysis/tlverse.Rmd" target="_blank">3ad00b6</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-26
</td>
<td>
Add modeling workflows
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/e84140a32d664d4b838bd3697a70db8842ef180c/analysis/tlverse.Rmd" target="_blank">e84140a</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-25
</td>
<td>
Partition data and define base recipe
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/9713b8ae22955d2a5c21c99d48e06b45aed6d76f/analysis/tlverse.Rmd" target="_blank">9713b8a</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-25
</td>
<td>
Add model specifications
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/aff1c2f8ae64421d5e7637c9136f6893ffccbc55/analysis/tlverse.Rmd" target="_blank">aff1c2f</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-25
</td>
<td>
Prepare data for modeling
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/e4100eb21cc0f42278521a6bedb9586743bd862c/analysis/tlverse.Rmd" target="_blank">e4100eb</a>
</td>
<td>
ashirwad
</td>
<td>
2021-04-21
</td>
<td>
Switch to tidymodels
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/abcfbb73457cfe568a4c3269ea5da860b680b287/analysis/tlverse.Rmd" target="_blank">abcfbb7</a>
</td>
<td>
ashirwad
</td>
<td>
2020-10-22
</td>
<td>
Build prediction models
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/61297bf2b5bb18a2f4bf531bea78e0450f367beb/analysis/tlverse.Rmd" target="_blank">61297bf</a>
</td>
<td>
ashirwad
</td>
<td>
2020-10-21
</td>
<td>
Import data and add a recap of study design
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/ashirwad/stat599-creative-component/de58baf245eb0290d0eb03e202b6b01b9b15cba0/docs/tlverse.html" target="_blank">de58baf</a>
</td>
<td>
ashirwad
</td>
<td>
2020-10-21
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/6fb4da63fa789ac55e7b2425c0debff7c4b6e025/analysis/tlverse.Rmd" target="_blank">6fb4da6</a>
</td>
<td>
ashirwad
</td>
<td>
2020-10-21
</td>
<td>
Add setup chunk
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<pre class="r"><code>knitr::opts_chunk$set(cache = TRUE, autodep = TRUE)
source(here::here(&quot;code&quot;, &quot;custom-funs.R&quot;))</code></pre>
<div id="getting-setup" class="section level1">
<h1>Getting setup</h1>
<p>Define setup chunk:</p>
<pre class="r"><code># Elegant handling of namespace conflicts
library(conflicted)

# Miscellaneous
library(tictoc)
library(doFuture)
registerDoFuture()
plan(multisession)

# Path &amp; data manipulation
library(here)
library(tidyverse)
conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;)
library(rio)
conflict_prefer(&quot;export&quot;, &quot;rio&quot;)

# Pretty plots
library(ggpubr)
library(plotly)
conflict_prefer(&quot;layout&quot;, &quot;plotly&quot;)
library(patchwork)

# Model building &amp; evaluation
library(tidymodels)

# Model explanation
library(DALEX)
library(DALEXtra)

# Set options
options(datatable.na.strings = c(&quot;&quot;, &quot;NA&quot;)) # read these strings as NA</code></pre>
</div>
<div id="international-stroke-trial-ist-data" class="section level1">
<h1>International Stroke Trial (IST) data</h1>
<p>Import IST data:</p>
<pre class="r"><code>ist &lt;- import(here(&quot;output&quot;, &quot;rds-files&quot;, &quot;ist.rds&quot;))
glimpse(ist)</code></pre>
<pre><code>Rows: 18,304
Columns: 22
$ RDELAY      &lt;dbl&gt; 20, 28, 12, 17, 19, 20, 45, 24, 24, 45, 24, 29, 2, 6, 30, ~
$ RCONSC      &lt;fct&gt; F, F, F, F, F, D, F, F, F, F, F, D, F, F, F, D, F, F, F, F~
$ SEX         &lt;fct&gt; F, F, M, M, M, F, M, M, M, M, M, F, F, M, M, F, F, F, M, M~
$ AGE         &lt;dbl&gt; 64, 73, 74, 82, 54, 79, 80, 81, 62, 61, 71, 64, 90, 70, 57~
$ RSLEEP      &lt;fct&gt; N, Y, N, N, N, N, N, N, Y, N, N, N, N, Y, N, N, Y, N, N, N~
$ RATRIAL     &lt;fct&gt; Y, N, N, N, N, N, Y, Y, N, N, Y, N, N, N, N, N, Y, N, N, N~
$ RCT         &lt;fct&gt; Y, Y, Y, Y, Y, N, Y, Y, Y, Y, Y, Y, Y, N, Y, N, N, Y, N, Y~
$ RVISINF     &lt;fct&gt; N, N, Y, N, N, N, Y, N, N, Y, Y, Y, N, N, N, N, N, N, N, N~
$ RHEP24      &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ RASP3       &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, Y, Y, N, N, N, N~
$ RSBP        &lt;dbl&gt; 150, 120, 160, 170, 160, 175, 200, 200, 150, 180, 190, 130~
$ RDEF1       &lt;fct&gt; Y, Y, Y, N, Y, Y, Y, Y, N, Y, Y, Y, N, Y, N, Y, Y, Y, N, Y~
$ RDEF2       &lt;fct&gt; Y, Y, Y, N, N, Y, Y, Y, Y, N, Y, Y, N, Y, Y, Y, Y, Y, Y, Y~
$ RDEF3       &lt;fct&gt; Y, Y, N, N, N, Y, Y, Y, Y, N, N, Y, N, N, Y, Y, Y, Y, Y, Y~
$ RDEF4       &lt;fct&gt; N, N, Y, Y, N, Y, Y, Y, Y, N, N, N, Y, Y, N, C, Y, N, N, Y~
$ RDEF5       &lt;fct&gt; C, N, N, N, N, Y, N, N, C, Y, N, C, Y, N, N, Y, N, N, N, N~
$ RDEF6       &lt;fct&gt; Y, N, N, N, N, Y, N, N, C, N, N, C, N, N, N, C, N, N, N, N~
$ RDEF7       &lt;fct&gt; N, N, N, N, Y, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ RDEF8       &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ STYPE       &lt;fct&gt; TACS, LACS, PACS, PACS, POCS, TACS, PACS, PACS, TACS, PACS~
$ treatment   &lt;fct&gt; yes_asp_no_hep, no_asp_no_hep, no_asp_no_hep, yes_asp_med_~
$ dead_or_dep &lt;fct&gt; no, yes, yes, no, yes, yes, yes, yes, yes, no, no, yes, ye~</code></pre>
</div>
<div id="data-partitioning" class="section level1">
<h1>Data partitioning</h1>
<p>Create data partitions:</p>
<pre class="r"><code># For reproducible results
set.seed(123)

# Data partitions
ist_split &lt;- initial_split(sample_frac(ist, 0.1), strata = dead_or_dep)
ist_train &lt;- training(ist_split)
ist_test &lt;- testing(ist_split)

ist_folds &lt;- vfold_cv(ist_train, v = 5)</code></pre>
<div id="model-specification" class="section level2 tabset">
<h2 class="tabset">Model specification</h2>
<div id="random-forest" class="section level3">
<h3>Random forest</h3>
<p>Specify a random forest model:</p>
<pre class="r"><code>rf_spec &lt;- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()
) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;ranger&quot;)
rf_spec</code></pre>
<pre><code>Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = tune()

Computational engine: ranger </code></pre>
</div>
<div id="neural-network" class="section level3">
<h3>Neural network</h3>
<p>Specify a neural network model:</p>
<pre class="r"><code>nnet_spec &lt;- mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;nnet&quot;)
nnet_spec</code></pre>
<pre><code>Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = tune()
  penalty = tune()
  epochs = tune()

Computational engine: nnet </code></pre>
</div>
<div id="xgboost" class="section level3">
<h3>XGBoost</h3>
<p>Specify an XGBoost model:</p>
<pre class="r"><code>xgb_spec &lt;- boost_tree(
  mtry = tune(),
  trees = 1000,
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune()
) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;xgboost&quot;)
xgb_spec</code></pre>
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 1000
  min_n = tune()
  tree_depth = tune()
  learn_rate = tune()
  loss_reduction = tune()
  sample_size = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="feature-engineering" class="section level2 tabset">
<h2 class="tabset">Feature engineering</h2>
<p>Define recipes for feature engineering:</p>
<div id="dummy-coding" class="section level3">
<h3>Dummy coding</h3>
<p>Create dummy variables:</p>
<pre class="r"><code>base_rec &lt;- recipe(dead_or_dep ~ ., data = ist_train) %&gt;%
  step_dummy(all_nominal(), -all_outcomes())
base_rec</code></pre>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         21

Operations:

Dummy variables from all_nominal(), -all_outcomes()</code></pre>
</div>
<div id="normalization" class="section level3">
<h3>Normalization</h3>
<p>Center and scale numeric variables:</p>
<pre class="r"><code>norm_rec &lt;- base_rec %&gt;%
  step_normalize(all_predictors())
norm_rec</code></pre>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         21

Operations:

Dummy variables from all_nominal(), -all_outcomes()
Centering and scaling for all_predictors()</code></pre>
</div>
</div>
<div id="modeling-workflow" class="section level2 tabset">
<h2 class="tabset">Modeling workflow</h2>
<p>Specify modeling workflows:</p>
<div id="random-forest-1" class="section level3">
<h3>Random forest</h3>
<p>Specify a modeling workflow for random forest:</p>
<pre class="r"><code>rf_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(rf_spec)
rf_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: rand_forest()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = tune()

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-1" class="section level3">
<h3>Neural network</h3>
<p>Specify a modeling workflow for neural net:</p>
<pre class="r"><code>nnet_wflow &lt;- workflow() %&gt;%
  add_recipe(norm_rec) %&gt;%
  add_model(nnet_spec)
nnet_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: mlp()

-- Preprocessor ----------------------------------------------------------------
2 Recipe Steps

* step_dummy()
* step_normalize()

-- Model -----------------------------------------------------------------------
Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = tune()
  penalty = tune()
  epochs = tune()

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-1" class="section level3">
<h3>XGBoost</h3>
<p>Specify a modeling workflow for XGBoost:</p>
<pre class="r"><code>xgb_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(xgb_spec)
xgb_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: boost_tree()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 1000
  min_n = tune()
  tree_depth = tune()
  learn_rate = tune()
  loss_reduction = tune()
  sample_size = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="model-tuning" class="section level2 tabset">
<h2 class="tabset">Model tuning</h2>
<div id="random-forest-2" class="section level3">
<h3>Random forest</h3>
<p>Tune random forest model:</p>
<pre class="r"><code>tic()
set.seed(345)
rf_res &lt;- tune_grid(
  object = rf_wflow,
  resamples = ist_folds,
  grid = 10
)</code></pre>
<pre><code>i Creating pre-processing data to finalize unknown parameter: mtry</code></pre>
<pre class="r"><code>toc()</code></pre>
<pre><code>21.39 sec elapsed</code></pre>
<pre class="r"><code>rf_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics          .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
<div id="neural-network-2" class="section level3">
<h3>Neural network</h3>
<p>Tune neural net model:</p>
<pre class="r"><code>tic()
set.seed(123)
nnet_res &lt;- tune_grid(
  object = nnet_wflow,
  resamples = ist_folds,
  grid = 10
)
toc()</code></pre>
<pre><code>10.08 sec elapsed</code></pre>
<pre class="r"><code>nnet_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics          .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
<div id="xgboost-2" class="section level3">
<h3>XGBoost</h3>
<p>Construct parameter grid:</p>
<pre class="r"><code>xgb_grid &lt;- grid_latin_hypercube(
  min_n(),
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), ist_train),
  size = 30
)
xgb_grid</code></pre>
<pre><code># A tibble: 30 x 6
   min_n tree_depth learn_rate loss_reduction sample_size  mtry
   &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;
 1    32         12   1.28e- 4        2.76e-5       0.284    16
 2    22          6   9.25e- 7        5.08e-9       0.200     9
 3     9          5   1.57e-10        7.36e-5       0.948     5
 4    13         11   9.27e- 9        5.05e-2       0.392    11
 5    36         10   2.49e- 6        2.29e+0       0.465     1
 6    11          3   2.93e- 3        1.67e+1       0.107    21
 7    17          1   1.56e- 9        7.38e-7       0.353    19
 8     8          7   3.17e- 4        2.02e-5       0.707     4
 9    24         14   2.50e- 8        5.80e-6       0.524    20
10    22          7   7.74e- 6        1.06e+0       0.132    10
# ... with 20 more rows</code></pre>
<p>Tune XGBoost model:</p>
<pre class="r"><code>tic()
set.seed(123)
xgb_res &lt;- tune_grid(
  object = xgb_wflow,
  resamples = ist_folds,
  grid = xgb_grid
)
toc()</code></pre>
<pre><code>60.59 sec elapsed</code></pre>
<pre class="r"><code>xgb_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics           .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;             &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
</div>
<div id="best-models" class="section level2 tabset">
<h2 class="tabset">Best models</h2>
<p>Identify best models and create final model specifications:</p>
<div id="random-forest-3" class="section level3">
<h3>Random forest</h3>
<p>Best random forest model:</p>
<pre class="r"><code>rf_best_acc &lt;- select_best(rf_res, &quot;accuracy&quot;)
rf_final_spec &lt;- finalize_model(rf_spec, rf_best_acc)
rf_final_spec</code></pre>
<pre><code>Random Forest Model Specification (classification)

Main Arguments:
  mtry = 27
  trees = 500
  min_n = 16

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-3" class="section level3">
<h3>Neural network</h3>
<p>Best neural net model:</p>
<pre class="r"><code>nnet_best_acc &lt;- select_best(nnet_res, &quot;accuracy&quot;)
nnet_final_spec &lt;- finalize_model(nnet_spec, nnet_best_acc)
nnet_final_spec</code></pre>
<pre><code>Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = 2
  penalty = 0.000706529703098408
  epochs = 469

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-3" class="section level3">
<h3>XGBoost</h3>
<p>Best XGBoost model:</p>
<pre class="r"><code>xgb_best_acc &lt;- select_best(xgb_res, &quot;accuracy&quot;)
xgb_final_spec &lt;- finalize_model(xgb_spec, xgb_best_acc)
xgb_final_spec</code></pre>
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 4
  trees = 1000
  min_n = 5
  tree_depth = 2
  learn_rate = 0.0166306075804429
  loss_reduction = 0.0228850351507784
  sample_size = 0.26876543791499

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="final-workflows" class="section level2 tabset">
<h2 class="tabset">Final workflows</h2>
<p>Specify final workflows:</p>
<div id="random-forest-4" class="section level3">
<h3>Random forest</h3>
<p>Create a final workflow for fitting random forest:</p>
<pre class="r"><code>rf_final_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(rf_final_spec)
rf_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: rand_forest()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Random Forest Model Specification (classification)

Main Arguments:
  mtry = 27
  trees = 500
  min_n = 16

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-4" class="section level3">
<h3>Neural network</h3>
<p>Create a final workflow for fitting neural network:</p>
<pre class="r"><code>nnet_final_wflow &lt;- workflow() %&gt;%
  add_recipe(norm_rec) %&gt;%
  add_model(nnet_final_spec)
nnet_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: mlp()

-- Preprocessor ----------------------------------------------------------------
2 Recipe Steps

* step_dummy()
* step_normalize()

-- Model -----------------------------------------------------------------------
Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = 2
  penalty = 0.000706529703098408
  epochs = 469

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-4" class="section level3">
<h3>XGBoost</h3>
<p>Create a final workflow for fitting XGBoost:</p>
<pre class="r"><code>xgb_final_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(xgb_final_spec)
xgb_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: boost_tree()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 4
  trees = 1000
  min_n = 5
  tree_depth = 2
  learn_rate = 0.0166306075804429
  loss_reduction = 0.0228850351507784
  sample_size = 0.26876543791499

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="final-fits" class="section level2 tabset">
<h2 class="tabset">Final fits</h2>
<p>Fit final best models to the training set and evaluate the test
set:</p>
<div id="random-forest-5" class="section level3">
<h3>Random forest</h3>
<p>Fit the final best random forest model to the training set and
evaluate the test set:</p>
<pre class="r"><code>tic()
rf_final_res &lt;- rf_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>1.53 sec elapsed</code></pre>
<pre class="r"><code>rf_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.742 Preprocessor1_Model1
2 roc_auc  binary         0.775 Preprocessor1_Model1</code></pre>
</div>
<div id="neural-network-5" class="section level3">
<h3>Neural network</h3>
<p>Fit the final best neural network model to the training set and
evaluate the test set:</p>
<pre class="r"><code>tic()
nnet_final_res &lt;- nnet_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>1.06 sec elapsed</code></pre>
<pre class="r"><code>nnet_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.727 Preprocessor1_Model1
2 roc_auc  binary         0.739 Preprocessor1_Model1</code></pre>
</div>
<div id="xgboost-5" class="section level3">
<h3>XGBoost</h3>
<p>Fit the final best xgboost model to the training set and evaluate the
test set:</p>
<pre class="r"><code>tic()
xgb_final_res &lt;- xgb_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>1.53 sec elapsed</code></pre>
<pre class="r"><code>xgb_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.773 Preprocessor1_Model1
2 roc_auc  binary         0.803 Preprocessor1_Model1</code></pre>
</div>
</div>
<div id="roc-curve" class="section level2 tabset">
<h2 class="tabset">ROC curve</h2>
<div id="random-forest-6" class="section level3">
<h3>Random forest</h3>
<p>Compute the data needed to plot the ROC curve for random forest
model:</p>
<pre class="r"><code>rf_auc &lt;- rf_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;Random forest&quot;)
rf_auc</code></pre>
<pre><code># A tibble: 460 x 4
   .threshold specificity sensitivity model        
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        
 1  -Inf          0             1     Random forest
 2     0.0879     0             1     Random forest
 3     0.0892     0.00617       1     Random forest
 4     0.101      0.00617       0.997 Random forest
 5     0.141      0.0123        0.997 Random forest
 6     0.153      0.0185        0.997 Random forest
 7     0.156      0.0247        0.997 Random forest
 8     0.157      0.0309        0.997 Random forest
 9     0.157      0.0370        0.997 Random forest
10     0.162      0.0432        0.997 Random forest
# ... with 450 more rows</code></pre>
</div>
<div id="neural-network-6" class="section level3">
<h3>Neural network</h3>
<p>Compute the data needed to plot the ROC curve for neural network
model:</p>
<pre class="r"><code>nnet_auc &lt;- nnet_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;Neural network&quot;)
nnet_auc</code></pre>
<pre><code># A tibble: 155 x 4
   .threshold specificity sensitivity model         
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;         
 1   -Inf           0           1     Neural network
 2      0.358       0           1     Neural network
 3      0.358       0.352       0.916 Neural network
 4      0.358       0.352       0.912 Neural network
 5      0.358       0.358       0.912 Neural network
 6      0.358       0.358       0.909 Neural network
 7      0.358       0.364       0.909 Neural network
 8      0.358       0.364       0.905 Neural network
 9      0.358       0.370       0.905 Neural network
10      0.358       0.377       0.905 Neural network
# ... with 145 more rows</code></pre>
</div>
<div id="xgboost-6" class="section level3">
<h3>XGBoost</h3>
<p>Compute the data needed to plot the ROC curve for xgboost model:</p>
<pre class="r"><code>xgb_auc &lt;- xgb_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;XGBoost&quot;)
xgb_auc</code></pre>
<pre><code># A tibble: 460 x 4
   .threshold specificity sensitivity model  
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
 1   -Inf         0             1     XGBoost
 2      0.127     0             1     XGBoost
 3      0.157     0.00617       1     XGBoost
 4      0.162     0.00617       0.997 XGBoost
 5      0.169     0.0123        0.997 XGBoost
 6      0.175     0.0185        0.997 XGBoost
 7      0.184     0.0247        0.997 XGBoost
 8      0.184     0.0309        0.997 XGBoost
 9      0.185     0.0370        0.997 XGBoost
10      0.187     0.0432        0.997 XGBoost
# ... with 450 more rows</code></pre>
</div>
</div>
<div id="section" class="section level2 unnumbered">
<h2 class="unnumbered"></h2>
<p>Compare ROC curves:</p>
<pre class="r"><code>roc_curves &lt;- bind_rows(rf_auc, nnet_auc, xgb_auc) %&gt;%
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) + 
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_manual(values = colors_discrete_drwhy(3)) + 
  theme_pubclean()
roc_curves</code></pre>
<p><img src="figure/tlverse.Rmd/roc-curves-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>roc_curves2 &lt;- ggplotly(roc_curves) %&gt;%
  layout(legend = list(orientation = &quot;h&quot;, xanchor = &quot;center&quot;, x = 0.5, y = 1))
roc_curves2</code></pre>
<div id="htmlwidget-292ec1f153fa9e3f1d12" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-292ec1f153fa9e3f1d12">{"x":{"data":[{"x":[1,1,0.648148148148148,0.648148148148148,0.641975308641975,0.641975308641975,0.635802469135802,0.635802469135802,0.62962962962963,0.623456790123457,0.617283950617284,0.611111111111111,0.611111111111111,0.604938271604938,0.604938271604938,0.598765432098765,0.592592592592593,0.58641975308642,0.580246913580247,0.580246913580247,0.574074074074074,0.567901234567901,0.561728395061728,0.561728395061728,0.561728395061728,0.555555555555556,0.555555555555556,0.555555555555556,0.555555555555556,0.555555555555556,0.549382716049383,0.549382716049383,0.54320987654321,0.54320987654321,0.537037037037037,0.537037037037037,0.537037037037037,0.530864197530864,0.524691358024691,0.524691358024691,0.518518518518519,0.518518518518519,0.512345679012346,0.506172839506173,0.506172839506173,0.5,0.493827160493827,0.493827160493827,0.493827160493827,0.487654320987654,0.487654320987654,0.481481481481482,0.475308641975309,0.469135802469136,0.462962962962963,0.462962962962963,0.45679012345679,0.450617283950617,0.444444444444444,0.444444444444444,0.444444444444444,0.438271604938272,0.432098765432099,0.432098765432099,0.425925925925926,0.314814814814815,0.314814814814815,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.302469135802469,0.302469135802469,0.302469135802469,0.296296296296296,0.296296296296296,0.290123456790123,0.290123456790123,0.290123456790123,0.290123456790123,0.283950617283951,0.283950617283951,0.283950617283951,0.283950617283951,0.283950617283951,0.277777777777778,0.277777777777778,0.277777777777778,0.277777777777778,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.12962962962963,0.123456790123457,0.123456790123457,0.123456790123457,0.123456790123457,0.123456790123457,0.123456790123457,0.123456790123457,0.117283950617284,0.117283950617284,0.111111111111111,0.111111111111111,0.111111111111111,0.104938271604938,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0740740740740741,0.0740740740740741,0.0679012345679012,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0],"y":[1,1,0.915540540540541,0.912162162162162,0.912162162162162,0.908783783783784,0.908783783783784,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.902027027027027,0.902027027027027,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.89527027027027,0.89527027027027,0.89527027027027,0.89527027027027,0.891891891891892,0.888513513513513,0.888513513513513,0.885135135135135,0.881756756756757,0.878378378378378,0.875,0.875,0.871621621621622,0.871621621621622,0.868243243243243,0.868243243243243,0.864864864864865,0.861486486486487,0.861486486486487,0.861486486486487,0.858108108108108,0.858108108108108,0.85472972972973,0.85472972972973,0.85472972972973,0.851351351351351,0.851351351351351,0.851351351351351,0.847972972972973,0.844594594594595,0.844594594594595,0.841216216216216,0.841216216216216,0.841216216216216,0.841216216216216,0.841216216216216,0.837837837837838,0.837837837837838,0.837837837837838,0.837837837837838,0.834459459459459,0.831081081081081,0.831081081081081,0.831081081081081,0.827702702702703,0.827702702702703,0.689189189189189,0.685810810810811,0.685810810810811,0.682432432432432,0.679054054054054,0.675675675675676,0.672297297297297,0.668918918918919,0.665540540540541,0.662162162162162,0.658783783783784,0.655405405405405,0.652027027027027,0.648648648648649,0.64527027027027,0.641891891891892,0.638513513513513,0.635135135135135,0.631756756756757,0.631756756756757,0.628378378378378,0.625,0.625,0.621621621621622,0.621621621621622,0.618243243243243,0.614864864864865,0.611486486486487,0.611486486486487,0.608108108108108,0.60472972972973,0.601351351351351,0.597972972972973,0.597972972972973,0.594594594594595,0.591216216216216,0.587837837837838,0.398648648648649,0.39527027027027,0.391891891891892,0.388513513513513,0.388513513513513,0.385135135135135,0.381756756756757,0.378378378378378,0.375,0.371621621621622,0.368243243243243,0.364864864864865,0.361486486486487,0.358108108108108,0.35472972972973,0.35472972972973,0.35472972972973,0.351351351351351,0.347972972972973,0.344594594594595,0.341216216216216,0.337837837837838,0.334459459459459,0.334459459459459,0.331081081081081,0.331081081081081,0.327702702702703,0.324324324324324,0.324324324324324,0.324324324324324,0.320945945945946,0.317567567567568,0.317567567567568,0.314189189189189,0.310810810810811,0.307432432432432,0.304054054054054,0.304054054054054,0.300675675675676,0.297297297297297,0.293918918918919,0.293918918918919,0.290540540540541,0.287162162162162,0.287162162162162,0.283783783783784,0.283783783783784,0.280405405405405,0.280405405405405,0.277027027027027,0.273648648648649,0.27027027027027,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Neural network","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Neural network","1 - specificity: 0.64814815<br />sensitivity: 0.915540541<br />model: Neural network","1 - specificity: 0.64814815<br />sensitivity: 0.912162162<br />model: Neural network","1 - specificity: 0.64197531<br />sensitivity: 0.912162162<br />model: Neural network","1 - specificity: 0.64197531<br />sensitivity: 0.908783784<br />model: Neural network","1 - specificity: 0.63580247<br />sensitivity: 0.908783784<br />model: Neural network","1 - specificity: 0.63580247<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.62962963<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.62345679<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.61728395<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.61111111<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.61111111<br />sensitivity: 0.902027027<br />model: Neural network","1 - specificity: 0.60493827<br />sensitivity: 0.902027027<br />model: Neural network","1 - specificity: 0.60493827<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.59876543<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.59259259<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.58641975<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.58024691<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.58024691<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.57407407<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.56790123<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.56172840<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.56172840<br />sensitivity: 0.891891892<br />model: Neural network","1 - specificity: 0.56172840<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.885135135<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.881756757<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.878378378<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.875000000<br />model: Neural network","1 - specificity: 0.54938272<br />sensitivity: 0.875000000<br />model: Neural network","1 - specificity: 0.54938272<br />sensitivity: 0.871621622<br />model: Neural network","1 - specificity: 0.54320988<br />sensitivity: 0.871621622<br />model: Neural network","1 - specificity: 0.54320988<br />sensitivity: 0.868243243<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.868243243<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.864864865<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.861486486<br />model: Neural network","1 - specificity: 0.53086420<br />sensitivity: 0.861486486<br />model: Neural network","1 - specificity: 0.52469136<br />sensitivity: 0.861486486<br />model: Neural network","1 - specificity: 0.52469136<br />sensitivity: 0.858108108<br />model: Neural network","1 - specificity: 0.51851852<br />sensitivity: 0.858108108<br />model: Neural network","1 - specificity: 0.51851852<br />sensitivity: 0.854729730<br />model: Neural network","1 - specificity: 0.51234568<br />sensitivity: 0.854729730<br />model: Neural network","1 - specificity: 0.50617284<br />sensitivity: 0.854729730<br />model: Neural network","1 - specificity: 0.50617284<br />sensitivity: 0.851351351<br />model: Neural network","1 - specificity: 0.50000000<br />sensitivity: 0.851351351<br />model: Neural network","1 - specificity: 0.49382716<br />sensitivity: 0.851351351<br />model: Neural network","1 - specificity: 0.49382716<br />sensitivity: 0.847972973<br />model: Neural network","1 - specificity: 0.49382716<br />sensitivity: 0.844594595<br />model: Neural network","1 - specificity: 0.48765432<br />sensitivity: 0.844594595<br />model: Neural network","1 - specificity: 0.48765432<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.48148148<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.47530864<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.46913580<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.46296296<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.46296296<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.45679012<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.45061728<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.44444444<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.44444444<br />sensitivity: 0.834459459<br />model: Neural network","1 - specificity: 0.44444444<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.43827160<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.43209877<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.43209877<br />sensitivity: 0.827702703<br />model: Neural network","1 - specificity: 0.42592593<br />sensitivity: 0.827702703<br />model: Neural network","1 - specificity: 0.31481481<br />sensitivity: 0.689189189<br />model: Neural network","1 - specificity: 0.31481481<br />sensitivity: 0.685810811<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.685810811<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.682432432<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.679054054<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.675675676<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.672297297<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.668918919<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.665540541<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.662162162<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.658783784<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.655405405<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.652027027<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.648648649<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.645270270<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.641891892<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.638513514<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.635135135<br />model: Neural network","1 - specificity: 0.30864198<br />sensitivity: 0.631756757<br />model: Neural network","1 - specificity: 0.30246914<br />sensitivity: 0.631756757<br />model: Neural network","1 - specificity: 0.30246914<br />sensitivity: 0.628378378<br />model: Neural network","1 - specificity: 0.30246914<br />sensitivity: 0.625000000<br />model: Neural network","1 - specificity: 0.29629630<br />sensitivity: 0.625000000<br />model: Neural network","1 - specificity: 0.29629630<br />sensitivity: 0.621621622<br />model: Neural network","1 - specificity: 0.29012346<br />sensitivity: 0.621621622<br />model: Neural network","1 - specificity: 0.29012346<br />sensitivity: 0.618243243<br />model: Neural network","1 - specificity: 0.29012346<br />sensitivity: 0.614864865<br />model: Neural network","1 - specificity: 0.29012346<br />sensitivity: 0.611486486<br />model: Neural network","1 - specificity: 0.28395062<br />sensitivity: 0.611486486<br />model: Neural network","1 - specificity: 0.28395062<br />sensitivity: 0.608108108<br />model: Neural network","1 - specificity: 0.28395062<br />sensitivity: 0.604729730<br />model: Neural network","1 - specificity: 0.28395062<br />sensitivity: 0.601351351<br />model: Neural network","1 - specificity: 0.28395062<br />sensitivity: 0.597972973<br />model: Neural network","1 - specificity: 0.27777778<br />sensitivity: 0.597972973<br />model: Neural network","1 - specificity: 0.27777778<br />sensitivity: 0.594594595<br />model: Neural network","1 - specificity: 0.27777778<br />sensitivity: 0.591216216<br />model: Neural network","1 - specificity: 0.27777778<br />sensitivity: 0.587837838<br />model: Neural network","1 - specificity: 0.14197531<br />sensitivity: 0.398648649<br />model: Neural network","1 - specificity: 0.14197531<br />sensitivity: 0.395270270<br />model: Neural network","1 - specificity: 0.14197531<br />sensitivity: 0.391891892<br />model: Neural network","1 - specificity: 0.14197531<br />sensitivity: 0.388513514<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.388513514<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.385135135<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.381756757<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.378378378<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.375000000<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.371621622<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.368243243<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.364864865<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.361486486<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.358108108<br />model: Neural network","1 - specificity: 0.13580247<br />sensitivity: 0.354729730<br />model: Neural network","1 - specificity: 0.12962963<br />sensitivity: 0.354729730<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.354729730<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.351351351<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.347972973<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.344594595<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.341216216<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.337837838<br />model: Neural network","1 - specificity: 0.12345679<br />sensitivity: 0.334459459<br />model: Neural network","1 - specificity: 0.11728395<br />sensitivity: 0.334459459<br />model: Neural network","1 - specificity: 0.11728395<br />sensitivity: 0.331081081<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.331081081<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.327702703<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.324324324<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.324324324<br />model: Neural network","1 - specificity: 0.09876543<br />sensitivity: 0.324324324<br />model: Neural network","1 - specificity: 0.09876543<br />sensitivity: 0.320945946<br />model: Neural network","1 - specificity: 0.09876543<br />sensitivity: 0.317567568<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.317567568<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.314189189<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.310810811<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.307432432<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.304054054<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.304054054<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.300675676<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.297297297<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.293918919<br />model: Neural network","1 - specificity: 0.08024691<br />sensitivity: 0.293918919<br />model: Neural network","1 - specificity: 0.08024691<br />sensitivity: 0.290540541<br />model: Neural network","1 - specificity: 0.08024691<br />sensitivity: 0.287162162<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.287162162<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.283783784<br />model: Neural network","1 - specificity: 0.06790123<br />sensitivity: 0.283783784<br />model: Neural network","1 - specificity: 0.06790123<br />sensitivity: 0.280405405<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.280405405<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.277027027<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.273648649<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.270270270<br />model: Neural network","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: Neural network"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"Neural network","legendgroup":"Neural network","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,1,0.993827160493827,0.993827160493827,0.987654320987654,0.981481481481482,0.975308641975309,0.969135802469136,0.962962962962963,0.95679012345679,0.950617283950617,0.944444444444444,0.938271604938272,0.938271604938272,0.932098765432099,0.925925925925926,0.919753086419753,0.91358024691358,0.907407407407407,0.907407407407407,0.901234567901235,0.895061728395062,0.888888888888889,0.882716049382716,0.876543209876543,0.87037037037037,0.864197530864198,0.858024691358025,0.851851851851852,0.845679012345679,0.845679012345679,0.845679012345679,0.839506172839506,0.833333333333333,0.827160493827161,0.820987654320988,0.814814814814815,0.808641975308642,0.802469135802469,0.802469135802469,0.796296296296296,0.796296296296296,0.790123456790123,0.783950617283951,0.777777777777778,0.771604938271605,0.765432098765432,0.765432098765432,0.759259259259259,0.759259259259259,0.759259259259259,0.759259259259259,0.753086419753086,0.753086419753086,0.746913580246914,0.740740740740741,0.734567901234568,0.734567901234568,0.728395061728395,0.722222222222222,0.722222222222222,0.722222222222222,0.722222222222222,0.716049382716049,0.709876543209877,0.703703703703704,0.697530864197531,0.691358024691358,0.685185185185185,0.679012345679012,0.679012345679012,0.679012345679012,0.672839506172839,0.666666666666667,0.660493827160494,0.660493827160494,0.660493827160494,0.654320987654321,0.648148148148148,0.648148148148148,0.641975308641975,0.635802469135802,0.635802469135802,0.62962962962963,0.623456790123457,0.617283950617284,0.617283950617284,0.611111111111111,0.604938271604938,0.604938271604938,0.604938271604938,0.604938271604938,0.604938271604938,0.598765432098765,0.598765432098765,0.598765432098765,0.598765432098765,0.592592592592593,0.58641975308642,0.580246913580247,0.574074074074074,0.567901234567901,0.561728395061728,0.555555555555556,0.555555555555556,0.549382716049383,0.549382716049383,0.54320987654321,0.54320987654321,0.537037037037037,0.530864197530864,0.524691358024691,0.518518518518519,0.512345679012346,0.512345679012346,0.506172839506173,0.5,0.5,0.5,0.493827160493827,0.487654320987654,0.487654320987654,0.487654320987654,0.487654320987654,0.487654320987654,0.487654320987654,0.487654320987654,0.481481481481482,0.481481481481482,0.481481481481482,0.475308641975309,0.475308641975309,0.469135802469136,0.462962962962963,0.462962962962963,0.45679012345679,0.450617283950617,0.444444444444444,0.438271604938272,0.432098765432099,0.425925925925926,0.425925925925926,0.419753086419753,0.419753086419753,0.41358024691358,0.41358024691358,0.41358024691358,0.41358024691358,0.41358024691358,0.407407407407407,0.407407407407407,0.401234567901235,0.401234567901235,0.395061728395062,0.395061728395062,0.395061728395062,0.388888888888889,0.388888888888889,0.388888888888889,0.388888888888889,0.388888888888889,0.382716049382716,0.376543209876543,0.37037037037037,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.358024691358025,0.358024691358025,0.358024691358025,0.358024691358025,0.358024691358025,0.358024691358025,0.358024691358025,0.351851851851852,0.351851851851852,0.345679012345679,0.345679012345679,0.345679012345679,0.339506172839506,0.339506172839506,0.333333333333333,0.333333333333333,0.333333333333333,0.333333333333333,0.333333333333333,0.327160493827161,0.320987654320988,0.320987654320988,0.320987654320988,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.314814814814815,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.308641975308642,0.302469135802469,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.290123456790123,0.290123456790123,0.283950617283951,0.277777777777778,0.277777777777778,0.277777777777778,0.271604938271605,0.271604938271605,0.271604938271605,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.259259259259259,0.253086419753086,0.253086419753086,0.246913580246914,0.246913580246914,0.240740740740741,0.234567901234568,0.234567901234568,0.234567901234568,0.234567901234568,0.228395061728395,0.228395061728395,0.222222222222222,0.216049382716049,0.216049382716049,0.209876543209877,0.209876543209877,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.197530864197531,0.197530864197531,0.197530864197531,0.197530864197531,0.191358024691358,0.191358024691358,0.191358024691358,0.185185185185185,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.172839506172839,0.172839506172839,0.172839506172839,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.160493827160494,0.160493827160494,0.160493827160494,0.160493827160494,0.160493827160494,0.160493827160494,0.160493827160494,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.148148148148148,0.148148148148148,0.141975308641975,0.141975308641975,0.135802469135803,0.12962962962963,0.123456790123457,0.123456790123457,0.117283950617284,0.117283950617284,0.111111111111111,0.104938271604938,0.104938271604938,0.104938271604938,0.0987654320987654,0.0987654320987654,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0740740740740741,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0432098765432098,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0,0,0,0,0,0],"y":[1,1,1,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.986486486486487,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.97972972972973,0.97972972972973,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.972972972972973,0.972972972972973,0.969594594594595,0.966216216216216,0.962837837837838,0.962837837837838,0.959459459459459,0.959459459459459,0.959459459459459,0.959459459459459,0.956081081081081,0.956081081081081,0.956081081081081,0.952702702702703,0.949324324324324,0.945945945945946,0.945945945945946,0.945945945945946,0.945945945945946,0.945945945945946,0.945945945945946,0.945945945945946,0.945945945945946,0.942567567567568,0.939189189189189,0.939189189189189,0.939189189189189,0.939189189189189,0.935810810810811,0.932432432432432,0.932432432432432,0.932432432432432,0.929054054054054,0.929054054054054,0.929054054054054,0.925675675675676,0.925675675675676,0.925675675675676,0.925675675675676,0.922297297297297,0.922297297297297,0.922297297297297,0.918918918918919,0.915540540540541,0.912162162162162,0.908783783783784,0.908783783783784,0.905405405405405,0.902027027027027,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.898648648648649,0.89527027027027,0.89527027027027,0.891891891891892,0.891891891891892,0.888513513513513,0.888513513513513,0.888513513513513,0.888513513513513,0.888513513513513,0.888513513513513,0.885135135135135,0.885135135135135,0.885135135135135,0.881756756756757,0.878378378378378,0.878378378378378,0.878378378378378,0.875,0.871621621621622,0.868243243243243,0.864864864864865,0.861486486486487,0.858108108108108,0.858108108108108,0.85472972972973,0.851351351351351,0.851351351351351,0.847972972972973,0.847972972972973,0.847972972972973,0.844594594594595,0.844594594594595,0.844594594594595,0.844594594594595,0.844594594594595,0.844594594594595,0.844594594594595,0.841216216216216,0.841216216216216,0.837837837837838,0.837837837837838,0.834459459459459,0.831081081081081,0.827702702702703,0.824324324324324,0.824324324324324,0.820945945945946,0.820945945945946,0.817567567567568,0.817567567567568,0.814189189189189,0.810810810810811,0.810810810810811,0.807432432432432,0.804054054054054,0.800675675675676,0.797297297297297,0.797297297297297,0.797297297297297,0.797297297297297,0.797297297297297,0.793918918918919,0.790540540540541,0.787162162162162,0.787162162162162,0.783783783783784,0.780405405405405,0.777027027027027,0.773648648648649,0.77027027027027,0.766891891891892,0.766891891891892,0.763513513513513,0.763513513513513,0.760135135135135,0.756756756756757,0.756756756756757,0.753378378378378,0.753378378378378,0.75,0.746621621621622,0.743243243243243,0.739864864864865,0.739864864864865,0.739864864864865,0.736486486486487,0.733108108108108,0.733108108108108,0.72972972972973,0.726351351351351,0.722972972972973,0.719594594594595,0.716216216216216,0.712837837837838,0.709459459459459,0.706081081081081,0.706081081081081,0.702702702702703,0.699324324324324,0.695945945945946,0.692567567567568,0.692567567567568,0.692567567567568,0.689189189189189,0.685810810810811,0.682432432432432,0.679054054054054,0.675675675675676,0.672297297297297,0.668918918918919,0.665540540540541,0.665540540540541,0.662162162162162,0.662162162162162,0.662162162162162,0.658783783783784,0.655405405405405,0.655405405405405,0.652027027027027,0.648648648648649,0.648648648648649,0.64527027027027,0.641891891891892,0.638513513513513,0.635135135135135,0.635135135135135,0.635135135135135,0.631756756756757,0.631756756756757,0.628378378378378,0.628378378378378,0.628378378378378,0.625,0.621621621621622,0.618243243243243,0.618243243243243,0.614864864864865,0.614864864864865,0.614864864864865,0.611486486486487,0.611486486486487,0.608108108108108,0.608108108108108,0.60472972972973,0.601351351351351,0.597972972972973,0.597972972972973,0.594594594594595,0.591216216216216,0.587837837837838,0.587837837837838,0.584459459459459,0.581081081081081,0.581081081081081,0.581081081081081,0.577702702702703,0.574324324324324,0.570945945945946,0.567567567567568,0.564189189189189,0.560810810810811,0.557432432432432,0.554054054054054,0.550675675675676,0.550675675675676,0.547297297297297,0.543918918918919,0.543918918918919,0.540540540540541,0.537162162162162,0.533783783783784,0.530405405405405,0.527027027027027,0.523648648648649,0.52027027027027,0.516891891891892,0.513513513513513,0.510135135135135,0.506756756756757,0.503378378378378,0.5,0.496621621621622,0.496621621621622,0.493243243243243,0.489864864864865,0.486486486486487,0.483108108108108,0.47972972972973,0.476351351351351,0.476351351351351,0.472972972972973,0.469594594594595,0.466216216216216,0.462837837837838,0.459459459459459,0.456081081081081,0.452702702702703,0.449324324324324,0.445945945945946,0.442567567567568,0.442567567567568,0.439189189189189,0.439189189189189,0.435810810810811,0.435810810810811,0.435810810810811,0.435810810810811,0.432432432432432,0.432432432432432,0.429054054054054,0.429054054054054,0.429054054054054,0.425675675675676,0.422297297297297,0.422297297297297,0.418918918918919,0.418918918918919,0.415540540540541,0.412162162162162,0.408783783783784,0.408783783783784,0.405405405405405,0.402027027027027,0.398648648648649,0.39527027027027,0.391891891891892,0.388513513513513,0.385135135135135,0.381756756756757,0.378378378378378,0.375,0.371621621621622,0.368243243243243,0.364864864864865,0.361486486486487,0.358108108108108,0.35472972972973,0.351351351351351,0.347972972972973,0.347972972972973,0.344594594594595,0.341216216216216,0.337837837837838,0.334459459459459,0.331081081081081,0.327702702702703,0.324324324324324,0.320945945945946,0.320945945945946,0.320945945945946,0.317567567567568,0.314189189189189,0.310810810810811,0.307432432432432,0.307432432432432,0.304054054054054,0.300675675675676,0.300675675675676,0.297297297297297,0.293918918918919,0.290540540540541,0.287162162162162,0.287162162162162,0.283783783783784,0.280405405405405,0.277027027027027,0.273648648648649,0.27027027027027,0.27027027027027,0.27027027027027,0.266891891891892,0.263513513513513,0.260135135135135,0.256756756756757,0.253378378378378,0.25,0.246621621621622,0.243243243243243,0.239864864864865,0.236486486486486,0.233108108108108,0.22972972972973,0.226351351351351,0.222972972972973,0.219594594594595,0.216216216216216,0.212837837837838,0.209459459459459,0.209459459459459,0.206081081081081,0.202702702702703,0.199324324324324,0.195945945945946,0.192567567567568,0.189189189189189,0.185810810810811,0.182432432432432,0.179054054054054,0.175675675675676,0.172297297297297,0.168918918918919,0.165540540540541,0.162162162162162,0.158783783783784,0.155405405405405,0.152027027027027,0.148648648648649,0.14527027027027,0.141891891891892,0.138513513513514,0.135135135135135,0.131756756756757,0.128378378378378,0.125,0.121621621621622,0.121621621621622,0.118243243243243,0.114864864864865,0.114864864864865,0.111486486486486,0.108108108108108,0.10472972972973,0.101351351351351,0.097972972972973,0.0945945945945946,0.0912162162162162,0.0878378378378378,0.0878378378378378,0.0844594594594595,0.0810810810810811,0.0810810810810811,0.0777027027027027,0.0743243243243243,0.0709459459459459,0.0675675675675676,0.0641891891891892,0.0608108108108108,0.0574324324324324,0.0540540540540541,0.0506756756756757,0.0472972972972973,0.0439189189189189,0.0405405405405405,0.0371621621621622,0.0337837837837838,0.0304054054054054,0.027027027027027,0.0236486486486486,0.0202702702702703,0.0168918918918919,0.0168918918918919,0.0135135135135135,0.0101351351351351,0.00675675675675676,0.00337837837837838,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 0.99382716<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 0.99382716<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.98765432<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.98148148<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.97530864<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.96913580<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.96296296<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.95679012<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.95061728<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.94444444<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.93827160<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.93827160<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.93209877<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.92592593<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.91975309<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.91358025<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.90740741<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.90740741<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.90123457<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.89506173<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.88888889<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.88271605<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.87654321<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.87037037<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.86419753<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.85802469<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.85185185<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.84567901<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.84567901<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.84567901<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.83950617<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.83333333<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.82716049<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.82098765<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.81481481<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.80864198<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.80246914<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.80246914<br />sensitivity: 0.979729730<br />model: Random forest","1 - specificity: 0.79629630<br />sensitivity: 0.979729730<br />model: Random forest","1 - specificity: 0.79629630<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.79012346<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.78395062<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.77777778<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.77160494<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.76543210<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.76543210<br />sensitivity: 0.972972973<br />model: Random forest","1 - specificity: 0.75925926<br />sensitivity: 0.972972973<br />model: Random forest","1 - specificity: 0.75925926<br />sensitivity: 0.969594595<br />model: Random forest","1 - specificity: 0.75925926<br />sensitivity: 0.966216216<br />model: Random forest","1 - specificity: 0.75925926<br />sensitivity: 0.962837838<br />model: Random forest","1 - specificity: 0.75308642<br />sensitivity: 0.962837838<br />model: Random forest","1 - specificity: 0.75308642<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.74691358<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.74074074<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.73456790<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.73456790<br />sensitivity: 0.956081081<br />model: Random forest","1 - specificity: 0.72839506<br />sensitivity: 0.956081081<br />model: Random forest","1 - specificity: 0.72222222<br />sensitivity: 0.956081081<br />model: Random forest","1 - specificity: 0.72222222<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.72222222<br />sensitivity: 0.949324324<br />model: Random forest","1 - specificity: 0.72222222<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.71604938<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.70987654<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.70370370<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.69753086<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.69135802<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.68518519<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.939189189<br />model: Random forest","1 - specificity: 0.67283951<br />sensitivity: 0.939189189<br />model: Random forest","1 - specificity: 0.66666667<br />sensitivity: 0.939189189<br />model: Random forest","1 - specificity: 0.66049383<br />sensitivity: 0.939189189<br />model: Random forest","1 - specificity: 0.66049383<br />sensitivity: 0.935810811<br />model: Random forest","1 - specificity: 0.66049383<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.65432099<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.64814815<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.64814815<br />sensitivity: 0.929054054<br />model: Random forest","1 - specificity: 0.64197531<br />sensitivity: 0.929054054<br />model: Random forest","1 - specificity: 0.63580247<br />sensitivity: 0.929054054<br />model: Random forest","1 - specificity: 0.63580247<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.62962963<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.62345679<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.61728395<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.61728395<br />sensitivity: 0.922297297<br />model: Random forest","1 - specificity: 0.61111111<br />sensitivity: 0.922297297<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.922297297<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.918918919<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.915540541<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.912162162<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.908783784<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.908783784<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.905405405<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.59259259<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.58641975<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.58024691<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.57407407<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.56790123<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.56172840<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.55555556<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.55555556<br />sensitivity: 0.895270270<br />model: Random forest","1 - specificity: 0.54938272<br />sensitivity: 0.895270270<br />model: Random forest","1 - specificity: 0.54938272<br />sensitivity: 0.891891892<br />model: Random forest","1 - specificity: 0.54320988<br />sensitivity: 0.891891892<br />model: Random forest","1 - specificity: 0.54320988<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.53703704<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.53086420<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.52469136<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.51851852<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.51234568<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.51234568<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50617284<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.881756757<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.878378378<br />model: Random forest","1 - specificity: 0.49382716<br />sensitivity: 0.878378378<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.878378378<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.875000000<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.868243243<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.864864865<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.861486486<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.858108108<br />model: Random forest","1 - specificity: 0.48148148<br />sensitivity: 0.858108108<br />model: Random forest","1 - specificity: 0.48148148<br />sensitivity: 0.854729730<br />model: Random forest","1 - specificity: 0.48148148<br />sensitivity: 0.851351351<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.851351351<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.46913580<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.46296296<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.46296296<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.45679012<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.44444444<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.43827160<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.43209877<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.42592593<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.42592593<br />sensitivity: 0.841216216<br />model: Random forest","1 - specificity: 0.41975309<br />sensitivity: 0.841216216<br />model: Random forest","1 - specificity: 0.41975309<br />sensitivity: 0.837837838<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.837837838<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.834459459<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.831081081<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.827702703<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.824324324<br />model: Random forest","1 - specificity: 0.40740741<br />sensitivity: 0.824324324<br />model: Random forest","1 - specificity: 0.40740741<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.817567568<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.817567568<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.814189189<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.810810811<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.810810811<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.807432432<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.804054054<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.800675676<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.38271605<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.37654321<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.37037037<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.36419753<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.36419753<br />sensitivity: 0.793918919<br />model: Random forest","1 - specificity: 0.36419753<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.36419753<br />sensitivity: 0.787162162<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.787162162<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.783783784<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.780405405<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.777027027<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.773648649<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.770270270<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.766891892<br />model: Random forest","1 - specificity: 0.35185185<br />sensitivity: 0.766891892<br />model: Random forest","1 - specificity: 0.35185185<br />sensitivity: 0.763513514<br />model: Random forest","1 - specificity: 0.34567901<br />sensitivity: 0.763513514<br />model: Random forest","1 - specificity: 0.34567901<br />sensitivity: 0.760135135<br />model: Random forest","1 - specificity: 0.34567901<br />sensitivity: 0.756756757<br />model: Random forest","1 - specificity: 0.33950617<br />sensitivity: 0.756756757<br />model: Random forest","1 - specificity: 0.33950617<br />sensitivity: 0.753378378<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.753378378<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.750000000<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.746621622<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.743243243<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.739864865<br />model: Random forest","1 - specificity: 0.32716049<br />sensitivity: 0.739864865<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.739864865<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.736486486<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.733108108<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.733108108<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.729729730<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.726351351<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.722972973<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.719594595<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.716216216<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.712837838<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.709459459<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.706081081<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.706081081<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.702702703<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.699324324<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.695945946<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.692567568<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.692567568<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.692567568<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.689189189<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.685810811<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.682432432<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.679054054<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.675675676<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.672297297<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.668918919<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.665540541<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.665540541<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.662162162<br />model: Random forest","1 - specificity: 0.28395062<br />sensitivity: 0.662162162<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.662162162<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.658783784<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.655405405<br />model: Random forest","1 - specificity: 0.27160494<br />sensitivity: 0.655405405<br />model: Random forest","1 - specificity: 0.27160494<br />sensitivity: 0.652027027<br />model: Random forest","1 - specificity: 0.27160494<br />sensitivity: 0.648648649<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.648648649<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.645270270<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.641891892<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.638513514<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.635135135<br />model: Random forest","1 - specificity: 0.25925926<br />sensitivity: 0.635135135<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.635135135<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.631756757<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.631756757<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.628378378<br />model: Random forest","1 - specificity: 0.24074074<br />sensitivity: 0.628378378<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.628378378<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.621621622<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.618243243<br />model: Random forest","1 - specificity: 0.22839506<br />sensitivity: 0.618243243<br />model: Random forest","1 - specificity: 0.22839506<br />sensitivity: 0.614864865<br />model: Random forest","1 - specificity: 0.22222222<br />sensitivity: 0.614864865<br />model: Random forest","1 - specificity: 0.21604938<br />sensitivity: 0.614864865<br />model: Random forest","1 - specificity: 0.21604938<br />sensitivity: 0.611486486<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.611486486<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.608108108<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.608108108<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.604729730<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.601351351<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.597972973<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.597972973<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.594594595<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.591216216<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.587837838<br />model: Random forest","1 - specificity: 0.19135802<br />sensitivity: 0.587837838<br />model: Random forest","1 - specificity: 0.19135802<br />sensitivity: 0.584459459<br />model: Random forest","1 - specificity: 0.19135802<br />sensitivity: 0.581081081<br />model: Random forest","1 - specificity: 0.18518519<br />sensitivity: 0.581081081<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.581081081<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.577702703<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.574324324<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.570945946<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.567567568<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.564189189<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.560810811<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.557432432<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.554054054<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.550675676<br />model: Random forest","1 - specificity: 0.17283951<br />sensitivity: 0.550675676<br />model: Random forest","1 - specificity: 0.17283951<br />sensitivity: 0.547297297<br />model: Random forest","1 - specificity: 0.17283951<br />sensitivity: 0.543918919<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.543918919<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.540540541<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.537162162<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.533783784<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.530405405<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.527027027<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.523648649<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.520270270<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.516891892<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.513513514<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.510135135<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.506756757<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.503378378<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.500000000<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.496621622<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.496621622<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.493243243<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.489864865<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.486486486<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.483108108<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.479729730<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.476351351<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.476351351<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.472972973<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.469594595<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.466216216<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.462837838<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.459459459<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.456081081<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.452702703<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.449324324<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.445945946<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.442567568<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.442567568<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.439189189<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.439189189<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.435810811<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.435810811<br />model: Random forest","1 - specificity: 0.12962963<br />sensitivity: 0.435810811<br />model: Random forest","1 - specificity: 0.12345679<br />sensitivity: 0.435810811<br />model: Random forest","1 - specificity: 0.12345679<br />sensitivity: 0.432432432<br />model: Random forest","1 - specificity: 0.11728395<br />sensitivity: 0.432432432<br />model: Random forest","1 - specificity: 0.11728395<br />sensitivity: 0.429054054<br />model: Random forest","1 - specificity: 0.11111111<br />sensitivity: 0.429054054<br />model: Random forest","1 - specificity: 0.10493827<br />sensitivity: 0.429054054<br />model: Random forest","1 - specificity: 0.10493827<br />sensitivity: 0.425675676<br />model: Random forest","1 - specificity: 0.10493827<br />sensitivity: 0.422297297<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.422297297<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.418918919<br />model: Random forest","1 - specificity: 0.09259259<br />sensitivity: 0.418918919<br />model: Random forest","1 - specificity: 0.09259259<br />sensitivity: 0.415540541<br />model: Random forest","1 - specificity: 0.09259259<br />sensitivity: 0.412162162<br />model: Random forest","1 - specificity: 0.09259259<br />sensitivity: 0.408783784<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.408783784<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.405405405<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.402027027<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.398648649<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.395270270<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.391891892<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.388513514<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.385135135<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.381756757<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.378378378<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.375000000<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.371621622<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.368243243<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.364864865<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.361486486<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.358108108<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.354729730<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.351351351<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.347972973<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.347972973<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.344594595<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.341216216<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.337837838<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.334459459<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.331081081<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.327702703<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.324324324<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.320945946<br />model: Random forest","1 - specificity: 0.07407407<br />sensitivity: 0.320945946<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.320945946<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.317567568<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.314189189<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.310810811<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.307432432<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.307432432<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.304054054<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.300675676<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.300675676<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.297297297<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.293918919<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.290540541<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.287162162<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.287162162<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.283783784<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.280405405<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.277027027<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.273648649<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.270270270<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.270270270<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.270270270<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.266891892<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.263513514<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.260135135<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.256756757<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.253378378<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.250000000<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.246621622<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.243243243<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.239864865<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.236486486<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.233108108<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.229729730<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.226351351<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.222972973<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.219594595<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.216216216<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.212837838<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.209459459<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.209459459<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.206081081<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.202702703<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.199324324<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.195945946<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.192567568<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.189189189<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.185810811<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.182432432<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.179054054<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.175675676<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.172297297<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.168918919<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.165540541<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.162162162<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.158783784<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.155405405<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.152027027<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.148648649<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.145270270<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.141891892<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.138513514<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.135135135<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.131756757<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.128378378<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.125000000<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.121621622<br />model: Random forest","1 - specificity: 0.02469136<br />sensitivity: 0.121621622<br />model: Random forest","1 - specificity: 0.02469136<br />sensitivity: 0.118243243<br />model: Random forest","1 - specificity: 0.02469136<br />sensitivity: 0.114864865<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.114864865<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.111486486<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.108108108<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.104729730<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.101351351<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.097972973<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.094594595<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.091216216<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.087837838<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.087837838<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.084459459<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.081081081<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.081081081<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.077702703<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.074324324<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.070945946<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.067567568<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.064189189<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.060810811<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.057432432<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.054054054<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.050675676<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.047297297<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.043918919<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.040540541<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.037162162<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.033783784<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.030405405<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.027027027<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.023648649<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.020270270<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.016891892<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.016891892<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.013513514<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.010135135<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.006756757<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.003378378<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: Random forest"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"Random forest","legendgroup":"Random forest","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,1,0.993827160493827,0.993827160493827,0.987654320987654,0.981481481481482,0.975308641975309,0.969135802469136,0.962962962962963,0.95679012345679,0.950617283950617,0.944444444444444,0.938271604938272,0.932098765432099,0.932098765432099,0.925925925925926,0.919753086419753,0.91358024691358,0.907407407407407,0.901234567901235,0.895061728395062,0.888888888888889,0.882716049382716,0.876543209876543,0.87037037037037,0.864197530864198,0.858024691358025,0.858024691358025,0.851851851851852,0.845679012345679,0.839506172839506,0.839506172839506,0.833333333333333,0.827160493827161,0.820987654320988,0.814814814814815,0.814814814814815,0.814814814814815,0.808641975308642,0.808641975308642,0.808641975308642,0.802469135802469,0.796296296296296,0.790123456790123,0.783950617283951,0.777777777777778,0.771604938271605,0.765432098765432,0.759259259259259,0.753086419753086,0.746913580246914,0.740740740740741,0.740740740740741,0.734567901234568,0.728395061728395,0.728395061728395,0.728395061728395,0.722222222222222,0.722222222222222,0.716049382716049,0.709876543209877,0.709876543209877,0.703703703703704,0.703703703703704,0.703703703703704,0.703703703703704,0.697530864197531,0.691358024691358,0.691358024691358,0.685185185185185,0.679012345679012,0.672839506172839,0.666666666666667,0.660493827160494,0.654320987654321,0.654320987654321,0.654320987654321,0.648148148148148,0.641975308641975,0.635802469135802,0.62962962962963,0.623456790123457,0.617283950617284,0.617283950617284,0.611111111111111,0.611111111111111,0.604938271604938,0.598765432098765,0.598765432098765,0.598765432098765,0.592592592592593,0.592592592592593,0.592592592592593,0.58641975308642,0.58641975308642,0.580246913580247,0.574074074074074,0.567901234567901,0.567901234567901,0.561728395061728,0.555555555555556,0.549382716049383,0.549382716049383,0.549382716049383,0.54320987654321,0.537037037037037,0.530864197530864,0.524691358024691,0.524691358024691,0.524691358024691,0.518518518518519,0.512345679012346,0.512345679012346,0.506172839506173,0.506172839506173,0.5,0.493827160493827,0.493827160493827,0.487654320987654,0.481481481481482,0.481481481481482,0.475308641975309,0.469135802469136,0.462962962962963,0.45679012345679,0.450617283950617,0.450617283950617,0.444444444444444,0.438271604938272,0.432098765432099,0.425925925925926,0.419753086419753,0.41358024691358,0.41358024691358,0.407407407407407,0.407407407407407,0.407407407407407,0.407407407407407,0.401234567901235,0.401234567901235,0.401234567901235,0.395061728395062,0.395061728395062,0.395061728395062,0.388888888888889,0.388888888888889,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.376543209876543,0.376543209876543,0.37037037037037,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.358024691358025,0.358024691358025,0.351851851851852,0.351851851851852,0.351851851851852,0.351851851851852,0.351851851851852,0.345679012345679,0.339506172839506,0.333333333333333,0.327160493827161,0.327160493827161,0.327160493827161,0.320987654320988,0.320987654320988,0.320987654320988,0.314814814814815,0.314814814814815,0.314814814814815,0.308641975308642,0.302469135802469,0.302469135802469,0.302469135802469,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.290123456790123,0.290123456790123,0.290123456790123,0.290123456790123,0.283950617283951,0.283950617283951,0.283950617283951,0.277777777777778,0.277777777777778,0.277777777777778,0.277777777777778,0.277777777777778,0.271604938271605,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.259259259259259,0.259259259259259,0.253086419753086,0.253086419753086,0.253086419753086,0.246913580246914,0.246913580246914,0.246913580246914,0.246913580246914,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.240740740740741,0.234567901234568,0.228395061728395,0.228395061728395,0.228395061728395,0.228395061728395,0.228395061728395,0.222222222222222,0.222222222222222,0.222222222222222,0.222222222222222,0.216049382716049,0.209876543209877,0.209876543209877,0.203703703703704,0.197530864197531,0.197530864197531,0.197530864197531,0.191358024691358,0.191358024691358,0.191358024691358,0.191358024691358,0.191358024691358,0.191358024691358,0.185185185185185,0.185185185185185,0.179012345679012,0.179012345679012,0.172839506172839,0.166666666666667,0.166666666666667,0.160493827160494,0.154320987654321,0.148148148148148,0.148148148148148,0.148148148148148,0.141975308641975,0.135802469135803,0.135802469135803,0.12962962962963,0.12962962962963,0.12962962962963,0.12962962962963,0.12962962962963,0.12962962962963,0.123456790123457,0.123456790123457,0.117283950617284,0.111111111111111,0.104938271604938,0.104938271604938,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0185185185185185,0.0185185185185185,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0,0,0,0,0,0,0],"y":[1,1,1,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.983108108108108,0.97972972972973,0.97972972972973,0.976351351351351,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.972972972972973,0.969594594594595,0.969594594594595,0.969594594594595,0.966216216216216,0.962837837837838,0.962837837837838,0.959459459459459,0.959459459459459,0.959459459459459,0.956081081081081,0.956081081081081,0.952702702702703,0.949324324324324,0.945945945945946,0.945945945945946,0.945945945945946,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.939189189189189,0.935810810810811,0.935810810810811,0.935810810810811,0.935810810810811,0.935810810810811,0.935810810810811,0.935810810810811,0.932432432432432,0.932432432432432,0.929054054054054,0.929054054054054,0.929054054054054,0.925675675675676,0.922297297297297,0.922297297297297,0.918918918918919,0.915540540540541,0.915540540540541,0.912162162162162,0.912162162162162,0.912162162162162,0.912162162162162,0.908783783783784,0.908783783783784,0.908783783783784,0.908783783783784,0.905405405405405,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.898648648648649,0.89527027027027,0.89527027027027,0.89527027027027,0.891891891891892,0.891891891891892,0.888513513513513,0.888513513513513,0.888513513513513,0.885135135135135,0.885135135135135,0.885135135135135,0.881756756756757,0.881756756756757,0.881756756756757,0.881756756756757,0.881756756756757,0.881756756756757,0.878378378378378,0.878378378378378,0.878378378378378,0.878378378378378,0.878378378378378,0.878378378378378,0.878378378378378,0.875,0.875,0.871621621621622,0.868243243243243,0.864864864864865,0.864864864864865,0.861486486486487,0.858108108108108,0.858108108108108,0.85472972972973,0.851351351351351,0.851351351351351,0.847972972972973,0.847972972972973,0.844594594594595,0.841216216216216,0.837837837837838,0.834459459459459,0.831081081081081,0.827702702702703,0.824324324324324,0.820945945945946,0.817567567567568,0.814189189189189,0.814189189189189,0.810810810810811,0.810810810810811,0.810810810810811,0.807432432432432,0.804054054054054,0.800675675675676,0.797297297297297,0.797297297297297,0.793918918918919,0.793918918918919,0.790540540540541,0.787162162162162,0.783783783783784,0.780405405405405,0.780405405405405,0.780405405405405,0.780405405405405,0.780405405405405,0.777027027027027,0.773648648648649,0.773648648648649,0.77027027027027,0.766891891891892,0.766891891891892,0.763513513513513,0.760135135135135,0.760135135135135,0.760135135135135,0.756756756756757,0.753378378378378,0.753378378378378,0.75,0.746621621621622,0.743243243243243,0.739864864864865,0.736486486486487,0.736486486486487,0.733108108108108,0.72972972972973,0.726351351351351,0.726351351351351,0.722972972972973,0.719594594594595,0.719594594594595,0.716216216216216,0.712837837837838,0.709459459459459,0.706081081081081,0.706081081081081,0.706081081081081,0.702702702702703,0.699324324324324,0.695945945945946,0.692567567567568,0.692567567567568,0.689189189189189,0.689189189189189,0.685810810810811,0.682432432432432,0.682432432432432,0.679054054054054,0.675675675675676,0.672297297297297,0.672297297297297,0.668918918918919,0.665540540540541,0.662162162162162,0.658783783783784,0.655405405405405,0.652027027027027,0.648648648648649,0.64527027027027,0.64527027027027,0.64527027027027,0.641891891891892,0.638513513513513,0.635135135135135,0.631756756756757,0.631756756756757,0.628378378378378,0.625,0.621621621621622,0.621621621621622,0.621621621621622,0.618243243243243,0.618243243243243,0.618243243243243,0.614864864864865,0.611486486486487,0.611486486486487,0.608108108108108,0.60472972972973,0.601351351351351,0.597972972972973,0.594594594594595,0.594594594594595,0.591216216216216,0.591216216216216,0.587837837837838,0.587837837837838,0.587837837837838,0.584459459459459,0.584459459459459,0.584459459459459,0.584459459459459,0.581081081081081,0.577702702702703,0.577702702702703,0.577702702702703,0.574324324324324,0.574324324324324,0.570945945945946,0.567567567567568,0.564189189189189,0.560810810810811,0.557432432432432,0.557432432432432,0.554054054054054,0.554054054054054,0.554054054054054,0.554054054054054,0.550675675675676,0.550675675675676,0.547297297297297,0.543918918918919,0.540540540540541,0.537162162162162,0.533783783783784,0.530405405405405,0.527027027027027,0.523648648648649,0.52027027027027,0.516891891891892,0.513513513513513,0.510135135135135,0.506756756756757,0.503378378378378,0.5,0.496621621621622,0.493243243243243,0.489864864864865,0.486486486486487,0.486486486486487,0.483108108108108,0.47972972972973,0.476351351351351,0.472972972972973,0.469594594594595,0.466216216216216,0.462837837837838,0.459459459459459,0.456081081081081,0.452702702702703,0.449324324324324,0.449324324324324,0.445945945945946,0.442567567567568,0.439189189189189,0.435810810810811,0.432432432432432,0.429054054054054,0.429054054054054,0.429054054054054,0.425675675675676,0.422297297297297,0.418918918918919,0.418918918918919,0.418918918918919,0.415540540540541,0.412162162162162,0.408783783783784,0.405405405405405,0.402027027027027,0.398648648648649,0.39527027027027,0.391891891891892,0.388513513513513,0.385135135135135,0.381756756756757,0.378378378378378,0.378378378378378,0.375,0.371621621621622,0.368243243243243,0.364864864864865,0.361486486486487,0.358108108108108,0.358108108108108,0.35472972972973,0.351351351351351,0.347972972972973,0.344594594594595,0.341216216216216,0.337837837837838,0.334459459459459,0.331081081081081,0.327702702702703,0.324324324324324,0.320945945945946,0.317567567567568,0.314189189189189,0.310810810810811,0.307432432432432,0.304054054054054,0.300675675675676,0.297297297297297,0.297297297297297,0.293918918918919,0.290540540540541,0.287162162162162,0.283783783783784,0.280405405405405,0.277027027027027,0.273648648648649,0.27027027027027,0.27027027027027,0.266891891891892,0.263513513513513,0.260135135135135,0.256756756756757,0.253378378378378,0.25,0.246621621621622,0.243243243243243,0.239864864864865,0.236486486486486,0.233108108108108,0.22972972972973,0.226351351351351,0.226351351351351,0.222972972972973,0.219594594594595,0.216216216216216,0.212837837837838,0.212837837837838,0.209459459459459,0.206081081081081,0.202702702702703,0.199324324324324,0.195945945945946,0.192567567567568,0.189189189189189,0.185810810810811,0.182432432432432,0.179054054054054,0.175675675675676,0.172297297297297,0.168918918918919,0.165540540540541,0.162162162162162,0.158783783783784,0.155405405405405,0.155405405405405,0.152027027027027,0.152027027027027,0.148648648648649,0.14527027027027,0.141891891891892,0.141891891891892,0.138513513513514,0.135135135135135,0.131756756756757,0.128378378378378,0.125,0.121621621621622,0.118243243243243,0.114864864864865,0.111486486486486,0.108108108108108,0.10472972972973,0.101351351351351,0.097972972972973,0.0945945945945946,0.0912162162162162,0.0878378378378378,0.0844594594594595,0.0810810810810811,0.0777027027027027,0.0743243243243243,0.0709459459459459,0.0675675675675676,0.0641891891891892,0.0608108108108108,0.0574324324324324,0.0540540540540541,0.0506756756756757,0.0472972972972973,0.0439189189189189,0.0405405405405405,0.0371621621621622,0.0337837837837838,0.0304054054054054,0.027027027027027,0.0236486486486486,0.0202702702702703,0.0202702702702703,0.0168918918918919,0.0135135135135135,0.0101351351351351,0.00675675675675676,0.00337837837837838,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 0.99382716<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 0.99382716<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.98765432<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.98148148<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.97530864<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.96913580<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.96296296<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.95679012<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.95061728<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.94444444<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.93827160<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.93209877<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.93209877<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.92592593<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.91975309<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.91358025<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.90740741<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.90123457<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.89506173<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.88888889<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.88271605<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.87654321<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.87037037<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.86419753<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.85802469<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.85802469<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.85185185<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.84567901<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.83950617<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.83950617<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.83333333<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.82716049<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.82098765<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.81481481<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.81481481<br />sensitivity: 0.983108108<br />model: XGBoost","1 - specificity: 0.81481481<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.80864198<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.80864198<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.80864198<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.80246914<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.79629630<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.79012346<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.78395062<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.77777778<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.77160494<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.76543210<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.75925926<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.75308642<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.74691358<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.74074074<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.74074074<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.73456790<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.72839506<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.72839506<br />sensitivity: 0.966216216<br />model: XGBoost","1 - specificity: 0.72839506<br />sensitivity: 0.962837838<br />model: XGBoost","1 - specificity: 0.72222222<br />sensitivity: 0.962837838<br />model: XGBoost","1 - specificity: 0.72222222<br />sensitivity: 0.959459459<br />model: XGBoost","1 - specificity: 0.71604938<br />sensitivity: 0.959459459<br />model: XGBoost","1 - specificity: 0.70987654<br />sensitivity: 0.959459459<br />model: XGBoost","1 - specificity: 0.70987654<br />sensitivity: 0.956081081<br />model: XGBoost","1 - specificity: 0.70370370<br />sensitivity: 0.956081081<br />model: XGBoost","1 - specificity: 0.70370370<br />sensitivity: 0.952702703<br />model: XGBoost","1 - specificity: 0.70370370<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.70370370<br />sensitivity: 0.945945946<br />model: XGBoost","1 - specificity: 0.69753086<br />sensitivity: 0.945945946<br />model: XGBoost","1 - specificity: 0.69135802<br />sensitivity: 0.945945946<br />model: XGBoost","1 - specificity: 0.69135802<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.68518519<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.67901235<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.67283951<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.66666667<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.66049383<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.65432099<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.65432099<br />sensitivity: 0.939189189<br />model: XGBoost","1 - specificity: 0.65432099<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.64814815<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.64197531<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.63580247<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.62962963<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.62345679<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.61728395<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.61728395<br />sensitivity: 0.932432432<br />model: XGBoost","1 - specificity: 0.61111111<br />sensitivity: 0.932432432<br />model: XGBoost","1 - specificity: 0.61111111<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.60493827<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.59876543<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.59876543<br />sensitivity: 0.925675676<br />model: XGBoost","1 - specificity: 0.59876543<br />sensitivity: 0.922297297<br />model: XGBoost","1 - specificity: 0.59259259<br />sensitivity: 0.922297297<br />model: XGBoost","1 - specificity: 0.59259259<br />sensitivity: 0.918918919<br />model: XGBoost","1 - specificity: 0.59259259<br />sensitivity: 0.915540541<br />model: XGBoost","1 - specificity: 0.58641975<br />sensitivity: 0.915540541<br />model: XGBoost","1 - specificity: 0.58641975<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.58024691<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.57407407<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.56790123<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.56790123<br />sensitivity: 0.908783784<br />model: XGBoost","1 - specificity: 0.56172840<br />sensitivity: 0.908783784<br />model: XGBoost","1 - specificity: 0.55555556<br />sensitivity: 0.908783784<br />model: XGBoost","1 - specificity: 0.54938272<br />sensitivity: 0.908783784<br />model: XGBoost","1 - specificity: 0.54938272<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.54938272<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.54320988<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.53703704<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.53086420<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.52469136<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.52469136<br />sensitivity: 0.898648649<br />model: XGBoost","1 - specificity: 0.52469136<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.51851852<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.51234568<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.51234568<br />sensitivity: 0.891891892<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.891891892<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.50000000<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.49382716<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.49382716<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.48765432<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.48148148<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.48148148<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.47530864<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.46913580<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.46296296<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.45679012<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.45061728<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.45061728<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.44444444<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.43827160<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.43209877<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.42592593<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.41975309<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.41358025<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.41358025<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.871621622<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.868243243<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.864864865<br />model: XGBoost","1 - specificity: 0.40123457<br />sensitivity: 0.864864865<br />model: XGBoost","1 - specificity: 0.40123457<br />sensitivity: 0.861486486<br />model: XGBoost","1 - specificity: 0.40123457<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.39506173<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.39506173<br />sensitivity: 0.854729730<br />model: XGBoost","1 - specificity: 0.39506173<br />sensitivity: 0.851351351<br />model: XGBoost","1 - specificity: 0.38888889<br />sensitivity: 0.851351351<br />model: XGBoost","1 - specificity: 0.38888889<br />sensitivity: 0.847972973<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.847972973<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.844594595<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.841216216<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.837837838<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.834459459<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.831081081<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.827702703<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.824324324<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.820945946<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.817567568<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.814189189<br />model: XGBoost","1 - specificity: 0.37654321<br />sensitivity: 0.814189189<br />model: XGBoost","1 - specificity: 0.37654321<br />sensitivity: 0.810810811<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.810810811<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.810810811<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.807432432<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.804054054<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.800675676<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.797297297<br />model: XGBoost","1 - specificity: 0.35802469<br />sensitivity: 0.797297297<br />model: XGBoost","1 - specificity: 0.35802469<br />sensitivity: 0.793918919<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.793918919<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.790540541<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.787162162<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.783783784<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.34567901<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.33950617<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.33333333<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.777027027<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.773648649<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.773648649<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.770270270<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.766891892<br />model: XGBoost","1 - specificity: 0.31481481<br />sensitivity: 0.766891892<br />model: XGBoost","1 - specificity: 0.31481481<br />sensitivity: 0.763513514<br />model: XGBoost","1 - specificity: 0.31481481<br />sensitivity: 0.760135135<br />model: XGBoost","1 - specificity: 0.30864198<br />sensitivity: 0.760135135<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.760135135<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.756756757<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.753378378<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.753378378<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.750000000<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.746621622<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.743243243<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.739864865<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.736486486<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.736486486<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.733108108<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.729729730<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.726351351<br />model: XGBoost","1 - specificity: 0.28395062<br />sensitivity: 0.726351351<br />model: XGBoost","1 - specificity: 0.28395062<br />sensitivity: 0.722972973<br />model: XGBoost","1 - specificity: 0.28395062<br />sensitivity: 0.719594595<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.719594595<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.716216216<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.712837838<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.709459459<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.706081081<br />model: XGBoost","1 - specificity: 0.27160494<br />sensitivity: 0.706081081<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.706081081<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.702702703<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.699324324<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.695945946<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.692567568<br />model: XGBoost","1 - specificity: 0.25925926<br />sensitivity: 0.692567568<br />model: XGBoost","1 - specificity: 0.25925926<br />sensitivity: 0.689189189<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.689189189<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.685810811<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.682432432<br />model: XGBoost","1 - specificity: 0.24691358<br />sensitivity: 0.682432432<br />model: XGBoost","1 - specificity: 0.24691358<br />sensitivity: 0.679054054<br />model: XGBoost","1 - specificity: 0.24691358<br />sensitivity: 0.675675676<br />model: XGBoost","1 - specificity: 0.24691358<br />sensitivity: 0.672297297<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.672297297<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.668918919<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.665540541<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.662162162<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.658783784<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.655405405<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.652027027<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.648648649<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.645270270<br />model: XGBoost","1 - specificity: 0.23456790<br />sensitivity: 0.645270270<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.645270270<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.641891892<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.638513514<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.635135135<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.631756757<br />model: XGBoost","1 - specificity: 0.22222222<br />sensitivity: 0.631756757<br />model: XGBoost","1 - specificity: 0.22222222<br />sensitivity: 0.628378378<br />model: XGBoost","1 - specificity: 0.22222222<br />sensitivity: 0.625000000<br />model: XGBoost","1 - specificity: 0.22222222<br />sensitivity: 0.621621622<br />model: XGBoost","1 - specificity: 0.21604938<br />sensitivity: 0.621621622<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.621621622<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.618243243<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.618243243<br />model: XGBoost","1 - specificity: 0.19753086<br />sensitivity: 0.618243243<br />model: XGBoost","1 - specificity: 0.19753086<br />sensitivity: 0.614864865<br />model: XGBoost","1 - specificity: 0.19753086<br />sensitivity: 0.611486486<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.611486486<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.608108108<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.604729730<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.601351351<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.597972973<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.594594595<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.594594595<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.591216216<br />model: XGBoost","1 - specificity: 0.17901235<br />sensitivity: 0.591216216<br />model: XGBoost","1 - specificity: 0.17901235<br />sensitivity: 0.587837838<br />model: XGBoost","1 - specificity: 0.17283951<br />sensitivity: 0.587837838<br />model: XGBoost","1 - specificity: 0.16666667<br />sensitivity: 0.587837838<br />model: XGBoost","1 - specificity: 0.16666667<br />sensitivity: 0.584459459<br />model: XGBoost","1 - specificity: 0.16049383<br />sensitivity: 0.584459459<br />model: XGBoost","1 - specificity: 0.15432099<br />sensitivity: 0.584459459<br />model: XGBoost","1 - specificity: 0.14814815<br />sensitivity: 0.584459459<br />model: XGBoost","1 - specificity: 0.14814815<br />sensitivity: 0.581081081<br />model: XGBoost","1 - specificity: 0.14814815<br />sensitivity: 0.577702703<br />model: XGBoost","1 - specificity: 0.14197531<br />sensitivity: 0.577702703<br />model: XGBoost","1 - specificity: 0.13580247<br />sensitivity: 0.577702703<br />model: XGBoost","1 - specificity: 0.13580247<br />sensitivity: 0.574324324<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.574324324<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.570945946<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.567567568<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.564189189<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.560810811<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.557432432<br />model: XGBoost","1 - specificity: 0.12345679<br />sensitivity: 0.557432432<br />model: XGBoost","1 - specificity: 0.12345679<br />sensitivity: 0.554054054<br />model: XGBoost","1 - specificity: 0.11728395<br />sensitivity: 0.554054054<br />model: XGBoost","1 - specificity: 0.11111111<br />sensitivity: 0.554054054<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.554054054<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.550675676<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.550675676<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.547297297<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.543918919<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.540540541<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.537162162<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.533783784<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.530405405<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.527027027<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.523648649<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.520270270<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.516891892<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.513513514<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.510135135<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.506756757<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.503378378<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.500000000<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.496621622<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.493243243<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.489864865<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.486486486<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.486486486<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.483108108<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.479729730<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.476351351<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.472972973<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.469594595<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.466216216<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.462837838<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.459459459<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.456081081<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.452702703<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.449324324<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.449324324<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.445945946<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.442567568<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.439189189<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.435810811<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.432432432<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.429054054<br />model: XGBoost","1 - specificity: 0.08024691<br />sensitivity: 0.429054054<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.429054054<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.425675676<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.422297297<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.418918919<br />model: XGBoost","1 - specificity: 0.06790123<br />sensitivity: 0.418918919<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.418918919<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.415540541<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.412162162<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.408783784<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.405405405<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.402027027<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.398648649<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.395270270<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.391891892<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.388513514<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.385135135<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.381756757<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.378378378<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.378378378<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.375000000<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.371621622<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.368243243<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.364864865<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.361486486<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.358108108<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.358108108<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.354729730<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.351351351<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.347972973<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.344594595<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.341216216<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.337837838<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.334459459<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.331081081<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.327702703<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.324324324<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.320945946<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.317567568<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.314189189<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.310810811<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.307432432<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.304054054<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.300675676<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.297297297<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.297297297<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.293918919<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.290540541<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.287162162<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.283783784<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.280405405<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.277027027<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.273648649<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.270270270<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.270270270<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.266891892<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.263513514<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.260135135<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.256756757<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.253378378<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.250000000<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.246621622<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.243243243<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.239864865<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.236486486<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.233108108<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.229729730<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.226351351<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.226351351<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.222972973<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.219594595<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.216216216<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.212837838<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.212837838<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.209459459<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.206081081<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.202702703<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.199324324<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.195945946<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.192567568<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.189189189<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.185810811<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.182432432<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.179054054<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.175675676<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.172297297<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.168918919<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.165540541<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.162162162<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.158783784<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.155405405<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.155405405<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.152027027<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.152027027<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.148648649<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.145270270<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.141891892<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.141891892<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.138513514<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.135135135<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.131756757<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.128378378<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.125000000<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.121621622<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.118243243<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.114864865<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.111486486<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.108108108<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.104729730<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.101351351<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.097972973<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.094594595<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.091216216<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.087837838<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.084459459<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.081081081<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.077702703<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.074324324<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.070945946<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.067567568<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.064189189<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.060810811<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.057432432<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.054054054<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.050675676<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.047297297<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.043918919<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.040540541<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.037162162<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.033783784<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.030405405<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.027027027<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.023648649<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.020270270<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.020270270<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.016891892<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.013513514<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.010135135<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.006756757<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.003378378<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: XGBoost"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGBoost","legendgroup":"XGBoost","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-0.05,1.05],"y":[-0.05,1.05],"text":"intercept: 0<br />slope: 1","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"dot"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":27.1581569115816,"r":7.97011207970112,"b":43.8356164383562,"l":53.3997509339975},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":{"text":"1 - specificity","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"scaleanchor":"y","scaleratio":1,"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":{"text":"sensitivity","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"scaleanchor":"x","scaleratio":1,"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"title":{"text":"model","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"orientation":"h","xanchor":"center","x":0.5,"y":1},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"298879a03654":{"x":{},"y":{},"colour":{},"type":"scatter"},"298868ee36f7":{"intercept":{},"slope":{}}},"cur_data":"298879a03654","visdat":{"298879a03654":["function (y) ","x"],"298868ee36f7":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="model-interpretation" class="section level1">
<h1>Model interpretation</h1>
<div id="define-explainers" class="section level2">
<h2>Define explainers</h2>
<div id="random-forest-7" class="section level3">
<h3>Random forest</h3>
<p>Create explainer for random forest:</p>
<pre class="r"><code>explainer_rf &lt;- explain_tidymodels(
  rf_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;RF&quot;
)
explainer_rf</code></pre>
<pre><code>Model label:  RF 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
<div id="neural-network-7" class="section level3">
<h3>Neural network</h3>
<p>Create explainer for neural network:</p>
<pre class="r"><code>explainer_nnet &lt;- explain_tidymodels(
  nnet_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;NNet&quot;
)
explainer_nnet</code></pre>
<pre><code>Model label:  NNet 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
<div id="xgboost-7" class="section level3">
<h3>XGBoost</h3>
<p>Create explainer for XGBoost:</p>
<pre class="r"><code>explainer_xgb &lt;- explain_tidymodels(
  xgb_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;XGB&quot;
)
explainer_xgb</code></pre>
<pre><code>Model label:  XGB 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
</div>
<div id="residual-diagnostics" class="section level2">
<h2>Residual diagnostics</h2>
<div id="random-forest-8" class="section level3">
<h3>Random forest</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_rf &lt;- model_performance(explainer_rf)
resid_diag_rf</code></pre>
<pre><code>Measures for:  classification
recall     : 0.9751693 
precision  : 0.9181722 
f1         : 0.9458128 
accuracy   : 0.9278426 
auc        : 0.9858313

Residuals:
         0%         10%         20%         30%         40%         50% 
-0.74312535 -0.42782482 -0.29259286 -0.19159648  0.02507024  0.07704259 
        60%         70%         80%         90%        100% 
 0.12866848  0.19082208  0.24753516  0.32714605  0.62429985 </code></pre>
</div>
<div id="neural-network-8" class="section level3">
<h3>Neural network</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_nnet &lt;- model_performance(explainer_nnet)
resid_diag_nnet</code></pre>
<pre><code>Measures for:  classification
recall     : 0.9074492 
precision  : 0.8154158 
f1         : 0.8589744 
accuracy   : 0.8075802 
auc        : 0.8160201

Residuals:
        0%        10%        20%        30%        40%        50%        60% 
-0.7177737 -0.6036178 -0.3578878 -0.3578600  0.2822263  0.2822263  0.3501108 
       70%        80%        90%       100% 
 0.3745205  0.3963342  0.3963847  0.6421400 </code></pre>
</div>
<div id="xgboost-8" class="section level3">
<h3>XGBoost</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_xgb &lt;- model_performance(explainer_xgb)
resid_diag_xgb</code></pre>
<pre><code>Measures for:  classification
recall     : 0.8600451 
precision  : 0.775178 
f1         : 0.8154093 
accuracy   : 0.7485423 
auc        : 0.8027246

Residuals:
         0%         10%         20%         30%         40%         50% 
-0.95772687 -0.62168851 -0.43980771 -0.29285383  0.04682295  0.10797129 
        60%         70%         80%         90%        100% 
 0.16806108  0.25395899  0.35322148  0.48632387  0.86145025 </code></pre>
<p>Create residual diagnostics plot:</p>
<pre class="r"><code>resid_diag_line &lt;- plot(resid_diag_rf, resid_diag_nnet, resid_diag_xgb)
resid_diag_box &lt;- plot(
  resid_diag_rf, resid_diag_nnet, resid_diag_xgb, geom = &quot;boxplot&quot;
)

resid_diag_plot &lt;- resid_diag_box + resid_diag_line
resid_diag_plot</code></pre>
<p><img src="figure/tlverse.Rmd/resid-diag-plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># TODO: Convert it into an interactive plot
resid_diag_plot2 &lt;- resid_diag_plot
resid_diag_plot2</code></pre>
<p><img src="figure/tlverse.Rmd/resid-diag-plot2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>export(resid_diag_plot2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;resid-diag-plot.rds&quot;))</code></pre>
</div>
</div>
<div id="variable-importance" class="section level2">
<h2>Variable importance</h2>
<div id="random-forest-9" class="section level3">
<h3>Random forest</h3>
<p>Compute variable importance for random forest:</p>
<pre class="r"><code>vip_rf &lt;- model_parts(explainer_rf, loss_function = loss_one_minus_auc)
vip_rf</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_        0.01443382    RF
2         RDEF8        0.01618172    RF
3         RDEF7        0.01619522    RF
4        RHEP24        0.01628247    RF
5         RDEF2        0.01685251    RF
6       RATRIAL        0.01795041    RF
7         RASP3        0.01842843    RF
8         RDEF4        0.02107649    RF
9           SEX        0.02114940    RF
10       RSLEEP        0.02131153    RF
11        STYPE        0.02190743    RF
12      RVISINF        0.02193515    RF
13        RDEF1        0.02309510    RF
14       RCONSC        0.02720812    RF
15        RDEF5        0.03319090    RF
16          RCT        0.03739138    RF
17         RSBP        0.04861892    RF
18    treatment        0.04924624    RF
19        RDEF6        0.05846647    RF
20        RDEF3        0.06337917    RF
21       RDELAY        0.06624354    RF
22          AGE        0.23084138    RF
23   _baseline_        0.50426532    RF</code></pre>
</div>
<div id="neural-network-9" class="section level3">
<h3>Neural network</h3>
<p>Compute variable importance for neural network:</p>
<pre class="r"><code>vip_nnet &lt;- model_parts(explainer_nnet, loss_function = loss_one_minus_auc)
vip_nnet</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_         0.1838481  NNet
2        RHEP24         0.1861143  NNet
3         RDEF2         0.1892134  NNet
4       RVISINF         0.1936781  NNet
5         RDEF4         0.1944037  NNet
6       RATRIAL         0.1951601  NNet
7         RASP3         0.1955691  NNet
8        RDELAY         0.1960543  NNet
9          RSBP         0.1979063  NNet
10        RDEF8         0.1994185  NNet
11        RDEF7         0.2009665  NNet
12       RSLEEP         0.2024618  NNet
13        RDEF1         0.2035136  NNet
14          SEX         0.2080062  NNet
15          RCT         0.2147804  NNet
16        RDEF6         0.2186275  NNet
17       RCONSC         0.2195272  NNet
18        STYPE         0.2210655  NNet
19    treatment         0.2372237  NNet
20        RDEF3         0.2373673  NNet
21        RDEF5         0.2601251  NNet
22          AGE         0.3135122  NNet
23   _baseline_         0.5023290  NNet</code></pre>
</div>
<div id="xgboost-9" class="section level3">
<h3>XGBoost</h3>
<p>Compute variable importance for XGBoost:</p>
<pre class="r"><code>vip_xgb &lt;- model_parts(explainer_xgb, loss_function = loss_one_minus_auc)
vip_xgb</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_         0.1963694   XGB
2        RHEP24         0.1963694   XGB
3         RASP3         0.1964396   XGB
4         RDEF8         0.1964581   XGB
5       RATRIAL         0.1970495   XGB
6         RDEF7         0.1971622   XGB
7         RDEF2         0.1972873   XGB
8           SEX         0.1978298   XGB
9        RSLEEP         0.1980439   XGB
10        RDEF1         0.1989996   XGB
11        RDEF4         0.1991555   XGB
12        RDEF5         0.1992709   XGB
13        STYPE         0.1993062   XGB
14      RVISINF         0.1998396   XGB
15       RDELAY         0.2022439   XGB
16         RSBP         0.2031456   XGB
17    treatment         0.2049611   XGB
18       RCONSC         0.2071440   XGB
19        RDEF6         0.2096536   XGB
20          RCT         0.2107840   XGB
21        RDEF3         0.2160928   XGB
22          AGE         0.2638793   XGB
23   _baseline_         0.5048998   XGB</code></pre>
<p>Create variable importance plot:</p>
<pre class="r"><code>vip_plot &lt;- plot_vip(vip_rf, vip_nnet, vip_xgb)
vip_plot</code></pre>
<p><img src="figure/tlverse.Rmd/vip-plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>vip_plot2 &lt;- ggplotly(vip_plot)
vip_plot2</code></pre>
<div id="htmlwidget-d34d0cab8ffedbe4216b" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-d34d0cab8ffedbe4216b">{"x":{"data":[{"x":[0.31351215451697,0.260125125121583,0.237367268726153,0.237223674615216,0.221065457578126,0.219527190612373,0.218627540838256,0.214780397357092,0.208006177905175,0.203513577346436],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___NNet<br />dropout_loss: 0.31351215<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.31351215","tidytext::reorder_within(variable, dropout_loss, label): RDEF5___NNet<br />dropout_loss: 0.26012513<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.26012513","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___NNet<br />dropout_loss: 0.23736727<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.23736727","tidytext::reorder_within(variable, dropout_loss, label): treatment___NNet<br />dropout_loss: 0.23722367<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.23722367","tidytext::reorder_within(variable, dropout_loss, label): STYPE___NNet<br />dropout_loss: 0.22106546<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.22106546","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___NNet<br />dropout_loss: 0.21952719<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.21952719","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___NNet<br />dropout_loss: 0.21862754<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.21862754","tidytext::reorder_within(variable, dropout_loss, label): RCT___NNet<br />dropout_loss: 0.21478040<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.21478040","tidytext::reorder_within(variable, dropout_loss, label): SEX___NNet<br />dropout_loss: 0.20800618<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.20800618","tidytext::reorder_within(variable, dropout_loss, label): RDEF1___NNet<br />dropout_loss: 0.20351358<br />label: NNet<br />y_min: 0.18384806<br />dropout_loss: 0.20351358"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.129664097331706,0.0762770679363183,0.0535192115408882,0.0533756174299509,0.0372174003928613,0.0356791334271083,0.0347794836529909,0.0309323401718272,0.0241581207199104,0.0196655201611715],"type":"data","width":0,"symmetric":false,"color":"rgba(67,120,191,1)"},"name":"NNet","legendgroup":"NNet","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.230841379498692,0.0662435355727882,0.0633791667531642,0.058466466432681,0.0492462405704855,0.0486189160392983,0.0373913840670201,0.0331909043464118,0.0272081236518515,0.0230950985150989],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___RF<br />dropout_loss: 0.23084138<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.23084138","tidytext::reorder_within(variable, dropout_loss, label): RDELAY___RF<br />dropout_loss: 0.06624354<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.06624354","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___RF<br />dropout_loss: 0.06337917<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.06337917","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___RF<br />dropout_loss: 0.05846647<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.05846647","tidytext::reorder_within(variable, dropout_loss, label): treatment___RF<br />dropout_loss: 0.04924624<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.04924624","tidytext::reorder_within(variable, dropout_loss, label): RSBP___RF<br />dropout_loss: 0.04861892<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.04861892","tidytext::reorder_within(variable, dropout_loss, label): RCT___RF<br />dropout_loss: 0.03739138<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.03739138","tidytext::reorder_within(variable, dropout_loss, label): RDEF5___RF<br />dropout_loss: 0.03319090<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.03319090","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___RF<br />dropout_loss: 0.02720812<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.02720812","tidytext::reorder_within(variable, dropout_loss, label): RDEF1___RF<br />dropout_loss: 0.02309510<br />label: RF<br />y_min: 0.01443382<br />dropout_loss: 0.02309510"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.216407557669581,0.0518097137436772,0.0489453449240533,0.0440326446035701,0.0348124187413746,0.0341850942101873,0.0229575622379092,0.0187570825173009,0.0127743018227405,0.00866127668598792],"type":"data","width":0,"symmetric":false,"color":"rgba(240,90,113,1)"},"name":"RF","legendgroup":"RF","showlegend":true,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[0.263879289578054,0.216092800971382,0.210783976184667,0.209653586547059,0.207144018926847,0.204961149117557,0.203145641516709,0.202243894887147,0.199839561196875,0.199306247088579],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___XGB<br />dropout_loss: 0.26387929<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.26387929","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___XGB<br />dropout_loss: 0.21609280<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.21609280","tidytext::reorder_within(variable, dropout_loss, label): RCT___XGB<br />dropout_loss: 0.21078398<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.21078398","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___XGB<br />dropout_loss: 0.20965359<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.20965359","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___XGB<br />dropout_loss: 0.20714402<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.20714402","tidytext::reorder_within(variable, dropout_loss, label): treatment___XGB<br />dropout_loss: 0.20496115<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.20496115","tidytext::reorder_within(variable, dropout_loss, label): RSBP___XGB<br />dropout_loss: 0.20314564<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.20314564","tidytext::reorder_within(variable, dropout_loss, label): RDELAY___XGB<br />dropout_loss: 0.20224389<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.20224389","tidytext::reorder_within(variable, dropout_loss, label): RVISINF___XGB<br />dropout_loss: 0.19983956<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.19983956","tidytext::reorder_within(variable, dropout_loss, label): STYPE___XGB<br />dropout_loss: 0.19930625<br />label: XGB<br />y_min: 0.19636943<br />dropout_loss: 0.19930625"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.0675098632272298,0.0197233746205572,0.0144145498338424,0.0132841601962342,0.0107745925760227,0.00859172276673201,0.00677621516588398,0.0058744685363227,0.00347013484605005,0.00293682073775481],"type":"data","width":0,"symmetric":false,"color":"rgba(139,220,190,1)"},"name":"XGB","legendgroup":"XGB","showlegend":true,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"x":[0.203513577346436,0.204438987368274,0.205487519210477,0.190487821899644,0.199883516483517,0.208674760728553,0.215490407547699,0.205809006238939,0.198241223436499,0.198035717363948,0.208586813186813,0.207478913732486,0.220940659340659,0.210103296703297,0.208006177905175,0.201240682898354,0.223219609287318,0.201456050340549,0.204705056179775,0.207856264038425,0.203980710554895,0.199080535975993,0.21219989631563,0.225209999298541,0.210306010306886,0.214780397357092,0.223902313647076,0.205178309721544,0.224048351648352,0.22862796376799,0.20713959421489,0.208285714285714,0.202905820364296,0.21501978021978,0.210676338195268,0.234995352833894,0.217867604240097,0.218627540838256,0.210410269383767,0.232416761416853,0.222896703296703,0.221531373941357,0.206021291049179,0.214439933805658,0.219527190612373,0.232011959876543,0.223545781282713,0.213758241758242,0.228002197802198,0.223237834203858,0.219626249155683,0.214034483991491,0.207801922674297,0.205787443463184,0.227465791915522,0.221527993659995,0.192915154581618,0.222181563138475,0.224540659340659,0.221065457578126,0.233265210689482,0.219290208977636,0.218799020875351,0.228648351648352,0.2242698373927,0.225216575476992,0.237223674615216,0.232549629494099,0.245072654531599,0.234551648351648,0.229050352432131,0.232719327819397,0.249929854096521,0.239084091599778,0.227497557401075,0.250558241758242,0.231223388667666,0.228649612913282,0.238205902858471,0.231604395604396,0.244324790569416,0.250600943119475,0.243173708434607,0.237367268726153,0.227826373626374,0.235052166934189,0.225120385232745,0.249114407968575,0.269036361036129,0.262117026619789,0.260879120879121,0.261203616021324,0.260125125121583,0.258001692372112,0.274286412171121,0.246804821556016,0.258916412404544,0.270764835164835,0.239240952990839,0.31351215451697,0.336062447390572,0.318956810096713,0.306443651604635,0.320826645264847,0.307017351822095,0.304297891779145,0.337349450549451,0.306749450549451,0.294755849462647,0.30266199665015],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x","yaxis":"y","orientation":"h","frame":null},{"x":[0.0230950985150989,0.0217452300785634,0.0235075658804472,0.0228403565111964,0.023441931366988,0.0225866610100581,0.0251839460512043,0.0252591100048727,0.0187050988099138,0.024764418771078,0.0229166666666667,0.0259483140839073,0.0272356861289353,0.027717417547926,0.0272081236518515,0.027811226479373,0.0335219624397193,0.0239441332527953,0.0249372202205481,0.0261644219977554,0.02859375,0.0262071043675552,0.0293132438039088,0.033051066949372,0.0323133761114351,0.0331909043464118,0.0419645307578708,0.0339334237639323,0.0325439591605219,0.032122439674523,0.0344662087170411,0.0322528778588469,0.0299479166666666,0.0336281253411944,0.0353007724805996,0.0339992712874069,0.0427701614142292,0.037578125,0.0382029405336841,0.0350729517396184,0.0369504473772265,0.0373913840670201,0.0404223897957317,0.0399886557005105,0.0508514447769777,0.0494431326839762,0.0460361985785714,0.0486189160392983,0.0478570426487093,0.0424466599494441,0.0532574769862906,0.0430134294136915,0.0521137152777778,0.0491926049347703,0.051977455142774,0.0528596074205085,0.0492462405704855,0.0414810591999434,0.0599953822897744,0.0428974666262802,0.0506684027777778,0.0396287804345452,0.0540026311391462,0.0551084798638684,0.0460069444444444,0.0498136515085668,0.0546033040272264,0.0606183375371921,0.058466466432681,0.0634995791245792,0.0625859726858617,0.0597193139566021,0.0593461779902458,0.0513734952537519,0.059534414802776,0.0489049022819085,0.0644791666666666,0.061766568402664,0.0677925428202898,0.0633791667531642,0.063984375,0.0542017995085822,0.063401978976095,0.0597017546170089,0.0617112166761202,0.0688043630751964,0.070346023323793,0.0620810451318926,0.069293543869815,0.061146624137946,0.0728273609629542,0.0672348484848485,0.0662435355727882,0.0700594363191478,0.0657792115711855,0.0589540342832187,0.0676715985222111,0.0631188711876663,0.0663498263888889,0.230841379498692,0.254509457899288,0.198108963860683,0.223903941994952,0.248842181045571,0.237446712353174,0.234835069444444,0.233835753367003,0.215384207456117,0.246550875404594,0.214996632161089],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x2","yaxis":"y2","orientation":"h","frame":null},{"x":[0.199306247088579,0.20603821855584,0.191501139553088,0.194205209299894,0.206258325144666,0.191672714078374,0.199141600949124,0.189316860465116,0.206132992759847,0.190660660660661,0.218134749419184,0.203880158025723,0.191336801726412,0.199839561196875,0.194821687746216,0.199176495219485,0.193721639251276,0.209688544359845,0.196430716430716,0.21587786259542,0.202305928594825,0.191155778018828,0.210700919815414,0.193101271023349,0.194796224796225,0.198509142298835,0.210376094258515,0.205293154274484,0.202243894887147,0.196165077061303,0.223391968138068,0.196893065157634,0.193212032047646,0.19696419932269,0.206350038213779,0.203145641516709,0.198953238953239,0.207961943582875,0.194475301784789,0.224365527160084,0.201510049549864,0.194838343732274,0.208975095285334,0.197062677582158,0.19832594737944,0.204961149117557,0.21384813519205,0.196336336336336,0.200095894671366,0.206660115733159,0.197975751559841,0.222396282774643,0.214114071351332,0.199986161025122,0.199872795152276,0.207144018926847,0.199236379236379,0.209497206703911,0.222352030091824,0.217493847872232,0.203108579731956,0.206345670924773,0.205392265771005,0.202696454742131,0.198746809415769,0.206570944778492,0.222057324925796,0.226556034959619,0.209653586547059,0.212434083433405,0.199510446263693,0.207664526484751,0.198666091631054,0.20818646762043,0.205291938457175,0.203809523809524,0.21235942788514,0.202939917225632,0.210911736389735,0.217433300266277,0.207341754483914,0.224170815355681,0.216999897649954,0.210783976184667,0.20014341004907,0.204791193987521,0.208219648219648,0.214888088219238,0.236530589666999,0.214371514371514,0.228414152786369,0.20087272035324,0.216092800971382,0.196761557005105,0.225765328321064,0.210364470653919,0.214366306398142,0.216556392619282,0.216924977538185,0.263879289578054,0.253997085165916,0.285752848766456,0.264560274560275,0.261207991785447,0.25281335054784,0.265544475955234,0.274741784037559,0.25861186637534,0.261122917962541,0.260440300623936],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x3","yaxis":"y3","orientation":"h","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":43.8356164383562,"l":69.3399750933998},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.29645862647108],"automargin":true,"type":"linear","autorange":false,"range":[0.176172987517055,0.34502452021766],"tickmode":"array","ticktext":["0.20","0.25","0.30"],"tickvals":[0.2,0.25,0.3],"categoryorder":"array","categoryarray":["0.20","0.25","0.30"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"annotations":[{"text":"One minus AUC loss after permutations","x":0.5,"y":0,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis","yshift":-23.9103362391034},{"text":"NNet","x":0.14822931323554,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RF","x":0.5,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"XGB","x":0.85177068676446,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["RDEF1","SEX","RCT","RDEF6","RCONSC","STYPE","treatment","RDEF3","RDEF5","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["RDEF1","SEX","RCT","RDEF6","RCONSC","STYPE","treatment","RDEF3","RDEF5","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.29645862647108,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.29645862647108,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.370208040195587,"x1":0.629791959804413,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.370208040195587,"x1":0.629791959804413,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.70354137352892,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.70354137352892,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[0.00243004002560209,0.266513239702797],"tickmode":"array","ticktext":["0.05","0.10","0.15","0.20","0.25"],"tickvals":[0.05,0.1,0.15,0.2,0.25],"categoryorder":"array","categoryarray":["0.05","0.10","0.15","0.20","0.25"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.370208040195587,0.629791959804413],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["RDEF1","RCONSC","RDEF5","RCT","RSBP","treatment","RDEF6","RDEF3","RDELAY","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["RDEF1","RCONSC","RDEF5","RCT","RSBP","treatment","RDEF6","RDEF3","RDELAY","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"xaxis3":{"type":"linear","autorange":false,"range":[0.184495061050049,0.290574648181523],"tickmode":"array","ticktext":["0.21","0.24","0.27"],"tickvals":[0.21,0.24,0.27],"categoryorder":"array","categoryarray":["0.21","0.24","0.27"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.70354137352892,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y3","title":"","hoverformat":".2f"},"yaxis3":{"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["STYPE","RVISINF","RDELAY","RSBP","treatment","RCONSC","RDEF6","RCT","RDEF3","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["STYPE","RVISINF","RDELAY","RSBP","treatment","RCONSC","RDEF6","RCT","RDEF3","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x3","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"29886e743b4":{"x":{},"y":{},"colour":{},"ymin":{},"ymax":{},"type":"scatter"},"29886b23116e":{"x":{},"y":{},"colour":{}}},"cur_data":"29886e743b4","visdat":{"29886e743b4":["function (y) ","x"],"29886b23116e":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="global-interpretation" class="section level2">
<h2>Global interpretation</h2>
<div id="random-forest-10" class="section level3">
<h3>Random forest</h3>
<p>Create PDP for age and blood pressure using random forest
explainer:</p>
<pre class="r"><code>pdp_age_rf &lt;- model_profile(explainer_rf, &quot;AGE&quot;)
pdp_rsbp_rf &lt;- model_profile(explainer_rf, &quot;RSBP&quot;)</code></pre>
</div>
<div id="neural-network-10" class="section level3">
<h3>Neural network</h3>
<p>Create PDP for age and blood pressure using neural network
explainer:</p>
<pre class="r"><code>pdp_age_nnet &lt;- model_profile(explainer_nnet, &quot;AGE&quot;)
pdp_rsbp_nnet &lt;- model_profile(explainer_nnet, &quot;RSBP&quot;)</code></pre>
</div>
<div id="xgboost-10" class="section level3">
<h3>XGBoost</h3>
<p>Create PDP for age and blood pressure using XGBoost explainer:</p>
<pre class="r"><code>pdp_age_xgb &lt;- model_profile(explainer_xgb, &quot;AGE&quot;)
pdp_rsbp_xgb &lt;- model_profile(explainer_xgb, &quot;RSBP&quot;)</code></pre>
<p>Create PDP profiles for age and blood pressure:</p>
<pre class="r"><code>pdp_age_rsbp &lt;- plot_pdp(
  pdp_age_rf, pdp_rsbp_rf, pdp_age_nnet, pdp_rsbp_nnet, pdp_age_xgb, 
  pdp_rsbp_xgb
)
pdp_age_rsbp</code></pre>
<p><img src="figure/tlverse.Rmd/pdp-age-rsbp-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>pdp_age_rsbp2 &lt;- ggplotly(pdp_age_rsbp) %&gt;%
  layout(legend = list(orientation = &quot;h&quot;, xanchor = &quot;center&quot;, x = 0.5, y = 1))
pdp_age_rsbp2</code></pre>
<div id="htmlwidget-5c89bfca271851966cab" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-5c89bfca271851966cab">{"x":{"data":[{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.378463015091025,0.440780651587703,0.447278797329578,0.453591551917222,0.458477121759816,0.476770347596057,0.484209724663302,0.48805077453205,0.501160199350347,0.506713329960017,0.511902730016994,0.517738400950698,0.523412608046799,0.526033724732703,0.527934699670299,0.530490094429513,0.532919672481946,0.536183131409241,0.542588941238095,0.548330617651797,0.552614590695273,0.557946360632927,0.563180460945706,0.567535168991466,0.5720069778006,0.577224209270759,0.582659562200102,0.589660967433941,0.595670494886981,0.603669600707294,0.612330732043704,0.618620061742242,0.624782168292288,0.632112687559201,0.638782907043599,0.644225882418898,0.648529631052267,0.652987193814145,0.65635968082949,0.65726585229675,0.657985911993766,0.65924932733231,0.660549046849246,0.661172422149591,0.662011703086574,0.664781691186454],"text":["_x_:  22.00<br />_yhat_: 0.3784630<br />_label_: NNet","_x_:  41.00<br />_yhat_: 0.4407807<br />_label_: NNet","_x_:  44.00<br />_yhat_: 0.4472788<br />_label_: NNet","_x_:  46.00<br />_yhat_: 0.4535916<br />_label_: NNet","_x_:  48.00<br />_yhat_: 0.4584771<br />_label_: NNet","_x_:  51.00<br />_yhat_: 0.4767703<br />_label_: NNet","_x_:  52.00<br />_yhat_: 0.4842097<br />_label_: NNet","_x_:  53.00<br />_yhat_: 0.4880508<br />_label_: NNet","_x_:  55.00<br />_yhat_: 0.5011602<br />_label_: NNet","_x_:  56.00<br />_yhat_: 0.5067133<br />_label_: NNet","_x_:  57.00<br />_yhat_: 0.5119027<br />_label_: NNet","_x_:  58.00<br />_yhat_: 0.5177384<br />_label_: NNet","_x_:  59.23<br />_yhat_: 0.5234126<br />_label_: NNet","_x_:  60.00<br />_yhat_: 0.5260337<br />_label_: NNet","_x_:  61.00<br />_yhat_: 0.5279347<br />_label_: NNet","_x_:  62.00<br />_yhat_: 0.5304901<br />_label_: NNet","_x_:  63.00<br />_yhat_: 0.5329197<br />_label_: NNet","_x_:  64.00<br />_yhat_: 0.5361831<br />_label_: NNet","_x_:  65.00<br />_yhat_: 0.5425889<br />_label_: NNet","_x_:  66.00<br />_yhat_: 0.5483306<br />_label_: NNet","_x_:  67.00<br />_yhat_: 0.5526146<br />_label_: NNet","_x_:  68.00<br />_yhat_: 0.5579464<br />_label_: NNet","_x_:  69.00<br />_yhat_: 0.5631805<br />_label_: NNet","_x_:  70.00<br />_yhat_: 0.5675352<br />_label_: NNet","_x_:  71.00<br />_yhat_: 0.5720070<br />_label_: NNet","_x_:  72.00<br />_yhat_: 0.5772242<br />_label_: NNet","_x_:  73.00<br />_yhat_: 0.5826596<br />_label_: NNet","_x_:  74.00<br />_yhat_: 0.5896610<br />_label_: NNet","_x_:  75.00<br />_yhat_: 0.5956705<br />_label_: NNet","_x_:  76.00<br />_yhat_: 0.6036696<br />_label_: NNet","_x_:  77.00<br />_yhat_: 0.6123307<br />_label_: NNet","_x_:  78.00<br />_yhat_: 0.6186201<br />_label_: NNet","_x_:  79.00<br />_yhat_: 0.6247822<br />_label_: NNet","_x_:  80.00<br />_yhat_: 0.6321127<br />_label_: NNet","_x_:  81.00<br />_yhat_: 0.6387829<br />_label_: NNet","_x_:  82.00<br />_yhat_: 0.6442259<br />_label_: NNet","_x_:  83.00<br />_yhat_: 0.6485296<br />_label_: NNet","_x_:  84.00<br />_yhat_: 0.6529872<br />_label_: NNet","_x_:  85.00<br />_yhat_: 0.6563597<br />_label_: NNet","_x_:  86.00<br />_yhat_: 0.6572659<br />_label_: NNet","_x_:  87.00<br />_yhat_: 0.6579859<br />_label_: NNet","_x_:  88.00<br />_yhat_: 0.6592493<br />_label_: NNet","_x_:  89.00<br />_yhat_: 0.6605490<br />_label_: NNet","_x_:  90.00<br />_yhat_: 0.6611724<br />_label_: NNet","_x_:  91.29<br />_yhat_: 0.6620117<br />_label_: NNet","_x_:  94.00<br />_yhat_: 0.6647817<br />_label_: NNet"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"NNet","legendgroup":"NNet","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.553585624727544,0.554985782207626,0.55575980936673,0.555819883204764,0.555373215793973,0.554526610518703,0.553988676765109,0.553840531826077,0.553901658222727,0.553687733588123,0.553292536811162,0.55317427260744,0.552864166397213,0.5530642375281,0.553277667797582,0.554112563342699,0.55499060230797,0.555713418243728,0.555839492043975,0.555601879509959,0.553894990361565,0.551914906076365,0.550742192773154,0.550257117874841,0.551167999721914,0.551189434439074,0.551731169652004,0.551750789554219,0.555279318100528],"text":["_x_:  90.00<br />_yhat_: 0.5535856<br />_label_: NNet","_x_: 104.13<br />_yhat_: 0.5549858<br />_label_: NNet","_x_: 110.00<br />_yhat_: 0.5557598<br />_label_: NNet","_x_: 115.84<br />_yhat_: 0.5558199<br />_label_: NNet","_x_: 120.00<br />_yhat_: 0.5553732<br />_label_: NNet","_x_: 126.10<br />_yhat_: 0.5545266<br />_label_: NNet","_x_: 130.00<br />_yhat_: 0.5539887<br />_label_: NNet","_x_: 135.00<br />_yhat_: 0.5538405<br />_label_: NNet","_x_: 140.00<br />_yhat_: 0.5539017<br />_label_: NNet","_x_: 142.01<br />_yhat_: 0.5536877<br />_label_: NNet","_x_: 145.00<br />_yhat_: 0.5532925<br />_label_: NNet","_x_: 146.00<br />_yhat_: 0.5531743<br />_label_: NNet","_x_: 150.00<br />_yhat_: 0.5528642<br />_label_: NNet","_x_: 154.32<br />_yhat_: 0.5530642<br />_label_: NNet","_x_: 155.74<br />_yhat_: 0.5532777<br />_label_: NNet","_x_: 160.00<br />_yhat_: 0.5541126<br />_label_: NNet","_x_: 165.00<br />_yhat_: 0.5549906<br />_label_: NNet","_x_: 170.00<br />_yhat_: 0.5557134<br />_label_: NNet","_x_: 172.12<br />_yhat_: 0.5558395<br />_label_: NNet","_x_: 175.00<br />_yhat_: 0.5556019<br />_label_: NNet","_x_: 180.00<br />_yhat_: 0.5538950<br />_label_: NNet","_x_: 185.00<br />_yhat_: 0.5519149<br />_label_: NNet","_x_: 190.00<br />_yhat_: 0.5507422<br />_label_: NNet","_x_: 200.00<br />_yhat_: 0.5502571<br />_label_: NNet","_x_: 209.74<br />_yhat_: 0.5511680<br />_label_: NNet","_x_: 210.00<br />_yhat_: 0.5511894<br />_label_: NNet","_x_: 220.00<br />_yhat_: 0.5517312<br />_label_: NNet","_x_: 232.32<br />_yhat_: 0.5517508<br />_label_: NNet","_x_: 270.00<br />_yhat_: 0.5552793<br />_label_: NNet"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"NNet","legendgroup":"NNet","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.239675385919636,0.241565190809191,0.242252344433345,0.323430224553225,0.488008608946609,0.512757232628483,0.497859151154401,0.488236198995449,0.50074524975025,0.506116336469087,0.507865481795982,0.543439313741814,0.547296585442336,0.544870034243534,0.546758787656788,0.543098243728494,0.540817298673549,0.5434249996115,0.55552727025752,0.585911362914863,0.598407768093018,0.590260938949939,0.605329460816961,0.604824511516262,0.599789908535909,0.590368396076146,0.593230643661894,0.648484418831169,0.679682603646354,0.680130309163059,0.71742480011655,0.724153066544567,0.732665695554446,0.718422788739039,0.720324340437341,0.721992118853369,0.789201798007548,0.815428258907759,0.821433884199134,0.85290034992785,0.858872758297258,0.86002023959374,0.862397875152625,0.858499666111666,0.851784693639694,0.852353355977356],"text":["_x_:  22.00<br />_yhat_: 0.2396754<br />_label_: RF","_x_:  41.00<br />_yhat_: 0.2415652<br />_label_: RF","_x_:  44.00<br />_yhat_: 0.2422523<br />_label_: RF","_x_:  46.00<br />_yhat_: 0.3234302<br />_label_: RF","_x_:  48.00<br />_yhat_: 0.4880086<br />_label_: RF","_x_:  51.00<br />_yhat_: 0.5127572<br />_label_: RF","_x_:  52.00<br />_yhat_: 0.4978592<br />_label_: RF","_x_:  53.00<br />_yhat_: 0.4882362<br />_label_: RF","_x_:  55.00<br />_yhat_: 0.5007452<br />_label_: RF","_x_:  56.00<br />_yhat_: 0.5061163<br />_label_: RF","_x_:  57.00<br />_yhat_: 0.5078655<br />_label_: RF","_x_:  58.00<br />_yhat_: 0.5434393<br />_label_: RF","_x_:  59.23<br />_yhat_: 0.5472966<br />_label_: RF","_x_:  60.00<br />_yhat_: 0.5448700<br />_label_: RF","_x_:  61.00<br />_yhat_: 0.5467588<br />_label_: RF","_x_:  62.00<br />_yhat_: 0.5430982<br />_label_: RF","_x_:  63.00<br />_yhat_: 0.5408173<br />_label_: RF","_x_:  64.00<br />_yhat_: 0.5434250<br />_label_: RF","_x_:  65.00<br />_yhat_: 0.5555273<br />_label_: RF","_x_:  66.00<br />_yhat_: 0.5859114<br />_label_: RF","_x_:  67.00<br />_yhat_: 0.5984078<br />_label_: RF","_x_:  68.00<br />_yhat_: 0.5902609<br />_label_: RF","_x_:  69.00<br />_yhat_: 0.6053295<br />_label_: RF","_x_:  70.00<br />_yhat_: 0.6048245<br />_label_: RF","_x_:  71.00<br />_yhat_: 0.5997899<br />_label_: RF","_x_:  72.00<br />_yhat_: 0.5903684<br />_label_: RF","_x_:  73.00<br />_yhat_: 0.5932306<br />_label_: RF","_x_:  74.00<br />_yhat_: 0.6484844<br />_label_: RF","_x_:  75.00<br />_yhat_: 0.6796826<br />_label_: RF","_x_:  76.00<br />_yhat_: 0.6801303<br />_label_: RF","_x_:  77.00<br />_yhat_: 0.7174248<br />_label_: RF","_x_:  78.00<br />_yhat_: 0.7241531<br />_label_: RF","_x_:  79.00<br />_yhat_: 0.7326657<br />_label_: RF","_x_:  80.00<br />_yhat_: 0.7184228<br />_label_: RF","_x_:  81.00<br />_yhat_: 0.7203243<br />_label_: RF","_x_:  82.00<br />_yhat_: 0.7219921<br />_label_: RF","_x_:  83.00<br />_yhat_: 0.7892018<br />_label_: RF","_x_:  84.00<br />_yhat_: 0.8154283<br />_label_: RF","_x_:  85.00<br />_yhat_: 0.8214339<br />_label_: RF","_x_:  86.00<br />_yhat_: 0.8529003<br />_label_: RF","_x_:  87.00<br />_yhat_: 0.8588728<br />_label_: RF","_x_:  88.00<br />_yhat_: 0.8600202<br />_label_: RF","_x_:  89.00<br />_yhat_: 0.8623979<br />_label_: RF","_x_:  90.00<br />_yhat_: 0.8584997<br />_label_: RF","_x_:  91.29<br />_yhat_: 0.8517847<br />_label_: RF","_x_:  94.00<br />_yhat_: 0.8523534<br />_label_: RF"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"RF","legendgroup":"RF","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.598178016455767,0.606361857725608,0.615315291486292,0.639868997141747,0.649192170523921,0.644362276556777,0.648429924075924,0.642180405649906,0.628226754551005,0.628346873820624,0.619344212620713,0.616469811632812,0.607829944860695,0.610939002775003,0.610450827755578,0.610641849261849,0.611676955766456,0.61097001029526,0.612625652292152,0.613407449023199,0.614522015318015,0.60419554040404,0.611431847263847,0.600972446830947,0.60516607012432,0.60516607012432,0.596953293872794,0.595399484515485,0.597750312271062],"text":["_x_:  90.00<br />_yhat_: 0.5981780<br />_label_: RF","_x_: 104.13<br />_yhat_: 0.6063619<br />_label_: RF","_x_: 110.00<br />_yhat_: 0.6153153<br />_label_: RF","_x_: 115.84<br />_yhat_: 0.6398690<br />_label_: RF","_x_: 120.00<br />_yhat_: 0.6491922<br />_label_: RF","_x_: 126.10<br />_yhat_: 0.6443623<br />_label_: RF","_x_: 130.00<br />_yhat_: 0.6484299<br />_label_: RF","_x_: 135.00<br />_yhat_: 0.6421804<br />_label_: RF","_x_: 140.00<br />_yhat_: 0.6282268<br />_label_: RF","_x_: 142.01<br />_yhat_: 0.6283469<br />_label_: RF","_x_: 145.00<br />_yhat_: 0.6193442<br />_label_: RF","_x_: 146.00<br />_yhat_: 0.6164698<br />_label_: RF","_x_: 150.00<br />_yhat_: 0.6078299<br />_label_: RF","_x_: 154.32<br />_yhat_: 0.6109390<br />_label_: RF","_x_: 155.74<br />_yhat_: 0.6104508<br />_label_: RF","_x_: 160.00<br />_yhat_: 0.6106418<br />_label_: RF","_x_: 165.00<br />_yhat_: 0.6116770<br />_label_: RF","_x_: 170.00<br />_yhat_: 0.6109700<br />_label_: RF","_x_: 172.12<br />_yhat_: 0.6126257<br />_label_: RF","_x_: 175.00<br />_yhat_: 0.6134074<br />_label_: RF","_x_: 180.00<br />_yhat_: 0.6145220<br />_label_: RF","_x_: 185.00<br />_yhat_: 0.6041955<br />_label_: RF","_x_: 190.00<br />_yhat_: 0.6114318<br />_label_: RF","_x_: 200.00<br />_yhat_: 0.6009724<br />_label_: RF","_x_: 209.74<br />_yhat_: 0.6051661<br />_label_: RF","_x_: 210.00<br />_yhat_: 0.6051661<br />_label_: RF","_x_: 220.00<br />_yhat_: 0.5969533<br />_label_: RF","_x_: 232.32<br />_yhat_: 0.5953995<br />_label_: RF","_x_: 270.00<br />_yhat_: 0.5977503<br />_label_: RF"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"RF","legendgroup":"RF","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.46741163097322,0.46741163097322,0.46741163097322,0.46741163097322,0.46741163097322,0.471806282773614,0.471806282773614,0.484810183867812,0.50085599668324,0.506366963237524,0.506366963237524,0.547144485339522,0.546371698901057,0.550832294523716,0.550832294523716,0.551270380690694,0.547625963836908,0.557702874317765,0.568247789889574,0.595108512938023,0.606000116951764,0.606001876927912,0.624958959631622,0.625778848230839,0.622583366334438,0.615479668080807,0.630057750754058,0.659369508214295,0.680354802533984,0.684948033094406,0.707927306853235,0.715180313810706,0.721635020077229,0.721112883128226,0.722122949175537,0.739465508647263,0.7881327399984,0.803589175418019,0.805103188119829,0.812970587667078,0.815292222835124,0.815292222835124,0.815292222835124,0.815292222835124,0.815292222835124,0.815292222835124],"text":["_x_:  22.00<br />_yhat_: 0.4674116<br />_label_: XGB","_x_:  41.00<br />_yhat_: 0.4674116<br />_label_: XGB","_x_:  44.00<br />_yhat_: 0.4674116<br />_label_: XGB","_x_:  46.00<br />_yhat_: 0.4674116<br />_label_: XGB","_x_:  48.00<br />_yhat_: 0.4674116<br />_label_: XGB","_x_:  51.00<br />_yhat_: 0.4718063<br />_label_: XGB","_x_:  52.00<br />_yhat_: 0.4718063<br />_label_: XGB","_x_:  53.00<br />_yhat_: 0.4848102<br />_label_: XGB","_x_:  55.00<br />_yhat_: 0.5008560<br />_label_: XGB","_x_:  56.00<br />_yhat_: 0.5063670<br />_label_: XGB","_x_:  57.00<br />_yhat_: 0.5063670<br />_label_: XGB","_x_:  58.00<br />_yhat_: 0.5471445<br />_label_: XGB","_x_:  59.23<br />_yhat_: 0.5463717<br />_label_: XGB","_x_:  60.00<br />_yhat_: 0.5508323<br />_label_: XGB","_x_:  61.00<br />_yhat_: 0.5508323<br />_label_: XGB","_x_:  62.00<br />_yhat_: 0.5512704<br />_label_: XGB","_x_:  63.00<br />_yhat_: 0.5476260<br />_label_: XGB","_x_:  64.00<br />_yhat_: 0.5577029<br />_label_: XGB","_x_:  65.00<br />_yhat_: 0.5682478<br />_label_: XGB","_x_:  66.00<br />_yhat_: 0.5951085<br />_label_: XGB","_x_:  67.00<br />_yhat_: 0.6060001<br />_label_: XGB","_x_:  68.00<br />_yhat_: 0.6060019<br />_label_: XGB","_x_:  69.00<br />_yhat_: 0.6249590<br />_label_: XGB","_x_:  70.00<br />_yhat_: 0.6257788<br />_label_: XGB","_x_:  71.00<br />_yhat_: 0.6225834<br />_label_: XGB","_x_:  72.00<br />_yhat_: 0.6154797<br />_label_: XGB","_x_:  73.00<br />_yhat_: 0.6300578<br />_label_: XGB","_x_:  74.00<br />_yhat_: 0.6593695<br />_label_: XGB","_x_:  75.00<br />_yhat_: 0.6803548<br />_label_: XGB","_x_:  76.00<br />_yhat_: 0.6849480<br />_label_: XGB","_x_:  77.00<br />_yhat_: 0.7079273<br />_label_: XGB","_x_:  78.00<br />_yhat_: 0.7151803<br />_label_: XGB","_x_:  79.00<br />_yhat_: 0.7216350<br />_label_: XGB","_x_:  80.00<br />_yhat_: 0.7211129<br />_label_: XGB","_x_:  81.00<br />_yhat_: 0.7221229<br />_label_: XGB","_x_:  82.00<br />_yhat_: 0.7394655<br />_label_: XGB","_x_:  83.00<br />_yhat_: 0.7881327<br />_label_: XGB","_x_:  84.00<br />_yhat_: 0.8035892<br />_label_: XGB","_x_:  85.00<br />_yhat_: 0.8051032<br />_label_: XGB","_x_:  86.00<br />_yhat_: 0.8129706<br />_label_: XGB","_x_:  87.00<br />_yhat_: 0.8152922<br />_label_: XGB","_x_:  88.00<br />_yhat_: 0.8152922<br />_label_: XGB","_x_:  89.00<br />_yhat_: 0.8152922<br />_label_: XGB","_x_:  90.00<br />_yhat_: 0.8152922<br />_label_: XGB","_x_:  91.29<br />_yhat_: 0.8152922<br />_label_: XGB","_x_:  94.00<br />_yhat_: 0.8152922<br />_label_: XGB"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGB","legendgroup":"XGB","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.687390157673508,0.687390157673508,0.687390157673508,0.687390157673508,0.687390157673508,0.67717519229278,0.681627038251609,0.667013648618013,0.643514736574143,0.644418652057648,0.641272418703884,0.638659270275384,0.618311956115067,0.622060884274542,0.621338807232678,0.619198077693582,0.621948344130069,0.619333541374654,0.619856650009751,0.622063481025398,0.628475185409188,0.625091457366943,0.629581732004881,0.631479295473546,0.637448161970824,0.637448161970824,0.637448161970824,0.637448161970824,0.637448161970824],"text":["_x_:  90.00<br />_yhat_: 0.6873902<br />_label_: XGB","_x_: 104.13<br />_yhat_: 0.6873902<br />_label_: XGB","_x_: 110.00<br />_yhat_: 0.6873902<br />_label_: XGB","_x_: 115.84<br />_yhat_: 0.6873902<br />_label_: XGB","_x_: 120.00<br />_yhat_: 0.6873902<br />_label_: XGB","_x_: 126.10<br />_yhat_: 0.6771752<br />_label_: XGB","_x_: 130.00<br />_yhat_: 0.6816270<br />_label_: XGB","_x_: 135.00<br />_yhat_: 0.6670136<br />_label_: XGB","_x_: 140.00<br />_yhat_: 0.6435147<br />_label_: XGB","_x_: 142.01<br />_yhat_: 0.6444187<br />_label_: XGB","_x_: 145.00<br />_yhat_: 0.6412724<br />_label_: XGB","_x_: 146.00<br />_yhat_: 0.6386593<br />_label_: XGB","_x_: 150.00<br />_yhat_: 0.6183120<br />_label_: XGB","_x_: 154.32<br />_yhat_: 0.6220609<br />_label_: XGB","_x_: 155.74<br />_yhat_: 0.6213388<br />_label_: XGB","_x_: 160.00<br />_yhat_: 0.6191981<br />_label_: XGB","_x_: 165.00<br />_yhat_: 0.6219483<br />_label_: XGB","_x_: 170.00<br />_yhat_: 0.6193335<br />_label_: XGB","_x_: 172.12<br />_yhat_: 0.6198567<br />_label_: XGB","_x_: 175.00<br />_yhat_: 0.6220635<br />_label_: XGB","_x_: 180.00<br />_yhat_: 0.6284752<br />_label_: XGB","_x_: 185.00<br />_yhat_: 0.6250915<br />_label_: XGB","_x_: 190.00<br />_yhat_: 0.6295817<br />_label_: XGB","_x_: 200.00<br />_yhat_: 0.6314793<br />_label_: XGB","_x_: 209.74<br />_yhat_: 0.6374482<br />_label_: XGB","_x_: 210.00<br />_yhat_: 0.6374482<br />_label_: XGB","_x_: 220.00<br />_yhat_: 0.6374482<br />_label_: XGB","_x_: 232.32<br />_yhat_: 0.6374482<br />_label_: XGB","_x_: 270.00<br />_yhat_: 0.6374482<br />_label_: XGB"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGB","legendgroup":"XGB","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":27.8953922789539,"l":47.0236612702366},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.480915721887079],"automargin":true,"type":"linear","autorange":false,"range":[18.4,97.6],"tickmode":"array","ticktext":["20","40","60","80"],"tickvals":[20,40,60,80],"categoryorder":"array","categoryarray":["20","40","60","80"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.208539261457987,0.893533999614275],"tickmode":"array","ticktext":["0.4","0.6","0.8"],"tickvals":[0.4,0.6,0.8],"categoryorder":"array","categoryarray":["0.4","0.6","0.8"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"annotations":[{"text":"Average prediction","x":0,"y":0.5,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-90,"xanchor":"right","yanchor":"center","annotationType":"axis","xshift":-30.2864259028643},{"text":"AGE","x":0.24045786094354,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RSBP","x":0.75954213905646,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.480915721887079,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.480915721887079,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.519084278112921,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.519084278112921,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[81,279],"tickmode":"array","ticktext":["100","150","200","250"],"tickvals":[100,150,200,250],"categoryorder":"array","categoryarray":["100","150","200","250"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.519084278112921,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.543400465884907,0.694246809663441],"tickmode":"array","ticktext":["0.55","0.60","0.65"],"tickvals":[0.55,0.6,0.65],"categoryorder":"array","categoryarray":["0.55","0.60","0.65"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"title":{"text":"Model","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"orientation":"h","xanchor":"center","x":0.5,"y":1},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"2988517c36b6":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"2988517c36b6","visdat":{"2988517c36b6":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>export(pdp_age_rsbp2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;pdp-age-rsbp.rds&quot;))</code></pre>
</div>
</div>
<div id="local-interpretation" class="section level2">
<h2>Local interpretation</h2>
<p>Find oldest and youngest patients in the training data:</p>
<pre class="r"><code>train_oldest &lt;- ist_train %&gt;% slice_max(AGE, with_ties = FALSE)
train_youngest &lt;- ist_train %&gt;% slice_min(AGE, with_ties = FALSE)</code></pre>
<div id="random-forest-11" class="section level3">
<h3>Random forest</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_rf &lt;- predict_parts(
  explainer_rf, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_rf &lt;- predict_parts(
  explainer_rf, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
</div>
<div id="neural-network-11" class="section level3">
<h3>Neural network</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_nnet &lt;- predict_parts(
  explainer_nnet, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_nnet &lt;- predict_parts(
  explainer_nnet, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
</div>
<div id="xgboost-11" class="section level3">
<h3>XGBoost</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_xgb &lt;- predict_parts(
  explainer_xgb, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_xgb &lt;- predict_parts(
  explainer_xgb, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
<p>Create local profile for the oldest patient in the training data:</p>
<pre class="r"><code>local_profile_old &lt;- plot_local(
  local_old_rf, local_old_nnet, local_old_xgb
)
local_profile_old</code></pre>
<p><img src="figure/tlverse.Rmd/local-profile-old-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>local_profile_old2 &lt;- ggplotly(local_profile_old)
local_profile_old2</code></pre>
<div id="htmlwidget-97430cc282ecedb9dc8b" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-97430cc282ecedb9dc8b">{"x":{"data":[{"orientation":"v","width":[0.00172124255572469,0.0104012394551516,0.00550673535392438,0.00116733333969611,0.00395918574588996,0.00348271927417435,0.00964742911658462],"base":[3.55,11.55,6.55,19.55,15.55,5.55,8.55],"x":[-0.000860621277862347,-0.00520061972757578,-0.00275336767696219,-0.000583666669848054,-0.00197959287294498,-0.00174135963708718,-0.00482371455829231],"y":[0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.9,0.899999999999999],"text":["mean_val: -1.721243e-03<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -1.040124e-02<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val: -5.506735e-03<br />variable: RDEF4 = C<br />mean_val > 0: FALSE","mean_val: -1.167333e-03<br />variable: RDEF6 = C<br />mean_val > 0: FALSE","mean_val: -3.959186e-03<br />variable: RDELAY = 8<br />mean_val > 0: FALSE","mean_val: -3.482719e-03<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -9.647429e-03<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.000244079269855524,0.00427096551781956,0.00737542060668515,7.07825392537609e-05,0.00111584881621051,0.000399824262937437],"base":[3.55,11.55,9.55,12.55,5.55,8.55],"x":[-0.000122039634927762,-0.00213548275890978,-0.00368771030334258,-3.53912696268804e-05,-0.000557924408105254,-0.000199912131468719],"y":[0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999],"text":["mean_val: -2.440793e-04<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -4.270966e-03<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val: -7.375421e-03<br />variable: RDEF7 = C<br />mean_val > 0: FALSE","mean_val: -7.078254e-05<br />variable: RDEF8 = C<br />mean_val > 0: FALSE","mean_val: -1.115849e-03<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -3.998243e-04<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.00344991643156901,0.0195999109173335,0.00181879983154606,0,0.00745219358809173,0.00684336767798023],"base":[3.55,11.55,9.55,0.55,5.55,8.55],"x":[-0.00172495821578451,-0.00979995545866674,-0.000909399915773029,0,-0.00372609679404587,-0.00342168383899011],"y":[0.9,0.899999999999999,0.899999999999999,0.9,0.9,0.899999999999999],"text":["mean_val: -3.449916e-03<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -1.959991e-02<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val: -1.818800e-03<br />variable: RDEF7 = C<br />mean_val > 0: FALSE","mean_val:  0.000000e+00<br />variable: RHEP24 = N<br />mean_val > 0: FALSE","mean_val: -7.452194e-03<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -6.843368e-03<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.0574883111447828,0.000916359601579497,0.0327997154383949,0.00117130336765541,0.00142961840163158,0.012130930215941,0.0260457455730816,0.0157396566595174,0.0154630651176513,0.000148106051563024,0.000857517805671348,0.00141207574835534,0.00784913192853759,0.0110951892131494],"base":[20.55,1.55,18.55,7.55,4.55,16.55,17.55,9.55,12.55,0.55,14.55,2.55,13.55,10.55],"x":[0.0287441555723914,0.000458179800789749,0.0163998577191974,0.000585651683827706,0.000714809200815789,0.00606546510797049,0.0130228727865408,0.00786982832975871,0.00773153255882565,7.4053025781512e-05,0.000428758902835674,0.00070603787417767,0.00392456596426879,0.0055475946065747],"y":[0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  5.748831e-02<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  9.163596e-04<br />variable: RASP3 = N<br />mean_val > 0:  TRUE","mean_val:  3.279972e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  1.171303e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  1.429618e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  1.213093e-02<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  2.604575e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  1.573966e-02<br />variable: RDEF7 = C<br />mean_val > 0:  TRUE","mean_val:  1.546307e-02<br />variable: RDEF8 = C<br />mean_val > 0:  TRUE","mean_val:  1.481061e-04<br />variable: RHEP24 = N<br />mean_val > 0:  TRUE","mean_val:  8.575178e-04<br />variable: RSBP = 130<br />mean_val > 0:  TRUE","mean_val:  1.412076e-03<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  7.849132e-03<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  1.109519e-02<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.180904657254897,0.000462499381995535,0.0175274300209832,0.00648291615444405,0.00613240477543592,0.0228894683756072,3.01687046958654e-05,0.0216343672435436,0.0555870648110999,0.0163813746284692,0.00102440102202218,0.0129528259475381,0.00161789639953905,0.0129193890874877,0.00556038733001287],"base":[20.55,1.55,18.55,7.55,4.55,16.55,6.55,17.55,19.55,15.55,0.55,14.55,2.55,13.55,10.55],"x":[0.0904523286274485,0.000231249690997767,0.00876371501049158,0.00324145807722203,0.00306620238771796,0.0114447341878036,1.50843523479327e-05,0.0108171836217718,0.02779353240555,0.00819068731423462,0.000512200511011088,0.00647641297376905,0.000808948199769527,0.00645969454374383,0.00278019366500643],"y":[0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  1.809047e-01<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  4.624994e-04<br />variable: RASP3 = N<br />mean_val > 0:  TRUE","mean_val:  1.752743e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  6.482916e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  6.132405e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  2.288947e-02<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  3.016870e-05<br />variable: RDEF4 = C<br />mean_val > 0:  TRUE","mean_val:  2.163437e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  5.558706e-02<br />variable: RDEF6 = C<br />mean_val > 0:  TRUE","mean_val:  1.638137e-02<br />variable: RDELAY = 8<br />mean_val > 0:  TRUE","mean_val:  1.024401e-03<br />variable: RHEP24 = N<br />mean_val > 0:  TRUE","mean_val:  1.295283e-02<br />variable: RSBP = 130<br />mean_val > 0:  TRUE","mean_val:  1.617896e-03<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  1.291939e-02<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  5.560387e-03<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.11186137765479,0.000125547664229153,0.0508086278065279,0.00781901603294454,0.0028979525133647,0.0205005336959463,0.00635306276106098,0.0300602493708568,0.046250436508671,0.0118975323103925,0.0131577135336249,0.0256610376197972,0.00529263899271287,0.0148850110873007,0.0101375384124216],"base":[20.55,1.55,18.55,7.55,4.55,16.55,6.55,17.55,19.55,12.55,15.55,14.55,2.55,13.55,10.55],"x":[0.055930688827395,6.27738321145765e-05,0.0254043139032639,0.00390950801647227,0.00144897625668235,0.0102502668479732,0.00317653138053049,0.0150301246854284,0.0231252182543355,0.00594876615519625,0.00657885676681243,0.0128305188098986,0.00264631949635644,0.00744250554365035,0.0050687692062108],"y":[0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  1.118614e-01<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  1.255477e-04<br />variable: RASP3 = N<br />mean_val > 0:  TRUE","mean_val:  5.080863e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  7.819016e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  2.897953e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  2.050053e-02<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  6.353063e-03<br />variable: RDEF4 = C<br />mean_val > 0:  TRUE","mean_val:  3.006025e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  4.625044e-02<br />variable: RDEF6 = C<br />mean_val > 0:  TRUE","mean_val:  1.189753e-02<br />variable: RDEF8 = C<br />mean_val > 0:  TRUE","mean_val:  1.315771e-02<br />variable: RDELAY = 8<br />mean_val > 0:  TRUE","mean_val:  2.566104e-02<br />variable: RSBP = 130<br />mean_val > 0:  TRUE","mean_val:  5.292639e-03<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  1.488501e-02<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  1.013754e-02<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"x":[-0.00336081523031573,-0.00172124255572469,-0.000703348262781844,-0.00341139962407333,-0.00124932418820944,-0.00209566682819995,-0.00242147269376347,-0.00436443992708624,-7.81799152986817e-05,0,-0.00109554733561112,0,-0.00109313609047224,-0.00417908927696575,0,-0.00128112059467811,-0.00314338640894263,-0.00314676740551956,-0.00280020978293405,-9.47549641749923e-07,0,-0.0298375026545299,-0.0104012394551516,-3.5605673964767e-10,-0.021191738915238,-0.000855068719908925,0,-0.00302887587201983,-0.0206108753493009,-0.0109753154376137,-0.0219654669780601,0.00219813428048288,-0.000539184131985615,-0.00686738496137629,-0.0145280988021405,-0.0282774399967743,0.000298994872145464,-0.00934716263490876,0,-0.0142299441091877,-0.0188776761828174,-0.00939018315374107,0,-0.000792903420812285,-0.00898097288310973,-0.00980484933905457,-0.00884827835604529,0,-0.00299843164949054,-0.00550673535392438,-0.00330702925866844,0,-0.000214120791519279,-0.0087808121541193,-0.00699073319110333,-0.00584465777978282,-0.00871067015409865,-0.00522073294452918,-0.00782604237568474,-0.0069181419597627,-0.00675518544750464,-0.0106808744710144,-0.0074602709021877,-0.00714168996739306,-0.00547398050725934,-0.00316236009093129,0.00551569538546481,0.000849020171412307,-0.0013990187410341,0.00382755157638448,2.33546781258642e-06,-0.00603909129627156,-0.00259942149721049,-0.00165860734145196,-0.00585757932587971,5.07968189733532e-09,-0.0016864004863405,-0.00374900770151942,0,0.00883745301746697,-0.00655129894456585,0.0018078014330033,-0.00116733333969611,0.00113192697470876,-0.00479970400230478,-0.00493232268640131,-0.00553260858602045,-0.00414401834645928,-0.00655727590718458,-2.30587625360545e-06,-0.00066714725722572,-0.00438654548646211,0,-0.00240228356967942,-0.00614884158597195,-7.13823323841289e-05,-0.00468448875725191,-0.00395918574588996,-0.00532247330865754,-0.00324342967533897,-0.00515673263217387,-0.00587811421419304,-0.00439406964157063,-0.00600881200515635,-0.00485115904710953,-0.00200171862135767,0.00042439670982708,0,0.000327561650350083,-0.0103846663837759,-0.00730800428460543,-0.0064128294723359,-0.000942178140864613,-0.011026899092462,-0.00255030573513015,-0.000344085259337601,-0.00185167954875132,-0.00629293605816506,0,-0.00689339635538144,-0.00403648730273365,-0.00361260544195841,-0.00593218931994621,-0.000816362826858819,-0.00348271927417435,0,-0.0156086575620822,-0.00466205967439381,-0.0136851446570281,-0.0170983061030499,-0.0172224635707346,-0.00830969383696856,0,-0.0156038920410848,-0.00554922196727381,-0.00842944000094981,-0.00591718122273222,-0.00784823315829375,-0.0118486656576982,-0.0155353065012915,-0.00964742911658462,-0.012071460689083,-3.3656330558185e-05,-0.0208525229530403,-0.0126734769530663,0,8.00547636736759e-07],"y":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x","yaxis":"y","frame":null},{"x":[-0.00131348175027113,-5.23286237674725e-07,0.000698400874311944,0.000405993474051125,-0.00129233942482854,-0.000304129248626439,-6.06344902263078e-05,-5.23286237563703e-07,0.000276215360198617,-0.00113717178917616,0.000266969340183665,-5.23286237674725e-07,-0.00203822787999175,-0.000244079269855524,0.000856485687134367,-5.23286237563703e-07,-0.000281155664063837,0.000430119505939408,-5.5262764446451e-05,-1.77917320773879e-05,-0.00131348175027113,-0.0136906720870642,-0.0243219517282199,0.00117631442092081,-0.00166176663472584,-0.000446162739511924,0.00191793781615213,0.00031583535512103,0.00177769632578306,-0.017300380462589,-0.00889389718638989,-0.002685423507089,0.000604818786251071,0.00204057337220609,0.00159848080126879,-0.00427096551781956,-0.00615328977185758,-2.08861473802724e-05,-0.000664874639856428,-0.000221070996544781,-0.0189421820708446,0.000151590737979213,-0.0027743202375855,-0.00333161510905688,-0.00454779428135832,-0.000920935247939569,-0.00411239825124665,-0.00247830195193532,-0.00726656026796335,-0.0212005144576026,-0.0147774727519807,-0.0137807675843753,-0.000566126560514357,-0.00794613656104182,-0.000483082903490972,-0.000352436678967338,-0.014449948419737,-0.00737542060668515,-0.000483082903490972,-0.000483082903490972,-0.0245186235290462,-0.0183598928747798,-0.00467531865809934,0.00185275855906319,0.00173307620262797,0.00174447801146049,0.000321027854555567,-0.00191682637899848,0.00270886205024323,-0.00548035353252185,-0.00397327558859994,0.00161225884983174,-0.0046617579780116,-6.32467144129345e-05,-0.00381086982745149,-0.00369912304046771,0.00155830224399822,0.00293469723101647,-7.07825392537609e-05,0.000100798436257654,0.000113040027271083,0.00285034548177765,0.00173670180443131,0.00292345552285422,-0.00423379102675747,-0.00111584881621051,0.000331195246282667,-0.000409485525811992,-0.00600915708238969,-0.00350424368917446,0.00134825456977428,0.00241237518150783,-0.00252980298774763,0.00214590644009371,0.00153028935148103,-0.000409485525811992,-0.00409108314749707,-0.00670992679170523,-0.00629209150502885,-0.000409485525811992,0.00109638401564427,0.000601977163183443,0.00198823507841361,0.000123469308873858,0.000703490128271533,0.00188756744955709,-0.00237529964366701,0.000139769418304514,0.00158961390286094,0.000968436446935006,-0.0022162225610477,0.00541704824572897,0.000816515238891369,0.000343329164356865,-0.000964785651666245,-0.000399824262937437,0.000572913036105516,0.00264968502909468,0.00473040310434625,-0.00395696546731539,-0.00150393421568706,5.55166104546645e-05,-0.00379950289627773,-0.00562393522010873,-0.00299486482702593,-0.00373177242258882],"y":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x2","yaxis":"y2","frame":null},{"x":[-0.00367374326925152,-0.00410717458982812,-0.00406613569630654,-0.00215631864188404,-0.00232833603386151,-0.00105576132323715,-0.00105827856732876,-0.00450611394170253,-0.00467175744479364,-0.00344991643156901,-0.00105827856732876,-0.00494721331687931,-0.00464606189926531,-0.00201376466047964,-0.00161169922799309,-0.00254134968080644,-0.00511372654831843,-0.00480572139890456,-0.00480759898797989,-0.0052569696527659,-0.00457232518246509,-0.0309230967441101,-0.00605918067906586,-0.0304464865509834,-0.00596591409936587,-0.0304360385731666,-0.0259422023268824,-0.0266696969413744,-0.0161805664889688,-0.0139048018495473,-0.00351249742384119,-0.0208764077142511,-0.0197621092414783,-0.0291334649869689,-0.0195999109173335,-0.0241261208674303,-0.0233801812077424,-0.026450590860457,-0.00948159151599248,-0.026700648944146,-0.00543436705360179,-0.0166122542772953,-0.00115369162698742,-0.00131621646746427,-0.00102760612220665,-0.00301469811143307,-0.000956419016351351,-0.00326205800835899,-0.00251214440814262,-0.00169776518267117,-0.00106265893105539,-0.000956419016351351,-0.00370928583430463,-0.00181879983154606,-0.000952783160172221,-0.00119422003219538,-0.00234102600650543,-0.00305711076412973,-0.00112133148959881,-0.00269717262357294,-0.000264829237817787,-4.82364679865732e-06,-0.00407373694480329,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.00374341706281023,-0.0138107908919519,-0.00237270542922763,-0.0128523441827136,-0.00379178853591489,-0.00718768895671595,-0.00745219358809173,-0.0139270887788895,-0.0138107908919519,-0.00237270542922763,-0.0132610929556972,-0.00662630673704279,-0.00264791962106881,-0.0122355159817389,-0.00939890110740338,-0.00240053800980045,-0.00237270542922763,-0.00260056009782217,-0.00598516478678401,-0.00357086624700365,-0.0140749806288424,-0.00344199823411095,-0.0113912267819503,-0.0120614380439955,-0.0058899222609774,-0.00304296647222935,-0.00650903661993307,-0.00684336767798023,-0.00628399429164028,-0.00329823860675971,-0.00754536741071055,-0.0080560396748538,-0.0101463609611284,-0.010425901541394,-0.00344199823411095,-0.00347015133627171,-0.0126106211787996,-0.00340288694073654,-0.0049700606302101,-0.00887359211047567,-0.00510749665737886,-0.00689805557193779],"y":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x3","yaxis":"y3","frame":null},{"x":[0.0574883111447828,0.0546829000388389,0.0973311373163556,0.0259511993399585,0.0461445614708437,0.022413835468057,0.108392926820196,0.0264956877258776,0.0302502396359569,0.0857585809294381,0.036309017341179,0.0306707294860354,0.0655001282495895,0.0408326093943384,0.100783317078644,0.0228303145962536,0.0896615076032528,0.112893769491471,0.0306707294860354,0.0269814960830678,0.0952115353402665,0.000916359601579497,0.000813800324720448,-0.00100134294454168,0.000388415505459316,0.000286219805309962,0.00201290882618721,1.09186175656362e-08,0.000756546696490057,0.000964719917957435,0,0.00272859430458028,0,0.00118082972076317,0.000938910355670619,0.00178354814744375,0.00147885670743875,0.00103379638740719,0.00304521119824297,0.00222266949411631,0.000155983553295713,-0.000462486887569113,0.0354327801938003,0,0.0513418769462353,0.0479494512263197,0.0588420448180397,0.0599942406151812,0.0599942406151812,0.00670769548765482,0,0.0719008121192694,0.0246666616239841,0.0399320567925435,0.0528706668277831,0.0327997154383949,0,0,0.0114471746920186,2.93704880893753e-05,0.0544894519919228,0.0301086299467832,0.0502871543830918,-0.00210160260975945,0.00459279798406931,6.13761153012149e-10,0.00506618146325477,0.00117130336765541,0.00538506621165447,-8.90743799608629e-07,0.00131304470647464,-0.00381203470605052,0,0.0019899903777989,-0.00415571530226477,0.00113638238115688,0.000873653973439636,0.00189474266495515,0.00407287777350307,-1.69971727473905e-05,0.000685133609209077,0.00113169478979191,0.00537174133866103,0,0,0.000442764694159381,0.00245582668498812,0.00140042249168493,0.000928106496005832,0.00460100052663681,0.000749176320049671,0.00206779689143466,0.000614880736634849,0.00194784421025862,0.000148021303066237,0.00195562798075766,0.00060990103795755,0.00340350574352888,0.00142961840163158,0.00137710289861714,0.00120092497561108,9.82505887536789e-07,0.00318246632902652,0.00150601620632607,0,0.00839536220820725,0.00112557484299569,0.014810742255788,0.0181818785723626,0.0142720478498778,0.0103716893043273,0.0197903105801553,0.0128929097436596,0.012130930215941,0.00166407992587436,0.00844131121051483,0.0147308502996006,0.019556239854596,0.00696228034846125,0.0158829322803995,0.0153928823986651,0.00512404215109497,0.0055883064475668,0.0147308502996006,0.0188252042245027,0.0158791095205689,0.0105603271704734,0.0196050701570537,0.0444606508924006,0.0212546286928214,-0.00138400424710439,0.0260457455730816,0.000381876127919512,0.00928701115690511,0.021033487925215,0.0397880980896211,0.0320068766607758,0.0423074063679114,0.0325353092466323,0.0163721583872557,0.0105613523751202,0.0384182216248456,0.0422607560690376,0.0366725922686447,0.0358717523419748,0.029574648433602,0.0393466917205264,0.0035059512479978,0.0258989623150815,0.0044965749007061,0.00786957167710356,0.0257618876057177,0.00693758199607641,0.0260310183313588,0.0229588163131571,0.00859069478689012,0.0290704620490142,0.0290766554733679,0.0109411304761025,0.0235778264910671,0.000407408765424666,0.0248197161850845,0.0327639336271791,0.000416057526669955,0.00482205921050471,0.0134811151847272,0.0157396566595174,0.0133657090271173,0.00809328307987123,0.00297866438931227,0.0265575012891522,0.00683387888601561,-0.000423296339138513,0,0.000794466956738682,0.0399353385095517,0.029522590480736,0.0141151406499219,0.0290029123167642,0.0011780798263874,0.0294131842682652,0.0154630651176513,-0.000663392668085683,0.0439987679332431,0.0245271817043297,0.0216385331436055,0,0.0317584679263556,0,4.54744964720755e-05,0.00127812050873755,-0.000167353843555929,-0.000312996502313645,0.000298921519939266,0.000403510848739908,-0.000284381941406675,0.000148106051563024,0,7.49309469739723e-05,0.000913317479851128,-0.000284381941406675,0,0.000401513150023125,-0.000343291996372397,0,0.000715929458695586,0.000376933738429175,-0.000727728777708103,0.000573603886162122,0,0.00255580924646115,-0.00127501902916038,0.00470138329903025,0.000988133923908729,0.00238751398967263,0,0.00592176474276829,0.00255473147873253,0.00752327941448172,-0.00128388883841635,2.79678500636482e-06,0.00160303491096103,0.000857517805671348,-0.000230345558985601,-0.00272708193098303,-0.00605862160645676,0,1.20849917415455e-05,0,-0.00115075353738348,0.00162553383204833,0.00570184034294452,4.38185639222155e-05,-0.000218025340890438,0.00659007426246383,0.00175894527092579,-2.90378790954726e-05,0.00118729437277809,0.000195083943981711,0,0.00205296948356726,-1.67132355342048e-05,0.00629441236063499,0.00163176855902503,0,0,0,0.00157001700450055,-0.000187541845115047,0.00141207574835534,0,0.00166660910299798,0.0156805185098899,0.0149919771332583,0.0149919771332583,0.013586368470526,0.0145500968229073,-0.000540091242095975,0.0132327054562199,0.0149919771332583,0.0164463121919504,0,0.00784913192853759,0.00343495420239459,0,0.014197093463482,-0.00448248773174698,0.000227548188543758,0.010757611554025,-0.000493199209813833,0.0154092645011257,0,1.19935692488582e-08,0.0109944466020135,0.00735620718069585,0.0041536017375795,0.0339890787145374,0.014115299603263,0.00520197573960801,0.00368090318529846,0.0171025844122853,0.014115299603263,0.00108698916662064,-0.00131300652838495,0.00849190562054492,0.0121644503533002,0.0147137655754107,0.0122465360368396,0.00313549483044595,0.0179782390885687,0.0110951892131494,0.0201276051188328,0.00844710861900266,0.014115299603263],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x","yaxis":"y","frame":null},{"x":[0.180904657254897,0.163025276545612,0.111167645759245,0.200758350758005,0.162811154718298,0.177299243714659,0.214775541441066,0.198506901108286,0.196689187685088,0.217063379698128,0.185259613958685,0.197416083331553,0.234220862450637,0.14401305337641,0.130092762299249,0.142118847495232,0.20360022551954,0.107708235107944,0.210910241752498,0.207418488346768,0.213238050031035,0.00112810208498992,0.000907392753019542,-0.00125949065714004,0.00169431325679503,0.00160882908393833,-0.00133445945453969,0.000619854445036649,0.00285652460594144,0.000671386922115769,-9.43099114200097e-05,0.000671386922115769,0.000609709014665283,0.000602662542349086,-0.00103756004887567,0.000809370504778695,0.000462499381995535,-0.000412788420277588,0.000111773347724498,0.000456331375136121,-3.04276485582067e-05,0.000671386922115769,0.0017008445433736,0.0164198130020287,0.0697823183194356,0.00131093266953319,0.0017008445433736,0.00192353445267057,0.00708548808455867,0.011281559364267,0.00183346650717264,0.00131093266953319,0.07134834602351,0.0175274300209832,0.00434236787062947,-0.00224034948692386,0.00481033906974138,0.0697823183194356,-0.00418665028484633,-0.00191400316358414,0.00205896489726654,0.083650069041341,0.00854746397714679,0.00670563755365139,0.00727160140232297,0.00272702177964579,0.00439427648800828,0.00827338683749035,0.00450621843130949,0.0064494822819714,0.00734242160091292,0.00370840528721361,0.00592810532114474,0.01646631342014,0.0045953646208019,0.00783667268106036,0.00970426482328812,0.00371764358090887,0.00648291615444405,0.00536615205736934,0.0050883792106825,0.0071288752974431,0.00410164957531933,0.00834645083819652,0.00657260119617986,0.0115250057320393,0.00627646846189123,0.00549797123835027,0.0058320250651519,0.00588841958980446,0.00586867695391746,0.00565687057314246,0.00613240477543592,0.00478131653938874,0.00308611340069065,0.00309057837206517,0.0119857784890037,0.00287132554641667,0.00844088452849379,0.00734568898869192,0.00797672882470624,0.00504586406871388,0.00647621283195254,0.00541222324403812,0.00301734186408009,0.00674184236155817,0.00901080387866104,0.0293692907958578,0.00877479804775727,0.0430649034375893,0.0398310658000891,0.0373262813656218,0.00877479804775727,0.00901080387866104,0.0363514934288258,0.0248673799374419,0.0278989129492957,0.0228894683756072,0.0249744506505805,0.017325495635317,0.037006766637962,0.0512090880208227,0.00630308248804967,0.00875567985626291,0.0221747924330287,0.00901763786100518,-0.000194773300476681,-0.00202596733522387,-0.000267610301101562,0.00204159933442005,3.01687046958654e-05,-0.000993257560385818,-0.000618694267345843,-0.000777762078381539,0.000271388823356866,0.000103904703977586,-0.00104293907420727,-0.00105743498079514,5.0835300106411e-05,-0.000567113808203401,0.0026915211913936,0.000793395683519549,5.0835300106411e-05,7.21535125871586e-05,0.000831089846742294,0.00119869121605642,4.35118877720742e-05,0.0265669025580832,0.0284255195929759,0.0208886257207321,0.00308878449255634,0.0216343672435436,0.0148562050316059,-0.00332370429618967,0.00951997394005399,0.0111213190902878,0.00960265370157865,0.00750243553417751,0.0395023319893582,0.0571876401396627,0.0142065034880086,0.0120814307291348,0.036662347722734,0.0402350067793399,0.020055934420293,0.0352279629505577,0.0171256200594029,0.032153851226519,0.0608650131513286,0.0207593130003297,0.0205772214160151,0.0416903857682648,0.0895150621123288,0.0450362307699589,0.0555870648110999,0.0310776754606746,0.0435709612383081,0.0649282617770955,0.0709837023480245,0.0754488814372378,0.0482246395408932,0.0649282617770955,0.0551811206994334,0.0643642533608277,0.0476204945969158,0.0550025731354813,0.0950165957726272,0.044910038329827,0.0720406105293313,0.0249057303807304,0.0253288204001214,-0.00220873991169179,0.014231696383063,0.0190487353652988,0.0104238863015832,0.0231556142068169,0.019962140353977,0.0182868098272799,0.0124126237586516,0.020009065276722,0.0209269074159563,0.0114089824554293,0.025542797834252,0.0200113617917556,0.00112817160366363,0.0099525738959777,0.0185192176243744,0.0163813746284692,0.0249571199451666,0.0096239776602568,0.00090841837341471,0.00219539207957575,0.00092153059727762,0.000613855969103683,0.000708963857651956,0.000769511661403044,0.00092153059727762,0.00193990997462201,0.00164842624374328,0.000652468166753906,0.00235760327500489,0.00134236760769191,0.000458023034626498,0.000909060007857398,0.00043390175584046,0.000937611568460728,0.000929442488188825,0.00102440102202218,0.000708963857651956,0.000648059391208045,0.000482979933089211,0.00992440029803376,0.0085657145009187,0.00354162152230664,0.0223623468064978,0.0101517860277882,0.0165668487711673,0.0142017534700479,0.0276451776782498,-0.000799158994147953,0.0105317293473453,0.0321389893593612,0.0252677873875395,0.0103021525789566,0.00116887931067966,0.0231891396686404,0.0232589282821973,-0.00341093833482686,0.0256926354662507,0.0129528259475381,-0.00362125372805033,0.00237797953180607,0.00300937972175219,0.00263723967156915,0.00355031136866046,0.00230496132066826,-2.06238145560311e-05,0.000146484637811195,0.0001119533527697,0.00456573456710119,0.000922970783265975,0.0013336293504842,0.000111953352769589,0.00119327613591458,0.000938583513182656,0.000430432658530266,0.0001119533527697,0.00161789639953905,0.00446759533793051,0.000132734045999339,0.00213709767111736,0.00283837902258088,0.0014338819404599,0.0120365642193084,0.0139902970430121,0.0121836842174671,0.0129193890874877,0.0106992551686247,0.00878038334559827,0.0162903538557327,0.0121533056290163,0.0097736243065325,0.0122534576837966,0.0174346778686975,0.0119234197309818,0.00984146961922105,0.014907438522362,0.0126194324362874,0.0156889169544416,0.0118341075914691,0.0137781002343138,0.0124757041387508,0.00728733865745534,0.0224362505266841,-0.00451143709505586,0.00188385055987095,0.00556038733001287,0.00353609590927373,0.000919466521088208,0.00667595992240677,0.0195066482048079,0.00673756305647699,0.018190557029624,0.0147393656088809,0.00215737947264905,0.0197485251851323,0.00188385055987095,0.00205092513980998,0.00173071658662038,-0.0023084087842834,-0.00468719460002254,0.00188426123803309,0.0167651243415639,0.0006261862691892,0.00367831147432096],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x2","yaxis":"y2","frame":null},{"x":[0.11186137765479,0.0910477808923745,0.0590828785933446,0.146034225412854,0.0859269957430118,0.0874197455272404,0.135660945159538,0.156409116859654,0.0866878283354006,0.127820105792862,0.0900548860463299,0.163748907650286,0.166625430834624,0.0821507894583373,0.133533266785693,0.0716531843954356,0.058210132501031,0.153536989492074,0.110812091795353,0.0712001717719996,0.159612080048357,8.87869859966806e-06,0.000185458489175061,4.16780238204906e-05,-0.000267914762454358,-0.000482929579957103,0.000272786153789895,0.000263140980784282,0.000125547664229153,9.29675206172709e-05,0.000149164358344001,-9.14216242486887e-06,0.000109498638866112,0.000340115893957993,0.000159687438637701,4.531387999962e-05,0.00034404966746715,0.00066382070167037,4.65252184181919e-05,0.00030195532209143,0.000119771975372274,0.000126126827807882,0.0646489035072072,0.047899601640283,0.019712971941549,0.0426024843737721,0.0854412551118066,0.0620998434529643,0.0819384006039394,0.0717752874101194,0.0308286383260672,0.0512470906388568,0.0225956832783694,0.0673419705296135,0.019712971941549,0.0305847407267062,0.0293837770420526,0.0209347794508513,0.0508086278065279,0.0339728625621593,0.0793881611083973,0.0649624688567122,0.0891006636275821,0.00589229381417866,0.00781901603294454,0.00699386252198941,0.00784833785336536,0.00344113079945041,0.00322373203916948,0.0110525389516906,0.00997874037696611,0.00697336555390726,0.00299579308316678,0.0143850822485005,0.0118580875367078,0.00429123309074353,0.0120263194784782,0.011137716696155,0.0110525389516906,0.00343730052085944,0.0112871982268555,0.00344867657587666,0.00400383338744892,0.0110525389516906,0.00357959096105476,0.00439636283024669,0.00431884710647101,0.0028979525133647,0.00357294691395305,0.00121421112241793,0.00426920863959956,0.00113790449699924,0.00402474437050149,0.00133729541304983,0.00276523111415239,0.00383521226552419,0.00155224530270681,0.00252791535945573,0.00101551074675843,0.000906483522743917,0.00417244138940087,0.00308605979682752,0.00247857637116933,0.00386120200580742,0.00390706053845391,0.0159602521269775,0.0201416892045702,0.0153343355359167,0.0205005336959463,0.0153133165818956,0.0230957360248524,0.0240195130714849,0.017242223555195,0.0325373472854951,0.0316580352101898,0.0120129480363351,0.0316949905325324,0.0292904076123007,0.00727577098582821,0.0250649281381019,0.0192134742945455,0.0115060032217739,0.00962302004293947,0.00862810609362608,0.0313779276201051,0.0290206487442615,0.00112117521204158,0.00191802336527558,0.00904940442879931,0.00635306276106098,0.00792787097253278,0.00904940442879931,0.0103961506718634,0.00934365418611993,0.00989629418803673,0.00808604904002463,0.00670434250604945,0.000902213063905588,0.00601866640117965,0.00964662719534237,0.00431527423810862,0.00110076087643729,0.010603792344983,0.0106246884411293,0.00618928829995424,0.00306429724010793,0.00110327812052891,0.0436355780074291,0.0427070364801339,0.0518042328686021,0.0478417645873768,0.0507338640236624,0.0300602493708568,0.0294611497222834,0.021625404998269,0.0127969520660688,0.0449659641161453,0.0190104905124917,0.00978960167975018,0.0441154624463083,0.00976448917066353,0.0233628227492203,0.0371587979702317,0.013057102337914,0.0467053000019652,0.00974454768219246,0.0310570973177976,0.0118673286786297,0.070004224084839,0.069004602853817,0.046250436508671,0.066985125189142,0.0406690030100785,0.0564501510237944,0.0520771642191112,0.0614759586574971,0.0226679405145911,0.0262078237746987,0.0154691974173569,0.0670787754493057,0.0401392099610461,0.0643119511218964,0.0171303515303499,0.0163413045382121,0.0667844800558213,0.0539389628083405,0.0147547128585875,0.0550818896503527,0.048435901454582,0.0146179176824922,0.018800996326768,0.0192578394059635,0.00783873628553422,0.0172865848673328,0.00345277157544266,0.0192578394059635,0.0201268105485284,0.00190970181343597,0.00215924762558661,0.0142299925715665,0.0136563861029868,0.00284729841906506,0.0118975323103925,0.00190970181343597,0.00827637917576651,0.017559783138829,0.0161881267103984,0.00192119564410331,0.0194672938570674,0.0171860432375831,0.0194079985274627,0.0176582670894129,0.0233077316296507,0.00999985851005325,0.0163457612466317,0.00572280622149868,0.00396485275075753,0.0131577135336249,0.0173080895902485,0.00357232151998332,0.0222958311120879,0.00561976009089249,0.0138414804429989,0.00428386279938431,0.0148172916833625,0.0153356697261008,0.0108354902383667,0.0225827628760205,0.00389580080508323,0.0198397600579376,0.012518873754563,0.022167249434728,0.03638851766966,0.0286429972447585,0.0286480636205579,0.020489986784995,0.0131128784717107,0.00868388034305578,0.0334844641827329,0.0161422211649683,0.0243188328240013,0.0399206924610621,0.0256610376197972,0.0426918774620568,0.00870606611121671,0.00820087722662854,0.0415288969201005,0.0230928888047555,0.0415288969201005,0.0370615887925376,0.0301263137556255,0.00828356220069248,0.00495205371458707,0.00398655028459849,0.00720752313944883,0.00710109343111465,0.00479370891591724,0.00491833648136641,0.00609712096327597,0.00286407410859535,0.00561348245473736,0.00523936236005706,0.00647631005462768,0.00354753146436793,0.00214458522916317,0.00691697886349429,0.00377168917333381,0.00166490158940458,0.0060967523550326,0.00529263899271287,0.00774531433516279,0.00732755060809998,0.0073878603278722,0.0120265334545915,0.017819752343781,0.0165449290240385,0.0234675388851098,0.0256298485459113,0.0242996366623973,0.0101787986521644,0.00587344140971069,0.0216753906814745,0.00721876882491823,0.00613458161907532,0.0240538507474602,0.005591979600576,0.0148850110873007,0.00743764710446959,0.0240600922785743,0.00742539172074363,0.00556597309241358,0.0218621300555135,0.0113913874188031,0.0194425496242875,0.00330636502887083,0.00434013975528957,0.00439962456355814,0.0137927714577787,0.0101375384124216,0.0033507020763901,0.0164323177971978,0.013590425956158,0.0185424044929206,0.00783307241878695,0.0125971531282307,0.0170296269276182,0.0164323177971978,0.0149133623273549,0.0164970168762408,0.0161707558772328,0.00330636502887083,0.00622361459234411,0.00578378329906104,0.00330636502887083,0.00490258381845921],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x3","yaxis":"y3","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":43.8356164383562,"l":184.109589041096},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.232413082973481],"automargin":true,"type":"linear","autorange":false,"range":[-0.0369740662618299,0.120030333098771],"tickmode":"array","ticktext":["0.00","0.04","0.08","0.12"],"tickvals":[0,0.04,0.08,0.12],"categoryorder":"array","categoryarray":["0.00","0.04","0.08","0.12"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"annotations":[{"text":"contribution","x":0.5,"y":0,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis","yshift":-23.9103362391034},{"text":"NNet","x":0.116206541486741,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RF","x":0.5,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"XGB","x":0.883793458513259,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.232413082973481,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.232413082973481,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.434253583693185,"x1":0.565746416306815,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.434253583693185,"x1":0.565746416306815,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.767586917026518,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.767586917026518,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[-0.0374555978280304,0.247157836749621],"tickmode":"array","ticktext":["0.00","0.05","0.10","0.15","0.20"],"tickvals":[0,0.05,0.1,0.15,0.2],"categoryorder":"array","categoryarray":["0.00","0.05","0.10","0.15","0.20"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.434253583693185,0.565746416306815],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"xaxis3":{"type":"linear","autorange":false,"range":[-0.0408005231230468,0.17650285721356],"tickmode":"array","ticktext":["0.00","0.05","0.10","0.15"],"tickvals":[0,0.05,0.1,0.15],"categoryorder":"array","categoryarray":["0.00","0.05","0.10","0.15"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.767586917026518,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y3","title":"","hoverformat":".2f"},"yaxis3":{"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RSLEEP = N","RATRIAL = N","RDEF2 = Y","RVISINF = N","RDEF4 = C","RDEF1 = Y","STYPE = PACS","RDEF7 = C","treatment = yes_asp_low_hep","RCT = Y","RDEF8 = C","SEX = F","RSBP = 130","RDELAY = 8","RDEF3 = Y","RDEF5 = C","RCONSC = D","RDEF6 = C","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x3","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"298842a01f9f":{"x":{},"y":{},"fill":{},"type":"bar"},"2988673e4af0":{"x":{},"y":{},"fill":{}}},"cur_data":"298842a01f9f","visdat":{"298842a01f9f":["function (y) ","x"],"2988673e4af0":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>export(local_profile_old2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;local-profile-old.rds&quot;))</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.0.3 (2020-10-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] stacks_0.2.1       summarytools_1.0.0 default_1.0.0      DALEXtra_2.1.1    
 [5] DALEX_2.3.0.9000   yardstick_0.0.9    workflowsets_0.1.0 workflows_0.2.4   
 [9] tune_0.1.6         rsample_0.1.1      recipes_0.1.17     parsnip_0.1.7     
[13] modeldata_0.1.1    infer_1.0.0        dials_0.0.10       scales_1.1.1      
[17] broom_0.7.10       tidymodels_0.1.4   patchwork_1.1.1    plotly_4.10.0     
[21] ggpubr_0.4.0       rio_0.5.29         forcats_0.5.1      stringr_1.4.0     
[25] dplyr_1.0.7        purrr_0.3.4        readr_2.1.1        tidyr_1.1.4       
[29] tibble_3.1.6       ggplot2_3.3.5      tidyverse_1.3.1    here_1.0.1        
[33] doFuture_0.12.0    future_1.23.0      foreach_1.5.1      tictoc_1.0.1      
[37] conflicted_1.1.0  

loaded via a namespace (and not attached):
  [1] utf8_1.2.2         reticulate_1.22    tidyselect_1.1.1  
  [4] htmlwidgets_1.5.4  grid_4.0.3         ranger_0.13.1     
  [7] pROC_1.18.0        munsell_0.5.0      codetools_0.2-18  
 [10] xgboost_1.5.0.2    withr_2.4.3        colorspace_2.0-2  
 [13] highr_0.9          knitr_1.37         rstudioapi_0.13   
 [16] ggsignif_0.6.3     listenv_0.8.0      labeling_0.4.2    
 [19] git2r_0.29.0       DiceDesign_1.9     farver_2.1.0      
 [22] rprojroot_2.0.2    parallelly_1.30.0  vctrs_0.3.8       
 [25] generics_0.1.1     ipred_0.9-12       xfun_0.29         
 [28] R6_2.5.1           lhs_1.1.3          cachem_1.0.6      
 [31] assertthat_0.2.1   promises_1.2.0.1   nnet_7.3-16       
 [34] gtable_0.3.0       globals_0.14.0     workflowr_1.7.0   
 [37] timeDate_3043.102  rlang_0.4.12       splines_4.0.3     
 [40] rstatix_0.7.0      butcher_0.1.5      lazyeval_0.2.2    
 [43] rapportools_1.0    checkmate_2.0.0    yaml_2.2.1        
 [46] abind_1.4-5        modelr_0.1.8       tidytext_0.3.2    
 [49] crosstalk_1.2.0    backports_1.4.1    httpuv_1.6.4      
 [52] tokenizers_0.2.1   tools_4.0.3        lava_1.6.10       
 [55] tcltk_4.0.3        usethis_2.1.5      ellipsis_0.3.2    
 [58] jquerylib_0.1.4    Rcpp_1.0.7         plyr_1.8.6        
 [61] base64enc_0.1-3    rpart_4.1-15       haven_2.4.3       
 [64] fs_1.5.2           furrr_0.2.3        magrittr_2.0.1    
 [67] data.table_1.14.2  magick_2.7.3       iBreakDown_2.0.1  
 [70] openxlsx_4.2.5     reprex_2.0.1       GPfit_1.0-8       
 [73] SnowballC_0.7.0    whisker_0.4        matrixStats_0.61.0
 [76] hms_1.1.1          evaluate_0.14      readxl_1.3.1      
 [79] compiler_4.0.3     ingredients_2.2.0  crayon_1.4.2      
 [82] htmltools_0.5.2    later_1.3.0        tzdb_0.2.0        
 [85] lubridate_1.8.0    DBI_1.1.2          dbplyr_2.1.1      
 [88] MASS_7.3-54        rappdirs_0.3.3     Matrix_1.4-0      
 [91] car_3.0-12         cli_3.1.0          pryr_0.1.5        
 [94] parallel_4.0.3     gower_0.2.2        pkgconfig_2.0.3   
 [97] foreign_0.8-81     xml2_1.3.3         bslib_0.3.1       
[100] hardhat_0.1.6      prodlim_2019.11.13 rvest_1.0.2       
[103] janeaustenr_0.1.5  digest_0.6.29      rmarkdown_2.11    
[106] cellranger_1.1.0   curl_4.3.2         lifecycle_1.0.1   
[109] jsonlite_1.7.2     carData_3.0-4      viridisLite_0.4.0 
[112] fansi_0.5.0        pillar_1.6.4       lattice_0.20-45   
[115] fastmap_1.1.0      httr_1.4.2         survival_3.2-13   
[118] glue_1.6.0         zip_2.2.0          png_0.1-7         
[121] iterators_1.0.13   pander_0.6.5       class_7.3-19      
[124] stringi_1.7.6      sass_0.4.0         memoise_2.0.1     
[127] future.apply_1.8.1</code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
