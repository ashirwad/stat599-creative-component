<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ashirwad Barnwal" />

<meta name="date" content="2020-10-21" />

<title>Stroke trial modeling result</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<link href="site_libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="site_libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">stat599-creative-component</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ashirwad/stat599-creative-component">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Stroke trial modeling result</h1>
<h4 class="author">Ashirwad Barnwal</h4>
<h4 class="date">10/21/2020</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2022-04-13
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong>
<code>stat599-creative-component/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.0). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20200920code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20200920)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20200920code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20200920)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomashirwadstat599creativecomponenttree8544ed17079f64540d1dd91e8a2cc6c264521265targetblank8544ed1a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/ashirwad/stat599-creative-component/tree/8544ed17079f64540d1dd91e8a2cc6c264521265" target="_blank">8544ed1</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomashirwadstat599creativecomponenttree8544ed17079f64540d1dd91e8a2cc6c264521265targetblank8544ed1a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/ashirwad/stat599-creative-component/tree/8544ed17079f64540d1dd91e8a2cc6c264521265" target="_blank">8544ed1</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/tlverse_cache/
    Ignored:    renv/library/
    Ignored:    renv/python/
    Ignored:    renv/staging/

Untracked files:
    Untracked:  analysis/img/
    Untracked:  data/IST_country_codes.csv
    Untracked:  extras/
    Untracked:  output/figures/
    Untracked:  output/ist_model_st.rds
    Untracked:  output/rds-files/
    Untracked:  output/tables/
    Untracked:  patient-level-prediction/
    Untracked:  slide/
    Untracked:  testing-ideas/

Unstaged changes:
    Modified:   .Rprofile
    Modified:   renv.lock
    Modified:   renv/activate.R

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/modeling.Rmd</code>) and HTML
(<code>docs/modeling.html</code>) files. If you’ve configured a remote
Git repository (see <code>?wflow_git_remote</code>), click on the
hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/ashirwad/stat599-creative-component/blob/87dadd284da62307306fc53f4b341b9b903943b2/analysis/modeling.Rmd" target="_blank">87dadd2</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-13
</td>
<td>
rename modeling file
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/ashirwad/stat599-creative-component/87dadd284da62307306fc53f4b341b9b903943b2/docs/modeling.html" target="_blank">87dadd2</a>
</td>
<td>
ashirwad
</td>
<td>
2022-04-13
</td>
<td>
rename modeling file
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<pre class="r"><code>knitr::opts_chunk$set(cache = TRUE, autodep = TRUE)
source(here::here(&quot;code&quot;, &quot;custom-funs.R&quot;))</code></pre>
<div id="getting-setup" class="section level1">
<h1>Getting setup</h1>
<p>Define setup chunk:</p>
<pre class="r"><code># Elegant handling of namespace conflicts
library(conflicted)

# Miscellaneous
library(tictoc)
library(doFuture)
registerDoFuture()
plan(multisession)

# Path &amp; data manipulation
library(here)
library(tidyverse)
conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;)
library(rio)
conflict_prefer(&quot;export&quot;, &quot;rio&quot;)

# Pretty plots
library(ggpubr)
library(plotly)
conflict_prefer(&quot;layout&quot;, &quot;plotly&quot;)
library(patchwork)

# Model building &amp; evaluation
library(tidymodels)

# Model explanation
library(DALEX)
library(DALEXtra)

# Set options
options(datatable.na.strings = c(&quot;&quot;, &quot;NA&quot;)) # read these strings as NA</code></pre>
</div>
<div id="international-stroke-trial-ist-data" class="section level1">
<h1>International Stroke Trial (IST) data</h1>
<p>Import IST data:</p>
<pre class="r"><code>ist &lt;- import(here(&quot;output&quot;, &quot;rds-files&quot;, &quot;ist.rds&quot;))
glimpse(ist)</code></pre>
<pre><code>Rows: 18,304
Columns: 22
$ RDELAY      &lt;dbl&gt; 20, 28, 12, 17, 19, 20, 45, 24, 24, 45, 24, 29, 2, 6, 30, ~
$ RCONSC      &lt;fct&gt; F, F, F, F, F, D, F, F, F, F, F, D, F, F, F, D, F, F, F, F~
$ SEX         &lt;fct&gt; F, F, M, M, M, F, M, M, M, M, M, F, F, M, M, F, F, F, M, M~
$ AGE         &lt;dbl&gt; 64, 73, 74, 82, 54, 79, 80, 81, 62, 61, 71, 64, 90, 70, 57~
$ RSLEEP      &lt;fct&gt; N, Y, N, N, N, N, N, N, Y, N, N, N, N, Y, N, N, Y, N, N, N~
$ RATRIAL     &lt;fct&gt; Y, N, N, N, N, N, Y, Y, N, N, Y, N, N, N, N, N, Y, N, N, N~
$ RCT         &lt;fct&gt; Y, Y, Y, Y, Y, N, Y, Y, Y, Y, Y, Y, Y, N, Y, N, N, Y, N, Y~
$ RVISINF     &lt;fct&gt; N, N, Y, N, N, N, Y, N, N, Y, Y, Y, N, N, N, N, N, N, N, N~
$ RHEP24      &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ RASP3       &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, Y, Y, N, N, N, N~
$ RSBP        &lt;dbl&gt; 150, 120, 160, 170, 160, 175, 200, 200, 150, 180, 190, 130~
$ RDEF1       &lt;fct&gt; Y, Y, Y, N, Y, Y, Y, Y, N, Y, Y, Y, N, Y, N, Y, Y, Y, N, Y~
$ RDEF2       &lt;fct&gt; Y, Y, Y, N, N, Y, Y, Y, Y, N, Y, Y, N, Y, Y, Y, Y, Y, Y, Y~
$ RDEF3       &lt;fct&gt; Y, Y, N, N, N, Y, Y, Y, Y, N, N, Y, N, N, Y, Y, Y, Y, Y, Y~
$ RDEF4       &lt;fct&gt; N, N, Y, Y, N, Y, Y, Y, Y, N, N, N, Y, Y, N, C, Y, N, N, Y~
$ RDEF5       &lt;fct&gt; C, N, N, N, N, Y, N, N, C, Y, N, C, Y, N, N, Y, N, N, N, N~
$ RDEF6       &lt;fct&gt; Y, N, N, N, N, Y, N, N, C, N, N, C, N, N, N, C, N, N, N, N~
$ RDEF7       &lt;fct&gt; N, N, N, N, Y, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ RDEF8       &lt;fct&gt; N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N, N~
$ STYPE       &lt;fct&gt; TACS, LACS, PACS, PACS, POCS, TACS, PACS, PACS, TACS, PACS~
$ treatment   &lt;fct&gt; yes_asp_no_hep, no_asp_no_hep, no_asp_no_hep, yes_asp_med_~
$ dead_or_dep &lt;fct&gt; no, yes, yes, no, yes, yes, yes, yes, yes, no, no, yes, ye~</code></pre>
</div>
<div id="data-partitioning" class="section level1">
<h1>Data partitioning</h1>
<p>Create data partitions:</p>
<pre class="r"><code># For reproducible results
set.seed(123)

# Data partitions
ist_split &lt;- initial_split(sample_frac(ist, 0.1), strata = dead_or_dep)
ist_train &lt;- training(ist_split)
ist_test &lt;- testing(ist_split)

ist_folds &lt;- vfold_cv(ist_train, v = 5)</code></pre>
<div id="model-specification" class="section level2 tabset">
<h2 class="tabset">Model specification</h2>
<div id="random-forest" class="section level3">
<h3>Random forest</h3>
<p>Specify a random forest model:</p>
<pre class="r"><code>rf_spec &lt;- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()
) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;ranger&quot;)
rf_spec</code></pre>
<pre><code>Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = tune()

Computational engine: ranger </code></pre>
</div>
<div id="neural-network" class="section level3">
<h3>Neural network</h3>
<p>Specify a neural network model:</p>
<pre class="r"><code>nnet_spec &lt;- mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;nnet&quot;)
nnet_spec</code></pre>
<pre><code>Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = tune()
  penalty = tune()
  epochs = tune()

Computational engine: nnet </code></pre>
</div>
<div id="xgboost" class="section level3">
<h3>XGBoost</h3>
<p>Specify an XGBoost model:</p>
<pre class="r"><code>xgb_spec &lt;- boost_tree(
  mtry = tune(),
  trees = 1000,
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune()
) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;xgboost&quot;)
xgb_spec</code></pre>
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 1000
  min_n = tune()
  tree_depth = tune()
  learn_rate = tune()
  loss_reduction = tune()
  sample_size = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="feature-engineering" class="section level2 tabset">
<h2 class="tabset">Feature engineering</h2>
<p>Define recipes for feature engineering:</p>
<div id="dummy-coding" class="section level3">
<h3>Dummy coding</h3>
<p>Create dummy variables:</p>
<pre class="r"><code>base_rec &lt;- recipe(dead_or_dep ~ ., data = ist_train) %&gt;%
  step_dummy(all_nominal(), -all_outcomes())
base_rec</code></pre>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         21

Operations:

Dummy variables from all_nominal(), -all_outcomes()</code></pre>
</div>
<div id="normalization" class="section level3">
<h3>Normalization</h3>
<p>Center and scale numeric variables:</p>
<pre class="r"><code>norm_rec &lt;- base_rec %&gt;%
  step_normalize(all_predictors())
norm_rec</code></pre>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         21

Operations:

Dummy variables from all_nominal(), -all_outcomes()
Centering and scaling for all_predictors()</code></pre>
</div>
</div>
<div id="modeling-workflow" class="section level2 tabset">
<h2 class="tabset">Modeling workflow</h2>
<p>Specify modeling workflows:</p>
<div id="random-forest-1" class="section level3">
<h3>Random forest</h3>
<p>Specify a modeling workflow for random forest:</p>
<pre class="r"><code>rf_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(rf_spec)
rf_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: rand_forest()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = tune()

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-1" class="section level3">
<h3>Neural network</h3>
<p>Specify a modeling workflow for neural net:</p>
<pre class="r"><code>nnet_wflow &lt;- workflow() %&gt;%
  add_recipe(norm_rec) %&gt;%
  add_model(nnet_spec)
nnet_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: mlp()

-- Preprocessor ----------------------------------------------------------------
2 Recipe Steps

* step_dummy()
* step_normalize()

-- Model -----------------------------------------------------------------------
Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = tune()
  penalty = tune()
  epochs = tune()

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-1" class="section level3">
<h3>XGBoost</h3>
<p>Specify a modeling workflow for XGBoost:</p>
<pre class="r"><code>xgb_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(xgb_spec)
xgb_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: boost_tree()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 1000
  min_n = tune()
  tree_depth = tune()
  learn_rate = tune()
  loss_reduction = tune()
  sample_size = tune()

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="model-tuning" class="section level2 tabset">
<h2 class="tabset">Model tuning</h2>
<div id="random-forest-2" class="section level3">
<h3>Random forest</h3>
<p>Tune random forest model:</p>
<pre class="r"><code>tic()
set.seed(345)
rf_res &lt;- tune_grid(
  object = rf_wflow,
  resamples = ist_folds,
  grid = 10
)</code></pre>
<pre><code>i Creating pre-processing data to finalize unknown parameter: mtry</code></pre>
<pre class="r"><code>toc()</code></pre>
<pre><code>23.01 sec elapsed</code></pre>
<pre class="r"><code>rf_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics          .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [20 x 6]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
<div id="neural-network-2" class="section level3">
<h3>Neural network</h3>
<p>Tune neural net model:</p>
<pre class="r"><code>tic()
set.seed(123)
nnet_res &lt;- tune_grid(
  object = nnet_wflow,
  resamples = ist_folds,
  grid = 10
)
toc()</code></pre>
<pre><code>9.76 sec elapsed</code></pre>
<pre class="r"><code>nnet_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics          .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [20 x 7]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
<div id="xgboost-2" class="section level3">
<h3>XGBoost</h3>
<p>Construct parameter grid:</p>
<pre class="r"><code>xgb_grid &lt;- grid_latin_hypercube(
  min_n(),
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), ist_train),
  size = 30
)
xgb_grid</code></pre>
<pre><code># A tibble: 30 x 6
   min_n tree_depth learn_rate loss_reduction sample_size  mtry
   &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;
 1    32         12   1.28e- 4        2.76e-5       0.284    16
 2    22          6   9.25e- 7        5.08e-9       0.200     9
 3     9          5   1.57e-10        7.36e-5       0.948     5
 4    13         11   9.27e- 9        5.05e-2       0.392    11
 5    36         10   2.49e- 6        2.29e+0       0.465     1
 6    11          3   2.93e- 3        1.67e+1       0.107    21
 7    17          1   1.56e- 9        7.38e-7       0.353    19
 8     8          7   3.17e- 4        2.02e-5       0.707     4
 9    24         14   2.50e- 8        5.80e-6       0.524    20
10    22          7   7.74e- 6        1.06e+0       0.132    10
# ... with 20 more rows</code></pre>
<p>Tune XGBoost model:</p>
<pre class="r"><code>tic()
set.seed(123)
xgb_res &lt;- tune_grid(
  object = xgb_wflow,
  resamples = ist_folds,
  grid = xgb_grid
)
toc()</code></pre>
<pre><code>55.19 sec elapsed</code></pre>
<pre class="r"><code>xgb_res</code></pre>
<pre><code># Tuning results
# 5-fold cross-validation 
# A tibble: 5 x 4
  splits             id    .metrics           .notes          
  &lt;list&gt;             &lt;chr&gt; &lt;list&gt;             &lt;list&gt;          
1 &lt;split [1097/275]&gt; Fold1 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
2 &lt;split [1097/275]&gt; Fold2 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
3 &lt;split [1098/274]&gt; Fold3 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
4 &lt;split [1098/274]&gt; Fold4 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;
5 &lt;split [1098/274]&gt; Fold5 &lt;tibble [60 x 10]&gt; &lt;tibble [0 x 1]&gt;</code></pre>
</div>
</div>
<div id="best-models" class="section level2 tabset">
<h2 class="tabset">Best models</h2>
<p>Identify best models and create final model specifications:</p>
<div id="random-forest-3" class="section level3">
<h3>Random forest</h3>
<p>Best random forest model:</p>
<pre class="r"><code>rf_best_acc &lt;- select_best(rf_res, &quot;accuracy&quot;)
rf_final_spec &lt;- finalize_model(rf_spec, rf_best_acc)
rf_final_spec</code></pre>
<pre><code>Random Forest Model Specification (classification)

Main Arguments:
  mtry = 27
  trees = 500
  min_n = 16

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-3" class="section level3">
<h3>Neural network</h3>
<p>Best neural net model:</p>
<pre class="r"><code>nnet_best_acc &lt;- select_best(nnet_res, &quot;accuracy&quot;)
nnet_final_spec &lt;- finalize_model(nnet_spec, nnet_best_acc)
nnet_final_spec</code></pre>
<pre><code>Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = 2
  penalty = 0.000706529703098408
  epochs = 469

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-3" class="section level3">
<h3>XGBoost</h3>
<p>Best XGBoost model:</p>
<pre class="r"><code>xgb_best_acc &lt;- select_best(xgb_res, &quot;accuracy&quot;)
xgb_final_spec &lt;- finalize_model(xgb_spec, xgb_best_acc)
xgb_final_spec</code></pre>
<pre><code>Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 4
  trees = 1000
  min_n = 5
  tree_depth = 2
  learn_rate = 0.0166306075804429
  loss_reduction = 0.0228850351507784
  sample_size = 0.26876543791499

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="final-workflows" class="section level2 tabset">
<h2 class="tabset">Final workflows</h2>
<p>Specify final workflows:</p>
<div id="random-forest-4" class="section level3">
<h3>Random forest</h3>
<p>Create a final workflow for fitting random forest:</p>
<pre class="r"><code>rf_final_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(rf_final_spec)
rf_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: rand_forest()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Random Forest Model Specification (classification)

Main Arguments:
  mtry = 27
  trees = 500
  min_n = 16

Computational engine: ranger </code></pre>
</div>
<div id="neural-network-4" class="section level3">
<h3>Neural network</h3>
<p>Create a final workflow for fitting neural network:</p>
<pre class="r"><code>nnet_final_wflow &lt;- workflow() %&gt;%
  add_recipe(norm_rec) %&gt;%
  add_model(nnet_final_spec)
nnet_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: mlp()

-- Preprocessor ----------------------------------------------------------------
2 Recipe Steps

* step_dummy()
* step_normalize()

-- Model -----------------------------------------------------------------------
Single Layer Neural Network Specification (classification)

Main Arguments:
  hidden_units = 2
  penalty = 0.000706529703098408
  epochs = 469

Computational engine: nnet </code></pre>
</div>
<div id="xgboost-4" class="section level3">
<h3>XGBoost</h3>
<p>Create a final workflow for fitting XGBoost:</p>
<pre class="r"><code>xgb_final_wflow &lt;- workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(xgb_final_spec)
xgb_final_wflow</code></pre>
<pre><code>== Workflow ====================================================================
Preprocessor: Recipe
Model: boost_tree()

-- Preprocessor ----------------------------------------------------------------
1 Recipe Step

* step_dummy()

-- Model -----------------------------------------------------------------------
Boosted Tree Model Specification (classification)

Main Arguments:
  mtry = 4
  trees = 1000
  min_n = 5
  tree_depth = 2
  learn_rate = 0.0166306075804429
  loss_reduction = 0.0228850351507784
  sample_size = 0.26876543791499

Computational engine: xgboost </code></pre>
</div>
</div>
<div id="final-fits" class="section level2 tabset">
<h2 class="tabset">Final fits</h2>
<p>Fit final best models to the training set and evaluate the test
set:</p>
<div id="random-forest-5" class="section level3">
<h3>Random forest</h3>
<p>Fit the final best random forest model to the training set and
evaluate the test set:</p>
<pre class="r"><code>tic()
rf_final_res &lt;- rf_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>1.53 sec elapsed</code></pre>
<pre class="r"><code>rf_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.745 Preprocessor1_Model1
2 roc_auc  binary         0.778 Preprocessor1_Model1</code></pre>
</div>
<div id="neural-network-5" class="section level3">
<h3>Neural network</h3>
<p>Fit the final best neural network model to the training set and
evaluate the test set:</p>
<pre class="r"><code>tic()
nnet_final_res &lt;- nnet_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>0.86 sec elapsed</code></pre>
<pre class="r"><code>nnet_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.727 Preprocessor1_Model1
2 roc_auc  binary         0.752 Preprocessor1_Model1</code></pre>
</div>
<div id="xgboost-5" class="section level3">
<h3>XGBoost</h3>
<p>Fit the final best xgboost model to the training set and evaluate the
test set:</p>
<pre class="r"><code>tic()
xgb_final_res &lt;- xgb_final_wflow %&gt;%
  last_fit(ist_split)
toc()</code></pre>
<pre><code>1.5 sec elapsed</code></pre>
<pre class="r"><code>xgb_final_res %&gt;%
  collect_metrics()</code></pre>
<pre><code># A tibble: 2 x 4
  .metric  .estimator .estimate .config             
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy binary         0.766 Preprocessor1_Model1
2 roc_auc  binary         0.807 Preprocessor1_Model1</code></pre>
</div>
</div>
<div id="roc-curve" class="section level2 tabset">
<h2 class="tabset">ROC curve</h2>
<div id="random-forest-6" class="section level3">
<h3>Random forest</h3>
<p>Compute the data needed to plot the ROC curve for random forest
model:</p>
<pre class="r"><code>rf_auc &lt;- rf_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;Random forest&quot;)
rf_auc</code></pre>
<pre><code># A tibble: 460 x 4
   .threshold specificity sensitivity model        
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        
 1  -Inf          0             1     Random forest
 2     0.0861     0             1     Random forest
 3     0.0988     0.00617       1     Random forest
 4     0.114      0.00617       0.997 Random forest
 5     0.138      0.0123        0.997 Random forest
 6     0.143      0.0185        0.997 Random forest
 7     0.148      0.0247        0.997 Random forest
 8     0.154      0.0309        0.997 Random forest
 9     0.170      0.0370        0.997 Random forest
10     0.174      0.0432        0.997 Random forest
# ... with 450 more rows</code></pre>
</div>
<div id="neural-network-6" class="section level3">
<h3>Neural network</h3>
<p>Compute the data needed to plot the ROC curve for neural network
model:</p>
<pre class="r"><code>nnet_auc &lt;- nnet_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;Neural network&quot;)
nnet_auc</code></pre>
<pre><code># A tibble: 116 x 4
   .threshold specificity sensitivity model         
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;         
 1   -Inf           0           1     Neural network
 2      0.348       0           1     Neural network
 3      0.348       0.327       0.916 Neural network
 4      0.348       0.333       0.916 Neural network
 5      0.348       0.340       0.916 Neural network
 6      0.348       0.340       0.912 Neural network
 7      0.348       0.340       0.909 Neural network
 8      0.348       0.346       0.909 Neural network
 9      0.348       0.352       0.909 Neural network
10      0.348       0.352       0.905 Neural network
# ... with 106 more rows</code></pre>
</div>
<div id="xgboost-6" class="section level3">
<h3>XGBoost</h3>
<p>Compute the data needed to plot the ROC curve for xgboost model:</p>
<pre class="r"><code>xgb_auc &lt;- xgb_final_res %&gt;%
  collect_predictions() %&gt;%
  roc_curve(dead_or_dep, .pred_yes, event_level = &quot;second&quot;) %&gt;%
  mutate(model = &quot;XGBoost&quot;)
xgb_auc</code></pre>
<pre><code># A tibble: 460 x 4
   .threshold specificity sensitivity model  
        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
 1   -Inf         0             1     XGBoost
 2      0.114     0             1     XGBoost
 3      0.146     0.00617       1     XGBoost
 4      0.158     0.00617       0.997 XGBoost
 5      0.162     0.0123        0.997 XGBoost
 6      0.163     0.0185        0.997 XGBoost
 7      0.168     0.0247        0.997 XGBoost
 8      0.170     0.0309        0.997 XGBoost
 9      0.185     0.0370        0.997 XGBoost
10      0.193     0.0432        0.997 XGBoost
# ... with 450 more rows</code></pre>
</div>
</div>
<div id="section" class="section level2 unnumbered">
<h2 class="unnumbered"></h2>
<p>Compare ROC curves:</p>
<pre class="r"><code>roc_curves &lt;- bind_rows(rf_auc, nnet_auc, xgb_auc) %&gt;%
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) + 
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_manual(values = colors_discrete_drwhy(3)) + 
  theme_pubclean()
roc_curves</code></pre>
<p><img src="figure/modeling.Rmd/roc-curves-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>roc_curves2 &lt;- ggplotly(roc_curves) %&gt;%
  layout(legend = list(orientation = &quot;h&quot;, xanchor = &quot;center&quot;, x = 0.5, y = 1))
roc_curves2</code></pre>
<div id="htmlwidget-292ec1f153fa9e3f1d12" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-292ec1f153fa9e3f1d12">{"x":{"data":[{"x":[1,1,0.672839506172839,0.666666666666667,0.660493827160494,0.660493827160494,0.660493827160494,0.654320987654321,0.648148148148148,0.648148148148148,0.641975308641975,0.635802469135802,0.62962962962963,0.62962962962963,0.62962962962963,0.623456790123457,0.617283950617284,0.617283950617284,0.611111111111111,0.604938271604938,0.604938271604938,0.598765432098765,0.598765432098765,0.592592592592593,0.58641975308642,0.580246913580247,0.574074074074074,0.574074074074074,0.567901234567901,0.567901234567901,0.561728395061728,0.555555555555556,0.555555555555556,0.549382716049383,0.54320987654321,0.54320987654321,0.54320987654321,0.537037037037037,0.537037037037037,0.537037037037037,0.537037037037037,0.530864197530864,0.530864197530864,0.524691358024691,0.524691358024691,0.518518518518519,0.518518518518519,0.518518518518519,0.512345679012346,0.512345679012346,0.512345679012346,0.512345679012346,0.506172839506173,0.506172839506173,0.506172839506173,0.5,0.493827160493827,0.487654320987654,0.487654320987654,0.271604938271605,0.265432098765432,0.265432098765432,0.265432098765432,0.259259259259259,0.253086419753086,0.253086419753086,0.253086419753086,0.253086419753086,0.253086419753086,0.253086419753086,0.246913580246914,0.246913580246914,0.240740740740741,0.240740740740741,0.234567901234568,0.228395061728395,0.228395061728395,0.222222222222222,0.222222222222222,0.216049382716049,0.216049382716049,0.216049382716049,0.209876543209877,0.111111111111111,0.111111111111111,0.111111111111111,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.0987654320987654,0.0925925925925926,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0555555555555556,0.0555555555555556,0.0555555555555556,0],"y":[1,1,0.915540540540541,0.915540540540541,0.915540540540541,0.912162162162162,0.908783783783784,0.908783783783784,0.908783783783784,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.902027027027027,0.898648648648649,0.898648648648649,0.898648648648649,0.89527027027027,0.89527027027027,0.89527027027027,0.891891891891892,0.891891891891892,0.888513513513513,0.888513513513513,0.888513513513513,0.888513513513513,0.888513513513513,0.885135135135135,0.885135135135135,0.881756756756757,0.881756756756757,0.881756756756757,0.878378378378378,0.878378378378378,0.878378378378378,0.875,0.871621621621622,0.871621621621622,0.868243243243243,0.864864864864865,0.861486486486487,0.861486486486487,0.858108108108108,0.858108108108108,0.85472972972973,0.85472972972973,0.851351351351351,0.847972972972973,0.847972972972973,0.844594594594595,0.841216216216216,0.837837837837838,0.837837837837838,0.834459459459459,0.831081081081081,0.831081081081081,0.831081081081081,0.831081081081081,0.827702702702703,0.611486486486487,0.611486486486487,0.608108108108108,0.60472972972973,0.60472972972973,0.60472972972973,0.601351351351351,0.597972972972973,0.594594594594595,0.591216216216216,0.587837837837838,0.587837837837838,0.584459459459459,0.584459459459459,0.581081081081081,0.581081081081081,0.581081081081081,0.577702702702703,0.577702702702703,0.574324324324324,0.574324324324324,0.570945945945946,0.567567567567568,0.567567567567568,0.456081081081081,0.452702702702703,0.449324324324324,0.449324324324324,0.445945945945946,0.442567567567568,0.439189189189189,0.435810810810811,0.432432432432432,0.429054054054054,0.425675675675676,0.422297297297297,0.418918918918919,0.418918918918919,0.418918918918919,0.415540540540541,0.415540540540541,0.412162162162162,0.408783783783784,0.405405405405405,0.405405405405405,0.405405405405405,0.402027027027027,0.398648648648649,0.39527027027027,0.391891891891892,0.391891891891892,0.391891891891892,0.388513513513513,0.388513513513513,0.385135135135135,0.381756756756757,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Neural network","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Neural network","1 - specificity: 0.67283951<br />sensitivity: 0.915540541<br />model: Neural network","1 - specificity: 0.66666667<br />sensitivity: 0.915540541<br />model: Neural network","1 - specificity: 0.66049383<br />sensitivity: 0.915540541<br />model: Neural network","1 - specificity: 0.66049383<br />sensitivity: 0.912162162<br />model: Neural network","1 - specificity: 0.66049383<br />sensitivity: 0.908783784<br />model: Neural network","1 - specificity: 0.65432099<br />sensitivity: 0.908783784<br />model: Neural network","1 - specificity: 0.64814815<br />sensitivity: 0.908783784<br />model: Neural network","1 - specificity: 0.64814815<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.64197531<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.63580247<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.62962963<br />sensitivity: 0.905405405<br />model: Neural network","1 - specificity: 0.62962963<br />sensitivity: 0.902027027<br />model: Neural network","1 - specificity: 0.62962963<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.62345679<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.61728395<br />sensitivity: 0.898648649<br />model: Neural network","1 - specificity: 0.61728395<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.61111111<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.60493827<br />sensitivity: 0.895270270<br />model: Neural network","1 - specificity: 0.60493827<br />sensitivity: 0.891891892<br />model: Neural network","1 - specificity: 0.59876543<br />sensitivity: 0.891891892<br />model: Neural network","1 - specificity: 0.59876543<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.59259259<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.58641975<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.58024691<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.57407407<br />sensitivity: 0.888513514<br />model: Neural network","1 - specificity: 0.57407407<br />sensitivity: 0.885135135<br />model: Neural network","1 - specificity: 0.56790123<br />sensitivity: 0.885135135<br />model: Neural network","1 - specificity: 0.56790123<br />sensitivity: 0.881756757<br />model: Neural network","1 - specificity: 0.56172840<br />sensitivity: 0.881756757<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.881756757<br />model: Neural network","1 - specificity: 0.55555556<br />sensitivity: 0.878378378<br />model: Neural network","1 - specificity: 0.54938272<br />sensitivity: 0.878378378<br />model: Neural network","1 - specificity: 0.54320988<br />sensitivity: 0.878378378<br />model: Neural network","1 - specificity: 0.54320988<br />sensitivity: 0.875000000<br />model: Neural network","1 - specificity: 0.54320988<br />sensitivity: 0.871621622<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.871621622<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.868243243<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.864864865<br />model: Neural network","1 - specificity: 0.53703704<br />sensitivity: 0.861486486<br />model: Neural network","1 - specificity: 0.53086420<br />sensitivity: 0.861486486<br />model: Neural network","1 - specificity: 0.53086420<br />sensitivity: 0.858108108<br />model: Neural network","1 - specificity: 0.52469136<br />sensitivity: 0.858108108<br />model: Neural network","1 - specificity: 0.52469136<br />sensitivity: 0.854729730<br />model: Neural network","1 - specificity: 0.51851852<br />sensitivity: 0.854729730<br />model: Neural network","1 - specificity: 0.51851852<br />sensitivity: 0.851351351<br />model: Neural network","1 - specificity: 0.51851852<br />sensitivity: 0.847972973<br />model: Neural network","1 - specificity: 0.51234568<br />sensitivity: 0.847972973<br />model: Neural network","1 - specificity: 0.51234568<br />sensitivity: 0.844594595<br />model: Neural network","1 - specificity: 0.51234568<br />sensitivity: 0.841216216<br />model: Neural network","1 - specificity: 0.51234568<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.50617284<br />sensitivity: 0.837837838<br />model: Neural network","1 - specificity: 0.50617284<br />sensitivity: 0.834459459<br />model: Neural network","1 - specificity: 0.50617284<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.50000000<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.49382716<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.48765432<br />sensitivity: 0.831081081<br />model: Neural network","1 - specificity: 0.48765432<br />sensitivity: 0.827702703<br />model: Neural network","1 - specificity: 0.27160494<br />sensitivity: 0.611486486<br />model: Neural network","1 - specificity: 0.26543210<br />sensitivity: 0.611486486<br />model: Neural network","1 - specificity: 0.26543210<br />sensitivity: 0.608108108<br />model: Neural network","1 - specificity: 0.26543210<br />sensitivity: 0.604729730<br />model: Neural network","1 - specificity: 0.25925926<br />sensitivity: 0.604729730<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.604729730<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.601351351<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.597972973<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.594594595<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.591216216<br />model: Neural network","1 - specificity: 0.25308642<br />sensitivity: 0.587837838<br />model: Neural network","1 - specificity: 0.24691358<br />sensitivity: 0.587837838<br />model: Neural network","1 - specificity: 0.24691358<br />sensitivity: 0.584459459<br />model: Neural network","1 - specificity: 0.24074074<br />sensitivity: 0.584459459<br />model: Neural network","1 - specificity: 0.24074074<br />sensitivity: 0.581081081<br />model: Neural network","1 - specificity: 0.23456790<br />sensitivity: 0.581081081<br />model: Neural network","1 - specificity: 0.22839506<br />sensitivity: 0.581081081<br />model: Neural network","1 - specificity: 0.22839506<br />sensitivity: 0.577702703<br />model: Neural network","1 - specificity: 0.22222222<br />sensitivity: 0.577702703<br />model: Neural network","1 - specificity: 0.22222222<br />sensitivity: 0.574324324<br />model: Neural network","1 - specificity: 0.21604938<br />sensitivity: 0.574324324<br />model: Neural network","1 - specificity: 0.21604938<br />sensitivity: 0.570945946<br />model: Neural network","1 - specificity: 0.21604938<br />sensitivity: 0.567567568<br />model: Neural network","1 - specificity: 0.20987654<br />sensitivity: 0.567567568<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.456081081<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.452702703<br />model: Neural network","1 - specificity: 0.11111111<br />sensitivity: 0.449324324<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.449324324<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.445945946<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.442567568<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.439189189<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.435810811<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.432432432<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.429054054<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.425675676<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.422297297<br />model: Neural network","1 - specificity: 0.10493827<br />sensitivity: 0.418918919<br />model: Neural network","1 - specificity: 0.09876543<br />sensitivity: 0.418918919<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.418918919<br />model: Neural network","1 - specificity: 0.09259259<br />sensitivity: 0.415540541<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.415540541<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.412162162<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.408783784<br />model: Neural network","1 - specificity: 0.08641975<br />sensitivity: 0.405405405<br />model: Neural network","1 - specificity: 0.08024691<br />sensitivity: 0.405405405<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.405405405<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.402027027<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.398648649<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.395270270<br />model: Neural network","1 - specificity: 0.07407407<br />sensitivity: 0.391891892<br />model: Neural network","1 - specificity: 0.06790123<br />sensitivity: 0.391891892<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.391891892<br />model: Neural network","1 - specificity: 0.06172840<br />sensitivity: 0.388513514<br />model: Neural network","1 - specificity: 0.05555556<br />sensitivity: 0.388513514<br />model: Neural network","1 - specificity: 0.05555556<br />sensitivity: 0.385135135<br />model: Neural network","1 - specificity: 0.05555556<br />sensitivity: 0.381756757<br />model: Neural network","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: Neural network"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"Neural network","legendgroup":"Neural network","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,1,0.993827160493827,0.993827160493827,0.987654320987654,0.981481481481482,0.975308641975309,0.969135802469136,0.962962962962963,0.95679012345679,0.950617283950617,0.944444444444444,0.944444444444444,0.938271604938272,0.932098765432099,0.932098765432099,0.925925925925926,0.919753086419753,0.91358024691358,0.907407407407407,0.901234567901235,0.901234567901235,0.895061728395062,0.888888888888889,0.882716049382716,0.876543209876543,0.87037037037037,0.864197530864198,0.864197530864198,0.858024691358025,0.851851851851852,0.845679012345679,0.839506172839506,0.833333333333333,0.827160493827161,0.820987654320988,0.814814814814815,0.808641975308642,0.808641975308642,0.808641975308642,0.802469135802469,0.802469135802469,0.796296296296296,0.796296296296296,0.796296296296296,0.790123456790123,0.783950617283951,0.783950617283951,0.777777777777778,0.777777777777778,0.771604938271605,0.765432098765432,0.759259259259259,0.753086419753086,0.746913580246914,0.740740740740741,0.740740740740741,0.740740740740741,0.734567901234568,0.728395061728395,0.722222222222222,0.716049382716049,0.716049382716049,0.716049382716049,0.709876543209877,0.703703703703704,0.703703703703704,0.697530864197531,0.691358024691358,0.685185185185185,0.679012345679012,0.679012345679012,0.679012345679012,0.679012345679012,0.672839506172839,0.666666666666667,0.660493827160494,0.654320987654321,0.648148148148148,0.641975308641975,0.635802469135802,0.635802469135802,0.62962962962963,0.62962962962963,0.623456790123457,0.617283950617284,0.611111111111111,0.611111111111111,0.604938271604938,0.604938271604938,0.604938271604938,0.598765432098765,0.598765432098765,0.598765432098765,0.592592592592593,0.592592592592593,0.58641975308642,0.580246913580247,0.574074074074074,0.574074074074074,0.567901234567901,0.561728395061728,0.555555555555556,0.549382716049383,0.54320987654321,0.537037037037037,0.537037037037037,0.530864197530864,0.530864197530864,0.530864197530864,0.530864197530864,0.524691358024691,0.518518518518519,0.518518518518519,0.512345679012346,0.506172839506173,0.5,0.5,0.5,0.5,0.5,0.493827160493827,0.487654320987654,0.481481481481482,0.475308641975309,0.475308641975309,0.475308641975309,0.475308641975309,0.469135802469136,0.469135802469136,0.469135802469136,0.469135802469136,0.462962962962963,0.462962962962963,0.45679012345679,0.450617283950617,0.450617283950617,0.450617283950617,0.450617283950617,0.450617283950617,0.450617283950617,0.444444444444444,0.438271604938272,0.432098765432099,0.432098765432099,0.432098765432099,0.425925925925926,0.425925925925926,0.419753086419753,0.41358024691358,0.407407407407407,0.401234567901235,0.401234567901235,0.401234567901235,0.401234567901235,0.395061728395062,0.395061728395062,0.395061728395062,0.395061728395062,0.388888888888889,0.382716049382716,0.382716049382716,0.382716049382716,0.382716049382716,0.376543209876543,0.37037037037037,0.364197530864197,0.358024691358025,0.358024691358025,0.351851851851852,0.351851851851852,0.345679012345679,0.339506172839506,0.333333333333333,0.333333333333333,0.333333333333333,0.333333333333333,0.327160493827161,0.320987654320988,0.320987654320988,0.320987654320988,0.320987654320988,0.314814814814815,0.314814814814815,0.308641975308642,0.308641975308642,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.290123456790123,0.290123456790123,0.290123456790123,0.290123456790123,0.290123456790123,0.283950617283951,0.283950617283951,0.283950617283951,0.283950617283951,0.277777777777778,0.277777777777778,0.277777777777778,0.271604938271605,0.271604938271605,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.259259259259259,0.259259259259259,0.253086419753086,0.253086419753086,0.253086419753086,0.253086419753086,0.246913580246914,0.246913580246914,0.246913580246914,0.246913580246914,0.246913580246914,0.240740740740741,0.234567901234568,0.234567901234568,0.234567901234568,0.228395061728395,0.222222222222222,0.216049382716049,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.203703703703704,0.203703703703704,0.197530864197531,0.197530864197531,0.197530864197531,0.191358024691358,0.191358024691358,0.185185185185185,0.185185185185185,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.179012345679012,0.172839506172839,0.166666666666667,0.166666666666667,0.166666666666667,0.166666666666667,0.160493827160494,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.148148148148148,0.148148148148148,0.148148148148148,0.148148148148148,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.141975308641975,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.135802469135803,0.12962962962963,0.123456790123457,0.123456790123457,0.123456790123457,0.117283950617284,0.111111111111111,0.111111111111111,0.111111111111111,0.111111111111111,0.104938271604938,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0802469135802469,0.0740740740740741,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0555555555555556,0.0555555555555556,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0493827160493827,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0246913580246914,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0,0,0,0,0,0],"y":[1,1,1,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.993243243243243,0.993243243243243,0.993243243243243,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.986486486486487,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.983108108108108,0.97972972972973,0.976351351351351,0.976351351351351,0.972972972972973,0.972972972972973,0.969594594594595,0.966216216216216,0.966216216216216,0.966216216216216,0.962837837837838,0.962837837837838,0.959459459459459,0.959459459459459,0.959459459459459,0.959459459459459,0.959459459459459,0.959459459459459,0.959459459459459,0.956081081081081,0.952702702702703,0.952702702702703,0.952702702702703,0.952702702702703,0.952702702702703,0.949324324324324,0.945945945945946,0.945945945945946,0.945945945945946,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.942567567567568,0.939189189189189,0.935810810810811,0.932432432432432,0.932432432432432,0.932432432432432,0.932432432432432,0.932432432432432,0.932432432432432,0.932432432432432,0.932432432432432,0.929054054054054,0.929054054054054,0.925675675675676,0.925675675675676,0.925675675675676,0.925675675675676,0.922297297297297,0.922297297297297,0.918918918918919,0.915540540540541,0.915540540540541,0.912162162162162,0.908783783783784,0.908783783783784,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.902027027027027,0.898648648648649,0.898648648648649,0.89527027027027,0.891891891891892,0.888513513513513,0.888513513513513,0.888513513513513,0.885135135135135,0.885135135135135,0.885135135135135,0.885135135135135,0.881756756756757,0.878378378378378,0.875,0.871621621621622,0.871621621621622,0.871621621621622,0.871621621621622,0.871621621621622,0.868243243243243,0.864864864864865,0.861486486486487,0.861486486486487,0.858108108108108,0.85472972972973,0.851351351351351,0.851351351351351,0.847972972972973,0.847972972972973,0.847972972972973,0.844594594594595,0.841216216216216,0.837837837837838,0.834459459459459,0.831081081081081,0.831081081081081,0.831081081081081,0.831081081081081,0.827702702702703,0.824324324324324,0.824324324324324,0.820945945945946,0.820945945945946,0.820945945945946,0.820945945945946,0.820945945945946,0.817567567567568,0.814189189189189,0.810810810810811,0.810810810810811,0.807432432432432,0.804054054054054,0.800675675675676,0.800675675675676,0.800675675675676,0.797297297297297,0.793918918918919,0.790540540540541,0.790540540540541,0.790540540540541,0.790540540540541,0.790540540540541,0.787162162162162,0.787162162162162,0.783783783783784,0.783783783783784,0.783783783783784,0.783783783783784,0.780405405405405,0.777027027027027,0.773648648648649,0.773648648648649,0.773648648648649,0.77027027027027,0.766891891891892,0.763513513513513,0.763513513513513,0.760135135135135,0.760135135135135,0.756756756756757,0.756756756756757,0.753378378378378,0.75,0.746621621621622,0.743243243243243,0.739864864864865,0.736486486486487,0.733108108108108,0.72972972972973,0.726351351351351,0.726351351351351,0.722972972972973,0.719594594594595,0.716216216216216,0.712837837837838,0.709459459459459,0.709459459459459,0.706081081081081,0.702702702702703,0.699324324324324,0.695945945945946,0.695945945945946,0.692567567567568,0.689189189189189,0.685810810810811,0.685810810810811,0.682432432432432,0.679054054054054,0.679054054054054,0.675675675675676,0.675675675675676,0.672297297297297,0.668918918918919,0.665540540540541,0.662162162162162,0.658783783783784,0.658783783783784,0.655405405405405,0.655405405405405,0.652027027027027,0.648648648648649,0.64527027027027,0.64527027027027,0.641891891891892,0.638513513513513,0.635135135135135,0.631756756756757,0.631756756756757,0.631756756756757,0.628378378378378,0.625,0.625,0.625,0.625,0.625,0.621621621621622,0.618243243243243,0.614864864864865,0.611486486486487,0.608108108108108,0.608108108108108,0.60472972972973,0.60472972972973,0.601351351351351,0.597972972972973,0.597972972972973,0.594594594594595,0.594594594594595,0.591216216216216,0.591216216216216,0.587837837837838,0.584459459459459,0.581081081081081,0.577702702702703,0.574324324324324,0.570945945945946,0.567567567567568,0.564189189189189,0.560810810810811,0.557432432432432,0.554054054054054,0.550675675675676,0.547297297297297,0.543918918918919,0.540540540540541,0.537162162162162,0.533783783783784,0.530405405405405,0.527027027027027,0.527027027027027,0.527027027027027,0.523648648648649,0.52027027027027,0.516891891891892,0.516891891891892,0.516891891891892,0.513513513513513,0.510135135135135,0.506756756756757,0.503378378378378,0.5,0.496621621621622,0.493243243243243,0.489864864864865,0.486486486486487,0.486486486486487,0.483108108108108,0.47972972972973,0.476351351351351,0.476351351351351,0.472972972972973,0.469594594594595,0.466216216216216,0.462837837837838,0.459459459459459,0.456081081081081,0.452702702702703,0.449324324324324,0.449324324324324,0.445945945945946,0.442567567567568,0.439189189189189,0.435810810810811,0.432432432432432,0.432432432432432,0.432432432432432,0.429054054054054,0.425675675675676,0.425675675675676,0.425675675675676,0.422297297297297,0.418918918918919,0.415540540540541,0.415540540540541,0.415540540540541,0.412162162162162,0.408783783783784,0.405405405405405,0.402027027027027,0.398648648648649,0.39527027027027,0.391891891891892,0.391891891891892,0.391891891891892,0.388513513513513,0.385135135135135,0.381756756756757,0.378378378378378,0.375,0.375,0.371621621621622,0.368243243243243,0.364864864864865,0.361486486486487,0.358108108108108,0.35472972972973,0.351351351351351,0.347972972972973,0.344594594594595,0.341216216216216,0.337837837837838,0.334459459459459,0.331081081081081,0.331081081081081,0.331081081081081,0.327702702702703,0.324324324324324,0.320945945945946,0.317567567567568,0.314189189189189,0.310810810810811,0.307432432432432,0.304054054054054,0.304054054054054,0.300675675675676,0.297297297297297,0.293918918918919,0.290540540540541,0.290540540540541,0.287162162162162,0.287162162162162,0.283783783783784,0.280405405405405,0.277027027027027,0.273648648648649,0.27027027027027,0.266891891891892,0.263513513513513,0.260135135135135,0.256756756756757,0.253378378378378,0.25,0.246621621621622,0.243243243243243,0.239864864864865,0.239864864864865,0.236486486486486,0.233108108108108,0.22972972972973,0.226351351351351,0.222972972972973,0.222972972972973,0.219594594594595,0.216216216216216,0.212837837837838,0.212837837837838,0.209459459459459,0.206081081081081,0.202702702702703,0.199324324324324,0.195945945945946,0.192567567567568,0.189189189189189,0.185810810810811,0.182432432432432,0.179054054054054,0.175675675675676,0.172297297297297,0.168918918918919,0.165540540540541,0.162162162162162,0.158783783783784,0.155405405405405,0.152027027027027,0.148648648648649,0.148648648648649,0.148648648648649,0.14527027027027,0.141891891891892,0.138513513513514,0.135135135135135,0.131756756756757,0.128378378378378,0.125,0.121621621621622,0.118243243243243,0.114864864864865,0.111486486486486,0.108108108108108,0.10472972972973,0.101351351351351,0.101351351351351,0.097972972972973,0.0945945945945946,0.0912162162162162,0.0912162162162162,0.0878378378378378,0.0844594594594595,0.0810810810810811,0.0777027027027027,0.0743243243243243,0.0709459459459459,0.0675675675675676,0.0641891891891892,0.0608108108108108,0.0574324324324324,0.0540540540540541,0.0506756756756757,0.0472972972972973,0.0439189189189189,0.0405405405405405,0.0371621621621622,0.0337837837837838,0.0304054054054054,0.027027027027027,0.0236486486486486,0.0202702702702703,0.0168918918918919,0.0168918918918919,0.0135135135135135,0.0101351351351351,0.00675675675675676,0.00337837837837838,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 0.99382716<br />sensitivity: 1.000000000<br />model: Random forest","1 - specificity: 0.99382716<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.98765432<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.98148148<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.97530864<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.96913580<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.96296296<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.95679012<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.95061728<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.94444444<br />sensitivity: 0.996621622<br />model: Random forest","1 - specificity: 0.94444444<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.93827160<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.93209877<br />sensitivity: 0.993243243<br />model: Random forest","1 - specificity: 0.93209877<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.92592593<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.91975309<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.91358025<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.90740741<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.90123457<br />sensitivity: 0.989864865<br />model: Random forest","1 - specificity: 0.90123457<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.89506173<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.88888889<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.88271605<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.87654321<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.87037037<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.86419753<br />sensitivity: 0.986486486<br />model: Random forest","1 - specificity: 0.86419753<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.85802469<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.85185185<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.84567901<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.83950617<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.83333333<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.82716049<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.82098765<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.81481481<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.80864198<br />sensitivity: 0.983108108<br />model: Random forest","1 - specificity: 0.80864198<br />sensitivity: 0.979729730<br />model: Random forest","1 - specificity: 0.80864198<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.80246914<br />sensitivity: 0.976351351<br />model: Random forest","1 - specificity: 0.80246914<br />sensitivity: 0.972972973<br />model: Random forest","1 - specificity: 0.79629630<br />sensitivity: 0.972972973<br />model: Random forest","1 - specificity: 0.79629630<br />sensitivity: 0.969594595<br />model: Random forest","1 - specificity: 0.79629630<br />sensitivity: 0.966216216<br />model: Random forest","1 - specificity: 0.79012346<br />sensitivity: 0.966216216<br />model: Random forest","1 - specificity: 0.78395062<br />sensitivity: 0.966216216<br />model: Random forest","1 - specificity: 0.78395062<br />sensitivity: 0.962837838<br />model: Random forest","1 - specificity: 0.77777778<br />sensitivity: 0.962837838<br />model: Random forest","1 - specificity: 0.77777778<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.77160494<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.76543210<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.75925926<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.75308642<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.74691358<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.74074074<br />sensitivity: 0.959459459<br />model: Random forest","1 - specificity: 0.74074074<br />sensitivity: 0.956081081<br />model: Random forest","1 - specificity: 0.74074074<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.73456790<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.72839506<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.72222222<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.71604938<br />sensitivity: 0.952702703<br />model: Random forest","1 - specificity: 0.71604938<br />sensitivity: 0.949324324<br />model: Random forest","1 - specificity: 0.71604938<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.70987654<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.70370370<br />sensitivity: 0.945945946<br />model: Random forest","1 - specificity: 0.70370370<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.69753086<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.69135802<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.68518519<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.942567568<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.939189189<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.935810811<br />model: Random forest","1 - specificity: 0.67901235<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.67283951<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.66666667<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.66049383<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.65432099<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.64814815<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.64197531<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.63580247<br />sensitivity: 0.932432432<br />model: Random forest","1 - specificity: 0.63580247<br />sensitivity: 0.929054054<br />model: Random forest","1 - specificity: 0.62962963<br />sensitivity: 0.929054054<br />model: Random forest","1 - specificity: 0.62962963<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.62345679<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.61728395<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.61111111<br />sensitivity: 0.925675676<br />model: Random forest","1 - specificity: 0.61111111<br />sensitivity: 0.922297297<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.922297297<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.918918919<br />model: Random forest","1 - specificity: 0.60493827<br />sensitivity: 0.915540541<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.915540541<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.912162162<br />model: Random forest","1 - specificity: 0.59876543<br />sensitivity: 0.908783784<br />model: Random forest","1 - specificity: 0.59259259<br />sensitivity: 0.908783784<br />model: Random forest","1 - specificity: 0.59259259<br />sensitivity: 0.905405405<br />model: Random forest","1 - specificity: 0.58641975<br />sensitivity: 0.905405405<br />model: Random forest","1 - specificity: 0.58024691<br />sensitivity: 0.905405405<br />model: Random forest","1 - specificity: 0.57407407<br />sensitivity: 0.905405405<br />model: Random forest","1 - specificity: 0.57407407<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.56790123<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.56172840<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.55555556<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.54938272<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.54320988<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.53703704<br />sensitivity: 0.902027027<br />model: Random forest","1 - specificity: 0.53703704<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.53086420<br />sensitivity: 0.898648649<br />model: Random forest","1 - specificity: 0.53086420<br />sensitivity: 0.895270270<br />model: Random forest","1 - specificity: 0.53086420<br />sensitivity: 0.891891892<br />model: Random forest","1 - specificity: 0.53086420<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.52469136<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.51851852<br />sensitivity: 0.888513514<br />model: Random forest","1 - specificity: 0.51851852<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.51234568<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50617284<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.885135135<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.881756757<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.878378378<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.875000000<br />model: Random forest","1 - specificity: 0.50000000<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.49382716<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.48765432<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.48148148<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.871621622<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.868243243<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.864864865<br />model: Random forest","1 - specificity: 0.47530864<br />sensitivity: 0.861486486<br />model: Random forest","1 - specificity: 0.46913580<br />sensitivity: 0.861486486<br />model: Random forest","1 - specificity: 0.46913580<br />sensitivity: 0.858108108<br />model: Random forest","1 - specificity: 0.46913580<br />sensitivity: 0.854729730<br />model: Random forest","1 - specificity: 0.46913580<br />sensitivity: 0.851351351<br />model: Random forest","1 - specificity: 0.46296296<br />sensitivity: 0.851351351<br />model: Random forest","1 - specificity: 0.46296296<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.45679012<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.847972973<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.844594595<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.841216216<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.837837838<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.834459459<br />model: Random forest","1 - specificity: 0.45061728<br />sensitivity: 0.831081081<br />model: Random forest","1 - specificity: 0.44444444<br />sensitivity: 0.831081081<br />model: Random forest","1 - specificity: 0.43827160<br />sensitivity: 0.831081081<br />model: Random forest","1 - specificity: 0.43209877<br />sensitivity: 0.831081081<br />model: Random forest","1 - specificity: 0.43209877<br />sensitivity: 0.827702703<br />model: Random forest","1 - specificity: 0.43209877<br />sensitivity: 0.824324324<br />model: Random forest","1 - specificity: 0.42592593<br />sensitivity: 0.824324324<br />model: Random forest","1 - specificity: 0.42592593<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.41975309<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.41358025<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.40740741<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.820945946<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.817567568<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.814189189<br />model: Random forest","1 - specificity: 0.40123457<br />sensitivity: 0.810810811<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.810810811<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.807432432<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.804054054<br />model: Random forest","1 - specificity: 0.39506173<br />sensitivity: 0.800675676<br />model: Random forest","1 - specificity: 0.38888889<br />sensitivity: 0.800675676<br />model: Random forest","1 - specificity: 0.38271605<br />sensitivity: 0.800675676<br />model: Random forest","1 - specificity: 0.38271605<br />sensitivity: 0.797297297<br />model: Random forest","1 - specificity: 0.38271605<br />sensitivity: 0.793918919<br />model: Random forest","1 - specificity: 0.38271605<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.37654321<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.37037037<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.36419753<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.790540541<br />model: Random forest","1 - specificity: 0.35802469<br />sensitivity: 0.787162162<br />model: Random forest","1 - specificity: 0.35185185<br />sensitivity: 0.787162162<br />model: Random forest","1 - specificity: 0.35185185<br />sensitivity: 0.783783784<br />model: Random forest","1 - specificity: 0.34567901<br />sensitivity: 0.783783784<br />model: Random forest","1 - specificity: 0.33950617<br />sensitivity: 0.783783784<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.783783784<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.780405405<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.777027027<br />model: Random forest","1 - specificity: 0.33333333<br />sensitivity: 0.773648649<br />model: Random forest","1 - specificity: 0.32716049<br />sensitivity: 0.773648649<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.773648649<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.770270270<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.766891892<br />model: Random forest","1 - specificity: 0.32098765<br />sensitivity: 0.763513514<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.763513514<br />model: Random forest","1 - specificity: 0.31481481<br />sensitivity: 0.760135135<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.760135135<br />model: Random forest","1 - specificity: 0.30864198<br />sensitivity: 0.756756757<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.756756757<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.753378378<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.750000000<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.746621622<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.743243243<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.739864865<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.736486486<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.733108108<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.729729730<br />model: Random forest","1 - specificity: 0.30246914<br />sensitivity: 0.726351351<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.726351351<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.722972973<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.719594595<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.716216216<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.712837838<br />model: Random forest","1 - specificity: 0.29629630<br />sensitivity: 0.709459459<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.709459459<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.706081081<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.702702703<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.699324324<br />model: Random forest","1 - specificity: 0.29012346<br />sensitivity: 0.695945946<br />model: Random forest","1 - specificity: 0.28395062<br />sensitivity: 0.695945946<br />model: Random forest","1 - specificity: 0.28395062<br />sensitivity: 0.692567568<br />model: Random forest","1 - specificity: 0.28395062<br />sensitivity: 0.689189189<br />model: Random forest","1 - specificity: 0.28395062<br />sensitivity: 0.685810811<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.685810811<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.682432432<br />model: Random forest","1 - specificity: 0.27777778<br />sensitivity: 0.679054054<br />model: Random forest","1 - specificity: 0.27160494<br />sensitivity: 0.679054054<br />model: Random forest","1 - specificity: 0.27160494<br />sensitivity: 0.675675676<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.675675676<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.672297297<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.668918919<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.665540541<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.662162162<br />model: Random forest","1 - specificity: 0.26543210<br />sensitivity: 0.658783784<br />model: Random forest","1 - specificity: 0.25925926<br />sensitivity: 0.658783784<br />model: Random forest","1 - specificity: 0.25925926<br />sensitivity: 0.655405405<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.655405405<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.652027027<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.648648649<br />model: Random forest","1 - specificity: 0.25308642<br />sensitivity: 0.645270270<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.645270270<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.641891892<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.638513514<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.635135135<br />model: Random forest","1 - specificity: 0.24691358<br />sensitivity: 0.631756757<br />model: Random forest","1 - specificity: 0.24074074<br />sensitivity: 0.631756757<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.631756757<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.628378378<br />model: Random forest","1 - specificity: 0.23456790<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.22839506<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.22222222<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.21604938<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.625000000<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.621621622<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.618243243<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.614864865<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.611486486<br />model: Random forest","1 - specificity: 0.20987654<br />sensitivity: 0.608108108<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.608108108<br />model: Random forest","1 - specificity: 0.20370370<br />sensitivity: 0.604729730<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.604729730<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.601351351<br />model: Random forest","1 - specificity: 0.19753086<br />sensitivity: 0.597972973<br />model: Random forest","1 - specificity: 0.19135802<br />sensitivity: 0.597972973<br />model: Random forest","1 - specificity: 0.19135802<br />sensitivity: 0.594594595<br />model: Random forest","1 - specificity: 0.18518519<br />sensitivity: 0.594594595<br />model: Random forest","1 - specificity: 0.18518519<br />sensitivity: 0.591216216<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.591216216<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.587837838<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.584459459<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.581081081<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.577702703<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.574324324<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.570945946<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.567567568<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.564189189<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.560810811<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.557432432<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.554054054<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.550675676<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.547297297<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.543918919<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.540540541<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.537162162<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.533783784<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.530405405<br />model: Random forest","1 - specificity: 0.17901235<br />sensitivity: 0.527027027<br />model: Random forest","1 - specificity: 0.17283951<br />sensitivity: 0.527027027<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.527027027<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.523648649<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.520270270<br />model: Random forest","1 - specificity: 0.16666667<br />sensitivity: 0.516891892<br />model: Random forest","1 - specificity: 0.16049383<br />sensitivity: 0.516891892<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.516891892<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.513513514<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.510135135<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.506756757<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.503378378<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.500000000<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.496621622<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.493243243<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.489864865<br />model: Random forest","1 - specificity: 0.15432099<br />sensitivity: 0.486486486<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.486486486<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.483108108<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.479729730<br />model: Random forest","1 - specificity: 0.14814815<br />sensitivity: 0.476351351<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.476351351<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.472972973<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.469594595<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.466216216<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.462837838<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.459459459<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.456081081<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.452702703<br />model: Random forest","1 - specificity: 0.14197531<br />sensitivity: 0.449324324<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.449324324<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.445945946<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.442567568<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.439189189<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.435810811<br />model: Random forest","1 - specificity: 0.13580247<br />sensitivity: 0.432432432<br />model: Random forest","1 - specificity: 0.12962963<br />sensitivity: 0.432432432<br />model: Random forest","1 - specificity: 0.12345679<br />sensitivity: 0.432432432<br />model: Random forest","1 - specificity: 0.12345679<br />sensitivity: 0.429054054<br />model: Random forest","1 - specificity: 0.12345679<br />sensitivity: 0.425675676<br />model: Random forest","1 - specificity: 0.11728395<br />sensitivity: 0.425675676<br />model: Random forest","1 - specificity: 0.11111111<br />sensitivity: 0.425675676<br />model: Random forest","1 - specificity: 0.11111111<br />sensitivity: 0.422297297<br />model: Random forest","1 - specificity: 0.11111111<br />sensitivity: 0.418918919<br />model: Random forest","1 - specificity: 0.11111111<br />sensitivity: 0.415540541<br />model: Random forest","1 - specificity: 0.10493827<br />sensitivity: 0.415540541<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.415540541<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.412162162<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.408783784<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.405405405<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.402027027<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.398648649<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.395270270<br />model: Random forest","1 - specificity: 0.09876543<br />sensitivity: 0.391891892<br />model: Random forest","1 - specificity: 0.09259259<br />sensitivity: 0.391891892<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.391891892<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.388513514<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.385135135<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.381756757<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.378378378<br />model: Random forest","1 - specificity: 0.08641975<br />sensitivity: 0.375000000<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.375000000<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.371621622<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.368243243<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.364864865<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.361486486<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.358108108<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.354729730<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.351351351<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.347972973<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.344594595<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.341216216<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.337837838<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.334459459<br />model: Random forest","1 - specificity: 0.08024691<br />sensitivity: 0.331081081<br />model: Random forest","1 - specificity: 0.07407407<br />sensitivity: 0.331081081<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.331081081<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.327702703<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.324324324<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.320945946<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.317567568<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.314189189<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.310810811<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.307432432<br />model: Random forest","1 - specificity: 0.06790123<br />sensitivity: 0.304054054<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.304054054<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.300675676<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.297297297<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.293918919<br />model: Random forest","1 - specificity: 0.06172840<br />sensitivity: 0.290540541<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.290540541<br />model: Random forest","1 - specificity: 0.05555556<br />sensitivity: 0.287162162<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.287162162<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.283783784<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.280405405<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.277027027<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.273648649<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.270270270<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.266891892<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.263513514<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.260135135<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.256756757<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.253378378<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.250000000<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.246621622<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.243243243<br />model: Random forest","1 - specificity: 0.04938272<br />sensitivity: 0.239864865<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.239864865<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.236486486<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.233108108<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.229729730<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.226351351<br />model: Random forest","1 - specificity: 0.04320988<br />sensitivity: 0.222972973<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.222972973<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.219594595<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.216216216<br />model: Random forest","1 - specificity: 0.03703704<br />sensitivity: 0.212837838<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.212837838<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.209459459<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.206081081<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.202702703<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.199324324<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.195945946<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.192567568<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.189189189<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.185810811<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.182432432<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.179054054<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.175675676<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.172297297<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.168918919<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.165540541<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.162162162<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.158783784<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.155405405<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.152027027<br />model: Random forest","1 - specificity: 0.03086420<br />sensitivity: 0.148648649<br />model: Random forest","1 - specificity: 0.02469136<br />sensitivity: 0.148648649<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.148648649<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.145270270<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.141891892<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.138513514<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.135135135<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.131756757<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.128378378<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.125000000<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.121621622<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.118243243<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.114864865<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.111486486<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.108108108<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.104729730<br />model: Random forest","1 - specificity: 0.01851852<br />sensitivity: 0.101351351<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.101351351<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.097972973<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.094594595<br />model: Random forest","1 - specificity: 0.01234568<br />sensitivity: 0.091216216<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.091216216<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.087837838<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.084459459<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.081081081<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.077702703<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.074324324<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.070945946<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.067567568<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.064189189<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.060810811<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.057432432<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.054054054<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.050675676<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.047297297<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.043918919<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.040540541<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.037162162<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.033783784<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.030405405<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.027027027<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.023648649<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.020270270<br />model: Random forest","1 - specificity: 0.00617284<br />sensitivity: 0.016891892<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.016891892<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.013513514<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.010135135<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.006756757<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.003378378<br />model: Random forest","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: Random forest"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"Random forest","legendgroup":"Random forest","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,1,0.993827160493827,0.993827160493827,0.987654320987654,0.981481481481482,0.975308641975309,0.969135802469136,0.962962962962963,0.95679012345679,0.950617283950617,0.944444444444444,0.938271604938272,0.938271604938272,0.932098765432099,0.925925925925926,0.919753086419753,0.91358024691358,0.907407407407407,0.901234567901235,0.895061728395062,0.888888888888889,0.882716049382716,0.876543209876543,0.87037037037037,0.87037037037037,0.864197530864198,0.858024691358025,0.851851851851852,0.845679012345679,0.845679012345679,0.839506172839506,0.833333333333333,0.833333333333333,0.833333333333333,0.827160493827161,0.820987654320988,0.814814814814815,0.808641975308642,0.802469135802469,0.796296296296296,0.796296296296296,0.790123456790123,0.783950617283951,0.777777777777778,0.771604938271605,0.765432098765432,0.759259259259259,0.753086419753086,0.753086419753086,0.746913580246914,0.746913580246914,0.740740740740741,0.734567901234568,0.734567901234568,0.728395061728395,0.722222222222222,0.722222222222222,0.716049382716049,0.716049382716049,0.709876543209877,0.709876543209877,0.709876543209877,0.703703703703704,0.697530864197531,0.697530864197531,0.691358024691358,0.685185185185185,0.679012345679012,0.672839506172839,0.672839506172839,0.666666666666667,0.666666666666667,0.666666666666667,0.666666666666667,0.660493827160494,0.654320987654321,0.654320987654321,0.648148148148148,0.641975308641975,0.641975308641975,0.635802469135802,0.62962962962963,0.623456790123457,0.623456790123457,0.617283950617284,0.611111111111111,0.611111111111111,0.604938271604938,0.598765432098765,0.598765432098765,0.592592592592593,0.58641975308642,0.58641975308642,0.58641975308642,0.580246913580247,0.574074074074074,0.567901234567901,0.561728395061728,0.555555555555556,0.555555555555556,0.555555555555556,0.549382716049383,0.54320987654321,0.537037037037037,0.530864197530864,0.524691358024691,0.518518518518519,0.512345679012346,0.506172839506173,0.506172839506173,0.506172839506173,0.506172839506173,0.5,0.493827160493827,0.493827160493827,0.493827160493827,0.487654320987654,0.481481481481482,0.481481481481482,0.475308641975309,0.469135802469136,0.469135802469136,0.469135802469136,0.469135802469136,0.462962962962963,0.45679012345679,0.450617283950617,0.444444444444444,0.438271604938272,0.438271604938272,0.432098765432099,0.425925925925926,0.419753086419753,0.419753086419753,0.41358024691358,0.407407407407407,0.407407407407407,0.407407407407407,0.407407407407407,0.401234567901235,0.395061728395062,0.388888888888889,0.388888888888889,0.382716049382716,0.382716049382716,0.376543209876543,0.376543209876543,0.37037037037037,0.37037037037037,0.37037037037037,0.37037037037037,0.37037037037037,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.364197530864197,0.358024691358025,0.358024691358025,0.351851851851852,0.351851851851852,0.345679012345679,0.345679012345679,0.345679012345679,0.339506172839506,0.333333333333333,0.333333333333333,0.333333333333333,0.333333333333333,0.327160493827161,0.327160493827161,0.327160493827161,0.327160493827161,0.320987654320988,0.320987654320988,0.320987654320988,0.320987654320988,0.314814814814815,0.308641975308642,0.308641975308642,0.308641975308642,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.302469135802469,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.296296296296296,0.290123456790123,0.290123456790123,0.283950617283951,0.277777777777778,0.277777777777778,0.271604938271605,0.265432098765432,0.265432098765432,0.265432098765432,0.265432098765432,0.259259259259259,0.259259259259259,0.253086419753086,0.253086419753086,0.253086419753086,0.246913580246914,0.240740740740741,0.240740740740741,0.234567901234568,0.228395061728395,0.228395061728395,0.228395061728395,0.228395061728395,0.228395061728395,0.228395061728395,0.222222222222222,0.216049382716049,0.216049382716049,0.216049382716049,0.216049382716049,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.209876543209877,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.203703703703704,0.197530864197531,0.197530864197531,0.191358024691358,0.191358024691358,0.185185185185185,0.185185185185185,0.185185185185185,0.185185185185185,0.185185185185185,0.179012345679012,0.179012345679012,0.172839506172839,0.172839506172839,0.172839506172839,0.172839506172839,0.166666666666667,0.160493827160494,0.160493827160494,0.160493827160494,0.154320987654321,0.154320987654321,0.154320987654321,0.154320987654321,0.148148148148148,0.141975308641975,0.141975308641975,0.135802469135803,0.135802469135803,0.12962962962963,0.123456790123457,0.123456790123457,0.123456790123457,0.117283950617284,0.117283950617284,0.117283950617284,0.117283950617284,0.111111111111111,0.111111111111111,0.111111111111111,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.104938271604938,0.0987654320987654,0.0987654320987654,0.0987654320987654,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0925925925925926,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0864197530864198,0.0802469135802469,0.0802469135802469,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0740740740740741,0.0679012345679012,0.0679012345679012,0.0679012345679012,0.0617283950617284,0.0617283950617284,0.0617283950617284,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0555555555555556,0.0493827160493827,0.0493827160493827,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0432098765432098,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0370370370370371,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0308641975308642,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0246913580246914,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0185185185185185,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.0123456790123457,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0.00617283950617287,0,0,0,0,0,0,0],"y":[1,1,1,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.996621621621622,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.993243243243243,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.989864864864865,0.986486486486487,0.986486486486487,0.986486486486487,0.983108108108108,0.97972972972973,0.97972972972973,0.97972972972973,0.97972972972973,0.97972972972973,0.97972972972973,0.97972972972973,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.976351351351351,0.972972972972973,0.972972972972973,0.969594594594595,0.969594594594595,0.969594594594595,0.966216216216216,0.966216216216216,0.966216216216216,0.962837837837838,0.962837837837838,0.959459459459459,0.959459459459459,0.956081081081081,0.952702702702703,0.952702702702703,0.952702702702703,0.949324324324324,0.949324324324324,0.949324324324324,0.949324324324324,0.949324324324324,0.945945945945946,0.945945945945946,0.942567567567568,0.939189189189189,0.935810810810811,0.935810810810811,0.935810810810811,0.932432432432432,0.932432432432432,0.932432432432432,0.929054054054054,0.929054054054054,0.929054054054054,0.929054054054054,0.925675675675676,0.925675675675676,0.925675675675676,0.922297297297297,0.922297297297297,0.922297297297297,0.918918918918919,0.918918918918919,0.918918918918919,0.915540540540541,0.912162162162162,0.912162162162162,0.912162162162162,0.912162162162162,0.912162162162162,0.912162162162162,0.908783783783784,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.905405405405405,0.902027027027027,0.898648648648649,0.89527027027027,0.89527027027027,0.89527027027027,0.891891891891892,0.888513513513513,0.888513513513513,0.888513513513513,0.885135135135135,0.885135135135135,0.885135135135135,0.881756756756757,0.878378378378378,0.875,0.875,0.875,0.875,0.875,0.875,0.871621621621622,0.871621621621622,0.871621621621622,0.871621621621622,0.868243243243243,0.868243243243243,0.868243243243243,0.864864864864865,0.861486486486487,0.858108108108108,0.858108108108108,0.858108108108108,0.858108108108108,0.85472972972973,0.85472972972973,0.851351351351351,0.851351351351351,0.847972972972973,0.847972972972973,0.844594594594595,0.841216216216216,0.837837837837838,0.834459459459459,0.834459459459459,0.831081081081081,0.827702702702703,0.824324324324324,0.820945945945946,0.817567567567568,0.817567567567568,0.814189189189189,0.814189189189189,0.810810810810811,0.810810810810811,0.807432432432432,0.804054054054054,0.804054054054054,0.804054054054054,0.800675675675676,0.797297297297297,0.793918918918919,0.793918918918919,0.790540540540541,0.787162162162162,0.783783783783784,0.783783783783784,0.780405405405405,0.777027027027027,0.773648648648649,0.773648648648649,0.773648648648649,0.77027027027027,0.766891891891892,0.766891891891892,0.763513513513513,0.760135135135135,0.756756756756757,0.753378378378378,0.75,0.746621621621622,0.743243243243243,0.739864864864865,0.736486486486487,0.736486486486487,0.733108108108108,0.72972972972973,0.726351351351351,0.722972972972973,0.719594594594595,0.719594594594595,0.716216216216216,0.716216216216216,0.716216216216216,0.712837837837838,0.712837837837838,0.712837837837838,0.709459459459459,0.706081081081081,0.702702702702703,0.702702702702703,0.699324324324324,0.699324324324324,0.695945945945946,0.692567567567568,0.692567567567568,0.692567567567568,0.689189189189189,0.689189189189189,0.689189189189189,0.685810810810811,0.682432432432432,0.679054054054054,0.675675675675676,0.672297297297297,0.672297297297297,0.672297297297297,0.668918918918919,0.665540540540541,0.662162162162162,0.662162162162162,0.658783783783784,0.655405405405405,0.652027027027027,0.648648648648649,0.64527027027027,0.64527027027027,0.641891891891892,0.638513513513513,0.635135135135135,0.631756756756757,0.628378378378378,0.625,0.621621621621622,0.618243243243243,0.614864864864865,0.614864864864865,0.611486486486487,0.611486486486487,0.608108108108108,0.608108108108108,0.60472972972973,0.601351351351351,0.597972972972973,0.594594594594595,0.594594594594595,0.591216216216216,0.591216216216216,0.587837837837838,0.584459459459459,0.581081081081081,0.581081081081081,0.581081081081081,0.577702702702703,0.574324324324324,0.574324324324324,0.570945945945946,0.567567567567568,0.564189189189189,0.564189189189189,0.564189189189189,0.560810810810811,0.560810810810811,0.557432432432432,0.557432432432432,0.557432432432432,0.554054054054054,0.550675675675676,0.550675675675676,0.547297297297297,0.543918918918919,0.540540540540541,0.540540540540541,0.537162162162162,0.533783783783784,0.533783783783784,0.530405405405405,0.527027027027027,0.523648648648649,0.52027027027027,0.516891891891892,0.516891891891892,0.513513513513513,0.510135135135135,0.510135135135135,0.506756756756757,0.503378378378378,0.5,0.5,0.496621621621622,0.493243243243243,0.489864864864865,0.486486486486487,0.483108108108108,0.47972972972973,0.476351351351351,0.472972972972973,0.469594594594595,0.466216216216216,0.466216216216216,0.462837837837838,0.462837837837838,0.459459459459459,0.456081081081081,0.452702702702703,0.449324324324324,0.445945945945946,0.442567567567568,0.439189189189189,0.439189189189189,0.435810810810811,0.432432432432432,0.432432432432432,0.429054054054054,0.425675675675676,0.425675675675676,0.422297297297297,0.418918918918919,0.415540540540541,0.412162162162162,0.408783783783784,0.405405405405405,0.402027027027027,0.398648648648649,0.39527027027027,0.391891891891892,0.388513513513513,0.385135135135135,0.381756756756757,0.378378378378378,0.375,0.371621621621622,0.368243243243243,0.364864864864865,0.361486486486487,0.358108108108108,0.35472972972973,0.351351351351351,0.347972972972973,0.344594594594595,0.341216216216216,0.341216216216216,0.337837837837838,0.337837837837838,0.334459459459459,0.331081081081081,0.327702702702703,0.324324324324324,0.320945945945946,0.317567567567568,0.314189189189189,0.310810810810811,0.307432432432432,0.307432432432432,0.304054054054054,0.300675675675676,0.297297297297297,0.293918918918919,0.290540540540541,0.287162162162162,0.283783783783784,0.280405405405405,0.277027027027027,0.273648648648649,0.27027027027027,0.266891891891892,0.263513513513513,0.260135135135135,0.256756756756757,0.253378378378378,0.25,0.246621621621622,0.243243243243243,0.239864864864865,0.236486486486486,0.236486486486486,0.233108108108108,0.22972972972973,0.226351351351351,0.222972972972973,0.219594594594595,0.216216216216216,0.212837837837838,0.209459459459459,0.209459459459459,0.206081081081081,0.202702702702703,0.199324324324324,0.195945945945946,0.192567567567568,0.189189189189189,0.189189189189189,0.185810810810811,0.182432432432432,0.179054054054054,0.175675675675676,0.175675675675676,0.172297297297297,0.168918918918919,0.165540540540541,0.162162162162162,0.158783783783784,0.155405405405405,0.152027027027027,0.148648648648649,0.14527027027027,0.141891891891892,0.138513513513514,0.135135135135135,0.131756756756757,0.128378378378378,0.125,0.125,0.121621621621622,0.118243243243243,0.114864864864865,0.111486486486486,0.108108108108108,0.10472972972973,0.101351351351351,0.097972972972973,0.0945945945945946,0.0912162162162162,0.0878378378378378,0.0844594594594595,0.0810810810810811,0.0777027027027027,0.0743243243243243,0.0709459459459459,0.0675675675675676,0.0641891891891892,0.0608108108108108,0.0574324324324324,0.0540540540540541,0.0506756756756757,0.0472972972972973,0.0439189189189189,0.0405405405405405,0.0371621621621622,0.0337837837837838,0.0304054054054054,0.027027027027027,0.0236486486486486,0.0202702702702703,0.0202702702702703,0.0168918918918919,0.0135135135135135,0.0101351351351351,0.00675675675675676,0.00337837837837838,0],"text":["1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 1.00000000<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 0.99382716<br />sensitivity: 1.000000000<br />model: XGBoost","1 - specificity: 0.99382716<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.98765432<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.98148148<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.97530864<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.96913580<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.96296296<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.95679012<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.95061728<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.94444444<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.93827160<br />sensitivity: 0.996621622<br />model: XGBoost","1 - specificity: 0.93827160<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.93209877<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.92592593<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.91975309<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.91358025<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.90740741<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.90123457<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.89506173<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.88888889<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.88271605<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.87654321<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.87037037<br />sensitivity: 0.993243243<br />model: XGBoost","1 - specificity: 0.87037037<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.86419753<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.85802469<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.85185185<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.84567901<br />sensitivity: 0.989864865<br />model: XGBoost","1 - specificity: 0.84567901<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.83950617<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.83333333<br />sensitivity: 0.986486486<br />model: XGBoost","1 - specificity: 0.83333333<br />sensitivity: 0.983108108<br />model: XGBoost","1 - specificity: 0.83333333<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.82716049<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.82098765<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.81481481<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.80864198<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.80246914<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.79629630<br />sensitivity: 0.979729730<br />model: XGBoost","1 - specificity: 0.79629630<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.79012346<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.78395062<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.77777778<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.77160494<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.76543210<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.75925926<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.75308642<br />sensitivity: 0.976351351<br />model: XGBoost","1 - specificity: 0.75308642<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.74691358<br />sensitivity: 0.972972973<br />model: XGBoost","1 - specificity: 0.74691358<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.74074074<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.73456790<br />sensitivity: 0.969594595<br />model: XGBoost","1 - specificity: 0.73456790<br />sensitivity: 0.966216216<br />model: XGBoost","1 - specificity: 0.72839506<br />sensitivity: 0.966216216<br />model: XGBoost","1 - specificity: 0.72222222<br />sensitivity: 0.966216216<br />model: XGBoost","1 - specificity: 0.72222222<br />sensitivity: 0.962837838<br />model: XGBoost","1 - specificity: 0.71604938<br />sensitivity: 0.962837838<br />model: XGBoost","1 - specificity: 0.71604938<br />sensitivity: 0.959459459<br />model: XGBoost","1 - specificity: 0.70987654<br />sensitivity: 0.959459459<br />model: XGBoost","1 - specificity: 0.70987654<br />sensitivity: 0.956081081<br />model: XGBoost","1 - specificity: 0.70987654<br />sensitivity: 0.952702703<br />model: XGBoost","1 - specificity: 0.70370370<br />sensitivity: 0.952702703<br />model: XGBoost","1 - specificity: 0.69753086<br />sensitivity: 0.952702703<br />model: XGBoost","1 - specificity: 0.69753086<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.69135802<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.68518519<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.67901235<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.67283951<br />sensitivity: 0.949324324<br />model: XGBoost","1 - specificity: 0.67283951<br />sensitivity: 0.945945946<br />model: XGBoost","1 - specificity: 0.66666667<br />sensitivity: 0.945945946<br />model: XGBoost","1 - specificity: 0.66666667<br />sensitivity: 0.942567568<br />model: XGBoost","1 - specificity: 0.66666667<br />sensitivity: 0.939189189<br />model: XGBoost","1 - specificity: 0.66666667<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.66049383<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.65432099<br />sensitivity: 0.935810811<br />model: XGBoost","1 - specificity: 0.65432099<br />sensitivity: 0.932432432<br />model: XGBoost","1 - specificity: 0.64814815<br />sensitivity: 0.932432432<br />model: XGBoost","1 - specificity: 0.64197531<br />sensitivity: 0.932432432<br />model: XGBoost","1 - specificity: 0.64197531<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.63580247<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.62962963<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.62345679<br />sensitivity: 0.929054054<br />model: XGBoost","1 - specificity: 0.62345679<br />sensitivity: 0.925675676<br />model: XGBoost","1 - specificity: 0.61728395<br />sensitivity: 0.925675676<br />model: XGBoost","1 - specificity: 0.61111111<br />sensitivity: 0.925675676<br />model: XGBoost","1 - specificity: 0.61111111<br />sensitivity: 0.922297297<br />model: XGBoost","1 - specificity: 0.60493827<br />sensitivity: 0.922297297<br />model: XGBoost","1 - specificity: 0.59876543<br />sensitivity: 0.922297297<br />model: XGBoost","1 - specificity: 0.59876543<br />sensitivity: 0.918918919<br />model: XGBoost","1 - specificity: 0.59259259<br />sensitivity: 0.918918919<br />model: XGBoost","1 - specificity: 0.58641975<br />sensitivity: 0.918918919<br />model: XGBoost","1 - specificity: 0.58641975<br />sensitivity: 0.915540541<br />model: XGBoost","1 - specificity: 0.58641975<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.58024691<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.57407407<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.56790123<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.56172840<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.55555556<br />sensitivity: 0.912162162<br />model: XGBoost","1 - specificity: 0.55555556<br />sensitivity: 0.908783784<br />model: XGBoost","1 - specificity: 0.55555556<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.54938272<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.54320988<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.53703704<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.53086420<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.52469136<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.51851852<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.51234568<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.905405405<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.902027027<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.898648649<br />model: XGBoost","1 - specificity: 0.50617284<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.50000000<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.49382716<br />sensitivity: 0.895270270<br />model: XGBoost","1 - specificity: 0.49382716<br />sensitivity: 0.891891892<br />model: XGBoost","1 - specificity: 0.49382716<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.48765432<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.48148148<br />sensitivity: 0.888513514<br />model: XGBoost","1 - specificity: 0.48148148<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.47530864<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.46913580<br />sensitivity: 0.885135135<br />model: XGBoost","1 - specificity: 0.46913580<br />sensitivity: 0.881756757<br />model: XGBoost","1 - specificity: 0.46913580<br />sensitivity: 0.878378378<br />model: XGBoost","1 - specificity: 0.46913580<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.46296296<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.45679012<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.45061728<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.44444444<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.43827160<br />sensitivity: 0.875000000<br />model: XGBoost","1 - specificity: 0.43827160<br />sensitivity: 0.871621622<br />model: XGBoost","1 - specificity: 0.43209877<br />sensitivity: 0.871621622<br />model: XGBoost","1 - specificity: 0.42592593<br />sensitivity: 0.871621622<br />model: XGBoost","1 - specificity: 0.41975309<br />sensitivity: 0.871621622<br />model: XGBoost","1 - specificity: 0.41975309<br />sensitivity: 0.868243243<br />model: XGBoost","1 - specificity: 0.41358025<br />sensitivity: 0.868243243<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.868243243<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.864864865<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.861486486<br />model: XGBoost","1 - specificity: 0.40740741<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.40123457<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.39506173<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.38888889<br />sensitivity: 0.858108108<br />model: XGBoost","1 - specificity: 0.38888889<br />sensitivity: 0.854729730<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.854729730<br />model: XGBoost","1 - specificity: 0.38271605<br />sensitivity: 0.851351351<br />model: XGBoost","1 - specificity: 0.37654321<br />sensitivity: 0.851351351<br />model: XGBoost","1 - specificity: 0.37654321<br />sensitivity: 0.847972973<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.847972973<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.844594595<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.841216216<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.837837838<br />model: XGBoost","1 - specificity: 0.37037037<br />sensitivity: 0.834459459<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.834459459<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.831081081<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.827702703<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.824324324<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.820945946<br />model: XGBoost","1 - specificity: 0.36419753<br />sensitivity: 0.817567568<br />model: XGBoost","1 - specificity: 0.35802469<br />sensitivity: 0.817567568<br />model: XGBoost","1 - specificity: 0.35802469<br />sensitivity: 0.814189189<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.814189189<br />model: XGBoost","1 - specificity: 0.35185185<br />sensitivity: 0.810810811<br />model: XGBoost","1 - specificity: 0.34567901<br />sensitivity: 0.810810811<br />model: XGBoost","1 - specificity: 0.34567901<br />sensitivity: 0.807432432<br />model: XGBoost","1 - specificity: 0.34567901<br />sensitivity: 0.804054054<br />model: XGBoost","1 - specificity: 0.33950617<br />sensitivity: 0.804054054<br />model: XGBoost","1 - specificity: 0.33333333<br />sensitivity: 0.804054054<br />model: XGBoost","1 - specificity: 0.33333333<br />sensitivity: 0.800675676<br />model: XGBoost","1 - specificity: 0.33333333<br />sensitivity: 0.797297297<br />model: XGBoost","1 - specificity: 0.33333333<br />sensitivity: 0.793918919<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.793918919<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.790540541<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.787162162<br />model: XGBoost","1 - specificity: 0.32716049<br />sensitivity: 0.783783784<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.783783784<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.780405405<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.777027027<br />model: XGBoost","1 - specificity: 0.32098765<br />sensitivity: 0.773648649<br />model: XGBoost","1 - specificity: 0.31481481<br />sensitivity: 0.773648649<br />model: XGBoost","1 - specificity: 0.30864198<br />sensitivity: 0.773648649<br />model: XGBoost","1 - specificity: 0.30864198<br />sensitivity: 0.770270270<br />model: XGBoost","1 - specificity: 0.30864198<br />sensitivity: 0.766891892<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.766891892<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.763513514<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.760135135<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.756756757<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.753378378<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.750000000<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.746621622<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.743243243<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.739864865<br />model: XGBoost","1 - specificity: 0.30246914<br />sensitivity: 0.736486486<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.736486486<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.733108108<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.729729730<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.726351351<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.722972973<br />model: XGBoost","1 - specificity: 0.29629630<br />sensitivity: 0.719594595<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.719594595<br />model: XGBoost","1 - specificity: 0.29012346<br />sensitivity: 0.716216216<br />model: XGBoost","1 - specificity: 0.28395062<br />sensitivity: 0.716216216<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.716216216<br />model: XGBoost","1 - specificity: 0.27777778<br />sensitivity: 0.712837838<br />model: XGBoost","1 - specificity: 0.27160494<br />sensitivity: 0.712837838<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.712837838<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.709459459<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.706081081<br />model: XGBoost","1 - specificity: 0.26543210<br />sensitivity: 0.702702703<br />model: XGBoost","1 - specificity: 0.25925926<br />sensitivity: 0.702702703<br />model: XGBoost","1 - specificity: 0.25925926<br />sensitivity: 0.699324324<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.699324324<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.695945946<br />model: XGBoost","1 - specificity: 0.25308642<br />sensitivity: 0.692567568<br />model: XGBoost","1 - specificity: 0.24691358<br />sensitivity: 0.692567568<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.692567568<br />model: XGBoost","1 - specificity: 0.24074074<br />sensitivity: 0.689189189<br />model: XGBoost","1 - specificity: 0.23456790<br />sensitivity: 0.689189189<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.689189189<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.685810811<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.682432432<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.679054054<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.675675676<br />model: XGBoost","1 - specificity: 0.22839506<br />sensitivity: 0.672297297<br />model: XGBoost","1 - specificity: 0.22222222<br />sensitivity: 0.672297297<br />model: XGBoost","1 - specificity: 0.21604938<br />sensitivity: 0.672297297<br />model: XGBoost","1 - specificity: 0.21604938<br />sensitivity: 0.668918919<br />model: XGBoost","1 - specificity: 0.21604938<br />sensitivity: 0.665540541<br />model: XGBoost","1 - specificity: 0.21604938<br />sensitivity: 0.662162162<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.662162162<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.658783784<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.655405405<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.652027027<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.648648649<br />model: XGBoost","1 - specificity: 0.20987654<br />sensitivity: 0.645270270<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.645270270<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.641891892<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.638513514<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.635135135<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.631756757<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.628378378<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.625000000<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.621621622<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.618243243<br />model: XGBoost","1 - specificity: 0.20370370<br />sensitivity: 0.614864865<br />model: XGBoost","1 - specificity: 0.19753086<br />sensitivity: 0.614864865<br />model: XGBoost","1 - specificity: 0.19753086<br />sensitivity: 0.611486486<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.611486486<br />model: XGBoost","1 - specificity: 0.19135802<br />sensitivity: 0.608108108<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.608108108<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.604729730<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.601351351<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.597972973<br />model: XGBoost","1 - specificity: 0.18518519<br />sensitivity: 0.594594595<br />model: XGBoost","1 - specificity: 0.17901235<br />sensitivity: 0.594594595<br />model: XGBoost","1 - specificity: 0.17901235<br />sensitivity: 0.591216216<br />model: XGBoost","1 - specificity: 0.17283951<br />sensitivity: 0.591216216<br />model: XGBoost","1 - specificity: 0.17283951<br />sensitivity: 0.587837838<br />model: XGBoost","1 - specificity: 0.17283951<br />sensitivity: 0.584459459<br />model: XGBoost","1 - specificity: 0.17283951<br />sensitivity: 0.581081081<br />model: XGBoost","1 - specificity: 0.16666667<br />sensitivity: 0.581081081<br />model: XGBoost","1 - specificity: 0.16049383<br />sensitivity: 0.581081081<br />model: XGBoost","1 - specificity: 0.16049383<br />sensitivity: 0.577702703<br />model: XGBoost","1 - specificity: 0.16049383<br />sensitivity: 0.574324324<br />model: XGBoost","1 - specificity: 0.15432099<br />sensitivity: 0.574324324<br />model: XGBoost","1 - specificity: 0.15432099<br />sensitivity: 0.570945946<br />model: XGBoost","1 - specificity: 0.15432099<br />sensitivity: 0.567567568<br />model: XGBoost","1 - specificity: 0.15432099<br />sensitivity: 0.564189189<br />model: XGBoost","1 - specificity: 0.14814815<br />sensitivity: 0.564189189<br />model: XGBoost","1 - specificity: 0.14197531<br />sensitivity: 0.564189189<br />model: XGBoost","1 - specificity: 0.14197531<br />sensitivity: 0.560810811<br />model: XGBoost","1 - specificity: 0.13580247<br />sensitivity: 0.560810811<br />model: XGBoost","1 - specificity: 0.13580247<br />sensitivity: 0.557432432<br />model: XGBoost","1 - specificity: 0.12962963<br />sensitivity: 0.557432432<br />model: XGBoost","1 - specificity: 0.12345679<br />sensitivity: 0.557432432<br />model: XGBoost","1 - specificity: 0.12345679<br />sensitivity: 0.554054054<br />model: XGBoost","1 - specificity: 0.12345679<br />sensitivity: 0.550675676<br />model: XGBoost","1 - specificity: 0.11728395<br />sensitivity: 0.550675676<br />model: XGBoost","1 - specificity: 0.11728395<br />sensitivity: 0.547297297<br />model: XGBoost","1 - specificity: 0.11728395<br />sensitivity: 0.543918919<br />model: XGBoost","1 - specificity: 0.11728395<br />sensitivity: 0.540540541<br />model: XGBoost","1 - specificity: 0.11111111<br />sensitivity: 0.540540541<br />model: XGBoost","1 - specificity: 0.11111111<br />sensitivity: 0.537162162<br />model: XGBoost","1 - specificity: 0.11111111<br />sensitivity: 0.533783784<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.533783784<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.530405405<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.527027027<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.523648649<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.520270270<br />model: XGBoost","1 - specificity: 0.10493827<br />sensitivity: 0.516891892<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.516891892<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.513513514<br />model: XGBoost","1 - specificity: 0.09876543<br />sensitivity: 0.510135135<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.510135135<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.506756757<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.503378378<br />model: XGBoost","1 - specificity: 0.09259259<br />sensitivity: 0.500000000<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.500000000<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.496621622<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.493243243<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.489864865<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.486486486<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.483108108<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.479729730<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.476351351<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.472972973<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.469594595<br />model: XGBoost","1 - specificity: 0.08641975<br />sensitivity: 0.466216216<br />model: XGBoost","1 - specificity: 0.08024691<br />sensitivity: 0.466216216<br />model: XGBoost","1 - specificity: 0.08024691<br />sensitivity: 0.462837838<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.462837838<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.459459459<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.456081081<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.452702703<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.449324324<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.445945946<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.442567568<br />model: XGBoost","1 - specificity: 0.07407407<br />sensitivity: 0.439189189<br />model: XGBoost","1 - specificity: 0.06790123<br />sensitivity: 0.439189189<br />model: XGBoost","1 - specificity: 0.06790123<br />sensitivity: 0.435810811<br />model: XGBoost","1 - specificity: 0.06790123<br />sensitivity: 0.432432432<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.432432432<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.429054054<br />model: XGBoost","1 - specificity: 0.06172840<br />sensitivity: 0.425675676<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.425675676<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.422297297<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.418918919<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.415540541<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.412162162<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.408783784<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.405405405<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.402027027<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.398648649<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.395270270<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.391891892<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.388513514<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.385135135<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.381756757<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.378378378<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.375000000<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.371621622<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.368243243<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.364864865<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.361486486<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.358108108<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.354729730<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.351351351<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.347972973<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.344594595<br />model: XGBoost","1 - specificity: 0.05555556<br />sensitivity: 0.341216216<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.341216216<br />model: XGBoost","1 - specificity: 0.04938272<br />sensitivity: 0.337837838<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.337837838<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.334459459<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.331081081<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.327702703<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.324324324<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.320945946<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.317567568<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.314189189<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.310810811<br />model: XGBoost","1 - specificity: 0.04320988<br />sensitivity: 0.307432432<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.307432432<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.304054054<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.300675676<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.297297297<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.293918919<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.290540541<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.287162162<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.283783784<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.280405405<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.277027027<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.273648649<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.270270270<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.266891892<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.263513514<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.260135135<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.256756757<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.253378378<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.250000000<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.246621622<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.243243243<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.239864865<br />model: XGBoost","1 - specificity: 0.03703704<br />sensitivity: 0.236486486<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.236486486<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.233108108<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.229729730<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.226351351<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.222972973<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.219594595<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.216216216<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.212837838<br />model: XGBoost","1 - specificity: 0.03086420<br />sensitivity: 0.209459459<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.209459459<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.206081081<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.202702703<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.199324324<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.195945946<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.192567568<br />model: XGBoost","1 - specificity: 0.02469136<br />sensitivity: 0.189189189<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.189189189<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.185810811<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.182432432<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.179054054<br />model: XGBoost","1 - specificity: 0.01851852<br />sensitivity: 0.175675676<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.175675676<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.172297297<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.168918919<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.165540541<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.162162162<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.158783784<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.155405405<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.152027027<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.148648649<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.145270270<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.141891892<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.138513514<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.135135135<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.131756757<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.128378378<br />model: XGBoost","1 - specificity: 0.01234568<br />sensitivity: 0.125000000<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.125000000<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.121621622<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.118243243<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.114864865<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.111486486<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.108108108<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.104729730<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.101351351<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.097972973<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.094594595<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.091216216<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.087837838<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.084459459<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.081081081<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.077702703<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.074324324<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.070945946<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.067567568<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.064189189<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.060810811<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.057432432<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.054054054<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.050675676<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.047297297<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.043918919<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.040540541<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.037162162<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.033783784<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.030405405<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.027027027<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.023648649<br />model: XGBoost","1 - specificity: 0.00617284<br />sensitivity: 0.020270270<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.020270270<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.016891892<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.013513514<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.010135135<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.006756757<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.003378378<br />model: XGBoost","1 - specificity: 0.00000000<br />sensitivity: 0.000000000<br />model: XGBoost"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGBoost","legendgroup":"XGBoost","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-0.05,1.05],"y":[-0.05,1.05],"text":"intercept: 0<br />slope: 1","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"dot"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":27.1581569115816,"r":7.97011207970112,"b":43.8356164383562,"l":53.3997509339975},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":{"text":"1 - specificity","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"scaleanchor":"y","scaleratio":1,"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":{"text":"sensitivity","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"scaleanchor":"x","scaleratio":1,"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"title":{"text":"model","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"orientation":"h","xanchor":"center","x":0.5,"y":1},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"488c75e25bc":{"x":{},"y":{},"colour":{},"type":"scatter"},"488c158c8c7":{"intercept":{},"slope":{}}},"cur_data":"488c75e25bc","visdat":{"488c75e25bc":["function (y) ","x"],"488c158c8c7":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="model-interpretation" class="section level1">
<h1>Model interpretation</h1>
<div id="define-explainers" class="section level2">
<h2>Define explainers</h2>
<div id="random-forest-7" class="section level3">
<h3>Random forest</h3>
<p>Create explainer for random forest:</p>
<pre class="r"><code>explainer_rf &lt;- explain_tidymodels(
  rf_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;RF&quot;
)
explainer_rf</code></pre>
<pre><code>Model label:  RF 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
<div id="neural-network-7" class="section level3">
<h3>Neural network</h3>
<p>Create explainer for neural network:</p>
<pre class="r"><code>explainer_nnet &lt;- explain_tidymodels(
  nnet_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;NNet&quot;
)
explainer_nnet</code></pre>
<pre><code>Model label:  NNet 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
<div id="xgboost-7" class="section level3">
<h3>XGBoost</h3>
<p>Create explainer for XGBoost:</p>
<pre class="r"><code>explainer_xgb &lt;- explain_tidymodels(
  xgb_final_res$.workflow[[1]],
  data = select(ist_train, -dead_or_dep),
  y = as.numeric(pull(ist_train, dead_or_dep)) - 1,
  verbose = FALSE,
  label = &quot;XGB&quot;
)
explainer_xgb</code></pre>
<pre><code>Model label:  XGB 
Model class:  workflow 
Data head  :
  RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP RDEF1
1     27      F   M  71      N       N   Y       N      N     N  180     N
2     19      F   F  78      N       N   Y       N      N     N  205     Y
  RDEF2 RDEF3 RDEF4 RDEF5 RDEF6 RDEF7 RDEF8 STYPE       treatment
1     Y     N     N     N     N     N     N  PACS yes_asp_low_hep
2     Y     Y     Y     N     N     N     N  PACS  no_asp_low_hep</code></pre>
</div>
</div>
<div id="residual-diagnostics" class="section level2">
<h2>Residual diagnostics</h2>
<div id="random-forest-8" class="section level3">
<h3>Random forest</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_rf &lt;- model_performance(explainer_rf)
resid_diag_rf</code></pre>
<pre><code>Measures for:  classification
recall     : 0.9785553 
precision  : 0.908805 
f1         : 0.9423913 
accuracy   : 0.9227405 
auc        : 0.9860914

Residuals:
         0%         10%         20%         30%         40%         50% 
-0.75609602 -0.43007249 -0.29355471 -0.19241522  0.02811013  0.07827345 
        60%         70%         80%         90%        100% 
 0.13052465  0.18849124  0.24863228  0.33209169  0.61527927 </code></pre>
</div>
<div id="neural-network-8" class="section level3">
<h3>Neural network</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_nnet &lt;- model_performance(explainer_nnet)
resid_diag_nnet</code></pre>
<pre><code>Measures for:  classification
recall     : 0.9266366 
precision  : 0.7917068 
f1         : 0.8538742 
accuracy   : 0.7951895 
auc        : 0.8158436

Residuals:
        0%        10%        20%        30%        40%        50%        60% 
-0.7162404 -0.5770669 -0.3486062 -0.3480058  0.2837596  0.2837596  0.2846670 
       70%        80%        90%       100% 
 0.3740048  0.4229331  0.4229331  0.6519942 </code></pre>
</div>
<div id="xgboost-8" class="section level3">
<h3>XGBoost</h3>
<p>Compute residuals:</p>
<pre class="r"><code>resid_diag_xgb &lt;- model_performance(explainer_xgb)
resid_diag_xgb</code></pre>
<pre><code>Measures for:  classification
recall     : 0.8634312 
precision  : 0.775076 
f1         : 0.8168713 
accuracy   : 0.75 
auc        : 0.8034631

Residuals:
         0%         10%         20%         30%         40%         50% 
-0.94972245 -0.61806973 -0.44333532 -0.28880954  0.04728317  0.11064526 
        60%         70%         80%         90%        100% 
 0.17327046  0.25320619  0.35129561  0.48108965  0.85049576 </code></pre>
<p>Create residual diagnostics plot:</p>
<pre class="r"><code>resid_diag_line &lt;- plot(resid_diag_rf, resid_diag_nnet, resid_diag_xgb)
resid_diag_box &lt;- plot(
  resid_diag_rf, resid_diag_nnet, resid_diag_xgb, geom = &quot;boxplot&quot;
)

resid_diag_plot &lt;- resid_diag_box + resid_diag_line
resid_diag_plot</code></pre>
<p><img src="figure/modeling.Rmd/resid-diag-plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># TODO: Convert it into an interactive plot
resid_diag_plot2 &lt;- resid_diag_plot
resid_diag_plot2</code></pre>
<p><img src="figure/modeling.Rmd/resid-diag-plot2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>export(resid_diag_plot2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;resid-diag-plot.rds&quot;))</code></pre>
</div>
</div>
<div id="variable-importance" class="section level2">
<h2>Variable importance</h2>
<div id="random-forest-9" class="section level3">
<h3>Random forest</h3>
<p>Compute variable importance for random forest:</p>
<pre class="r"><code>vip_rf &lt;- model_parts(explainer_rf, loss_function = loss_one_minus_auc)
vip_rf</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_        0.01425060    RF
2         RDEF8        0.01590064    RF
3        RHEP24        0.01604213    RF
4         RDEF7        0.01624788    RF
5         RDEF2        0.01653076    RF
6       RATRIAL        0.01745047    RF
7         RASP3        0.01853563    RF
8           SEX        0.02067901    RF
9         RDEF4        0.02159015    RF
10       RSLEEP        0.02165307    RF
11        STYPE        0.02169939    RF
12      RVISINF        0.02183946    RF
13        RDEF1        0.02297348    RF
14       RCONSC        0.02505181    RF
15        RDEF5        0.03221375    RF
16          RCT        0.03530247    RF
17         RSBP        0.04825853    RF
18    treatment        0.04994768    RF
19        RDEF6        0.06291630    RF
20        RDEF3        0.06298674    RF
21       RDELAY        0.06463645    RF
22          AGE        0.23205263    RF
23   _baseline_        0.50429581    RF</code></pre>
</div>
<div id="neural-network-9" class="section level3">
<h3>Neural network</h3>
<p>Compute variable importance for neural network:</p>
<pre class="r"><code>vip_nnet &lt;- model_parts(explainer_nnet, loss_function = loss_one_minus_auc)
vip_nnet</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_         0.1851454  NNet
2        RHEP24         0.1860182  NNet
3        RDELAY         0.1886149  NNet
4         RASP3         0.1908306  NNet
5         RDEF2         0.1931710  NNet
6           SEX         0.1962104  NNet
7          RSBP         0.1974317  NNet
8         RDEF8         0.2021403  NNet
9       RATRIAL         0.2022920  NNet
10       RSLEEP         0.2055098  NNet
11        RDEF7         0.2149349  NNet
12        STYPE         0.2154834  NNet
13        RDEF1         0.2160364  NNet
14      RVISINF         0.2163113  NNet
15        RDEF4         0.2165832  NNet
16        RDEF3         0.2168414  NNet
17          RCT         0.2192947  NNet
18        RDEF6         0.2288890  NNet
19       RCONSC         0.2381560  NNet
20    treatment         0.2411572  NNet
21        RDEF5         0.2460428  NNet
22          AGE         0.2930101  NNet
23   _baseline_         0.5015140  NNet</code></pre>
</div>
<div id="xgboost-9" class="section level3">
<h3>XGBoost</h3>
<p>Compute variable importance for XGBoost:</p>
<pre class="r"><code>vip_xgb &lt;- model_parts(explainer_xgb, loss_function = loss_one_minus_auc)
vip_xgb</code></pre>
<pre><code>       variable mean_dropout_loss label
1  _full_model_         0.1953273   XGB
2        RHEP24         0.1953273   XGB
3         RDEF8         0.1956459   XGB
4         RASP3         0.1956639   XGB
5         RDEF7         0.1960057   XGB
6        RSLEEP         0.1964225   XGB
7       RATRIAL         0.1964565   XGB
8         RDEF2         0.1966020   XGB
9         RDEF1         0.1974145   XGB
10          SEX         0.1975457   XGB
11      RVISINF         0.1982570   XGB
12        STYPE         0.1984947   XGB
13        RDEF4         0.1995500   XGB
14        RDEF5         0.1996109   XGB
15       RDELAY         0.2013358   XGB
16         RSBP         0.2028924   XGB
17    treatment         0.2040234   XGB
18        RDEF6         0.2076031   XGB
19       RCONSC         0.2077900   XGB
20          RCT         0.2101955   XGB
21        RDEF3         0.2152059   XGB
22          AGE         0.2652844   XGB
23   _baseline_         0.5052814   XGB</code></pre>
<p>Create variable importance plot:</p>
<pre class="r"><code>vip_plot &lt;- plot_vip(vip_rf, vip_nnet, vip_xgb)
vip_plot</code></pre>
<p><img src="figure/modeling.Rmd/vip-plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>vip_plot2 &lt;- ggplotly(vip_plot)
vip_plot2</code></pre>
<div id="htmlwidget-d34d0cab8ffedbe4216b" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-d34d0cab8ffedbe4216b">{"x":{"data":[{"x":[0.293010127659843,0.246042768457136,0.241157239393108,0.238156023067471,0.228889049717385,0.219294725555076,0.216841389756746,0.216583216350399,0.216311292208091,0.216036357144957],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___NNet<br />dropout_loss: 0.29301013<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.29301013","tidytext::reorder_within(variable, dropout_loss, label): RDEF5___NNet<br />dropout_loss: 0.24604277<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.24604277","tidytext::reorder_within(variable, dropout_loss, label): treatment___NNet<br />dropout_loss: 0.24115724<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.24115724","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___NNet<br />dropout_loss: 0.23815602<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.23815602","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___NNet<br />dropout_loss: 0.22888905<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.22888905","tidytext::reorder_within(variable, dropout_loss, label): RCT___NNet<br />dropout_loss: 0.21929473<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.21929473","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___NNet<br />dropout_loss: 0.21684139<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.21684139","tidytext::reorder_within(variable, dropout_loss, label): RDEF4___NNet<br />dropout_loss: 0.21658322<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.21658322","tidytext::reorder_within(variable, dropout_loss, label): RVISINF___NNet<br />dropout_loss: 0.21631129<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.21631129","tidytext::reorder_within(variable, dropout_loss, label): RDEF1___NNet<br />dropout_loss: 0.21603636<br />label: NNet<br />y_min: 0.1851454<br />dropout_loss: 0.21603636"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.107864766831076,0.0608974076283683,0.0560118785643401,0.0530106622387029,0.0437436888886175,0.0341493647263086,0.0316960289279784,0.0314378555216314,0.0311659313793231,0.0308909963161892],"type":"data","width":0,"symmetric":false,"color":"rgba(67,120,191,1)"},"name":"NNet","legendgroup":"NNet","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.232052628562377,0.0646364485580852,0.0629867409564246,0.0629162980960832,0.0499476787854686,0.0482585281442529,0.0353024669174893,0.0322137470491196,0.0250518130352004,0.0229734768849988],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___RF<br />dropout_loss: 0.23205263<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.23205263","tidytext::reorder_within(variable, dropout_loss, label): RDELAY___RF<br />dropout_loss: 0.06463645<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.06463645","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___RF<br />dropout_loss: 0.06298674<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.06298674","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___RF<br />dropout_loss: 0.06291630<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.06291630","tidytext::reorder_within(variable, dropout_loss, label): treatment___RF<br />dropout_loss: 0.04994768<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.04994768","tidytext::reorder_within(variable, dropout_loss, label): RSBP___RF<br />dropout_loss: 0.04825853<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.04825853","tidytext::reorder_within(variable, dropout_loss, label): RCT___RF<br />dropout_loss: 0.03530247<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.03530247","tidytext::reorder_within(variable, dropout_loss, label): RDEF5___RF<br />dropout_loss: 0.03221375<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.03221375","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___RF<br />dropout_loss: 0.02505181<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.02505181","tidytext::reorder_within(variable, dropout_loss, label): RDEF1___RF<br />dropout_loss: 0.02297348<br />label: RF<br />y_min: 0.0142506<br />dropout_loss: 0.02297348"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.217802025362847,0.0503858453585556,0.0487361377568951,0.0486656948965537,0.0356970755859391,0.0340079249447234,0.0210518637179598,0.0179631438495901,0.0108012098356709,0.00872287368546931],"type":"data","width":0,"symmetric":false,"color":"rgba(240,90,113,1)"},"name":"RF","legendgroup":"RF","showlegend":true,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[0.265284350651304,0.215205861858939,0.210195542489431,0.207789996919731,0.207603111469987,0.204023429265134,0.202892419381318,0.20133576467534,0.19961088494341,0.19955004235352],"y":[10,9,8,7,6,5,4,3,2,1],"text":["tidytext::reorder_within(variable, dropout_loss, label): AGE___XGB<br />dropout_loss: 0.26528435<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.26528435","tidytext::reorder_within(variable, dropout_loss, label): RDEF3___XGB<br />dropout_loss: 0.21520586<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.21520586","tidytext::reorder_within(variable, dropout_loss, label): RCT___XGB<br />dropout_loss: 0.21019554<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.21019554","tidytext::reorder_within(variable, dropout_loss, label): RCONSC___XGB<br />dropout_loss: 0.20779000<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.20779000","tidytext::reorder_within(variable, dropout_loss, label): RDEF6___XGB<br />dropout_loss: 0.20760311<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.20760311","tidytext::reorder_within(variable, dropout_loss, label): treatment___XGB<br />dropout_loss: 0.20402343<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.20402343","tidytext::reorder_within(variable, dropout_loss, label): RSBP___XGB<br />dropout_loss: 0.20289242<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.20289242","tidytext::reorder_within(variable, dropout_loss, label): RDELAY___XGB<br />dropout_loss: 0.20133576<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.20133576","tidytext::reorder_within(variable, dropout_loss, label): RDEF5___XGB<br />dropout_loss: 0.19961088<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.19961088","tidytext::reorder_within(variable, dropout_loss, label): RDEF4___XGB<br />dropout_loss: 0.19955004<br />label: XGB<br />y_min: 0.1953273<br />dropout_loss: 0.19955004"],"type":"scatter","mode":"lines","opacity":0.8,"line":{"color":"transparent"},"error_x":{"array":[0,0,0,0,0,0,0,0,0,0],"arrayminus":[0.0699570881099043,0.0198785993175384,0.014868279948031,0.0124627343783311,0.0122758489285872,0.00869616672373352,0.00756515683991807,0.00600850213394027,0.00428362240200986,0.0042227798121196],"type":"data","width":0,"symmetric":false,"color":"rgba(139,220,190,1)"},"name":"XGB","legendgroup":"XGB","showlegend":true,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"x":[0.216036357144957,0.215729464721893,0.219844477234217,0.215917021425082,0.215252747252747,0.226433341610361,0.224370440516274,0.207172098178373,0.21132163702177,0.211634431400941,0.212687912087912,0.228563850308642,0.216311292208091,0.208331843615367,0.213251971526275,0.217943069997906,0.218386813186813,0.219624397192781,0.213195791427858,0.205333902190964,0.223237326590346,0.215243956043956,0.218810989010989,0.209398335543304,0.216204258209836,0.222214235616486,0.212668187450469,0.225424821127946,0.216583216350399,0.214571411124293,0.206559962765682,0.216307435182459,0.223672527472527,0.20742907452761,0.225446632774416,0.221704896184063,0.206621978021978,0.215257451635809,0.229720085292328,0.209197693488729,0.216841389756746,0.217523076923077,0.211036185358364,0.224476823361087,0.229201739618406,0.228015292956234,0.227362637362637,0.218248394863563,0.212421119433669,0.219294725555076,0.20306284458092,0.220043956043956,0.226662048956441,0.205260640223406,0.222668581511531,0.227843956043956,0.220595034545328,0.23973104016101,0.228889049717385,0.241556186868687,0.216905915372102,0.226117052829925,0.225829826919625,0.221919118787816,0.2312,0.237192365645404,0.24715140232025,0.227977459707256,0.238156023067471,0.23989010989011,0.240779189057157,0.229415384615385,0.259373246352413,0.221133714844023,0.242751866156324,0.251726195921604,0.221361661810186,0.227344894968246,0.21941735292065,0.258199702898267,0.239350785430991,0.270353272306397,0.238254945054945,0.240734065934066,0.241157239393108,0.239475285803731,0.23161390085629,0.246828187757494,0.243206886072329,0.2403844476237,0.23568374963369,0.257131868131868,0.246042768457136,0.262534196127946,0.246694175513951,0.229500198213033,0.250841758212889,0.25747032967033,0.236980075371624,0.296069160443855,0.315748632154882,0.299630665581323,0.293010127659843,0.297128608395252,0.286682698108979,0.299041758241758,0.288021978021978,0.288855199933784,0.26556284458092,0.293359731135701],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x","yaxis":"y","orientation":"h","frame":null},{"x":[0.0229734768849988,0.0218855218855218,0.0227086159289549,0.022618732047332,0.0233134217243335,0.0225380495306783,0.0253494866064622,0.0253469067028389,0.0183688175565018,0.0245887238118093,0.0230164930555555,0.0227612939477346,0.0252161001219706,0.0260141616073819,0.0250518130352004,0.0262728242750441,0.0308384629123811,0.0215801389715756,0.0230723878152637,0.0238364548260381,0.0267664930555556,0.0241598128190584,0.0294835680751174,0.0308912681794038,0.0319554188541832,0.0322137470491196,0.0415724610217337,0.034100237490068,0.0308910592739648,0.03056169332211,0.0333306193461577,0.0302626032617906,0.0290885416666666,0.0322655311715253,0.0340059394389352,0.0312556244759634,0.040469887927515,0.0350868055555555,0.0369945020333478,0.0328677398989899,0.0343474463212512,0.0353024669174893,0.0386406506615088,0.0370905416903006,0.0513132157995391,0.0491174542228926,0.0450265365519603,0.0482585281442529,0.0475501543209876,0.0432730550989022,0.0522829336388658,0.0425068238890709,0.0513281250000001,0.0482442923993194,0.0519426905209913,0.0540024943616129,0.0499476787854686,0.0427007654098389,0.060108646880214,0.0434944841724503,0.0512456597222223,0.0405415438366634,0.0543154538715027,0.0561985961429382,0.0464848134118967,0.050384330045347,0.0579755743051616,0.0648744723394801,0.0629162980960832,0.06824757996633,0.0686110242159077,0.0636174873463009,0.0634418939503686,0.055147513743791,0.0649055488681943,0.0530319903919642,0.0693098958333334,0.061666120755541,0.0680453721519204,0.0629867409564246,0.0634722222222223,0.0543299570451291,0.0625111355429148,0.0604480265497215,0.0619682359614294,0.0668578142536476,0.0694181249482686,0.061150400133451,0.0671644739441349,0.0599907004636732,0.0705578163205282,0.0658713874859709,0.0646364485580852,0.0682339228399161,0.0645074092456041,0.0594912108308767,0.0666419190044369,0.0610844648901551,0.0628211805555555,0.232052628562377,0.259259259259259,0.198785893656513,0.222498382320802,0.24871487583352,0.239171906709137,0.237569444444444,0.236339085297419,0.217350762758304,0.245884356853161,0.214952318491208],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x2","yaxis":"y2","orientation":"h","frame":null},{"x":[0.19955004235352,0.190868260212328,0.205751719620046,0.206869245897074,0.193641391583502,0.19250744469654,0.212807995763598,0.191003179210726,0.192928283837375,0.216076999668105,0.193045903045903,0.190726726104085,0.196259116259116,0.207443568457509,0.19961088494341,0.195207165292244,0.202655311715253,0.19137326401005,0.191616739931934,0.209265794169607,0.197196742651288,0.214364420843014,0.203961131127852,0.194248772603909,0.221630711361876,0.194612344015882,0.208400772724899,0.20133576467534,0.192841790244388,0.196091806091806,0.21003564451604,0.197697850512946,0.193836823553805,0.19990561990562,0.20537176547658,0.223237083748202,0.208286793729057,0.19530980026263,0.193190184316339,0.202892419381318,0.196198773397618,0.206917106110444,0.199363407155615,0.201143659711075,0.214256471415412,0.212273099079344,0.222604270383892,0.197288167807036,0.197271164208735,0.198021354731628,0.204023429265134,0.200249966483733,0.204769079593842,0.197606253053249,0.195894465894466,0.20413038219642,0.224445181989158,0.202471042471043,0.209324162026422,0.202836961145774,0.218984598543069,0.205605764533464,0.201439253387305,0.195973879442912,0.207603111469987,0.210819888964305,0.205974451359319,0.205453254396626,0.202661560471771,0.200262336925695,0.207789996919731,0.209684296628901,0.218428348292757,0.205309841673478,0.202080652080652,0.221953755946454,0.20609147142166,0.204907646466088,0.210195542489431,0.206390885616582,0.223073348821772,0.214499399497762,0.214957621956526,0.208687258687259,0.210088389943847,0.205283075723199,0.216706197517789,0.197361600663488,0.214015444015444,0.228810202964591,0.201465201465202,0.235795995132205,0.215205861858939,0.21514963024397,0.207996022053179,0.212998418652064,0.215901299268479,0.223328808367706,0.196597596426546,0.265284350651304,0.256570269557283,0.28953202787919,0.266284856284856,0.262761273255713,0.254156779956731,0.266258914141084,0.276353313680533,0.259266016669707,0.260120775450964,0.261539279636982],"y":[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10],"hoverinfo":"x","type":"box","fillcolor":"rgba(255,255,255,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(0,0,0,1)","width":1.88976377952756},"showlegend":false,"xaxis":"x3","yaxis":"y3","orientation":"h","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":43.8356164383562,"l":69.3399750933998},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.29645862647108],"automargin":true,"type":"linear","autorange":false,"range":[0.178615197262462,0.322278795721188],"tickmode":"array","ticktext":["0.20","0.24","0.28","0.32"],"tickvals":[0.2,0.24,0.28,0.32],"categoryorder":"array","categoryarray":["0.20","0.24","0.28","0.32"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"annotations":[{"text":"One minus AUC loss after permutations","x":0.5,"y":0,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis","yshift":-23.9103362391034},{"text":"NNet","x":0.14822931323554,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RF","x":0.5,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"XGB","x":0.85177068676446,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["RDEF1","RVISINF","RDEF4","RDEF3","RCT","RDEF6","RCONSC","treatment","RDEF5","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["RDEF1","RVISINF","RDEF4","RDEF3","RCT","RDEF6","RCONSC","treatment","RDEF5","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.29645862647108,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.29645862647108,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.370208040195587,"x1":0.629791959804413,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.370208040195587,"x1":0.629791959804413,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.70354137352892,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.70354137352892,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[0.00200017039654302,0.271509692062246],"tickmode":"array","ticktext":["0.1","0.2"],"tickvals":[0.1,0.2],"categoryorder":"array","categoryarray":["0.1","0.2"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.370208040195587,0.629791959804413],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["RDEF1","RCONSC","RDEF5","RCT","RSBP","treatment","RDEF6","RDEF3","RDELAY","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["RDEF1","RCONSC","RDEF5","RCT","RSBP","treatment","RDEF6","RDEF3","RDELAY","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"xaxis3":{"type":"linear","autorange":false,"range":[0.185786461015329,0.294472292967945],"tickmode":"array","ticktext":["0.21","0.24","0.27"],"tickvals":[0.21,0.24,0.27],"categoryorder":"array","categoryarray":["0.21","0.24","0.27"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.70354137352892,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y3","title":"","hoverformat":".2f"},"yaxis3":{"type":"linear","autorange":false,"range":[0.4,10.6],"tickmode":"array","ticktext":["RDEF4","RDEF5","RDELAY","RSBP","treatment","RDEF6","RCONSC","RCT","RDEF3","AGE"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"categoryorder":"array","categoryarray":["RDEF4","RDEF5","RDELAY","RSBP","treatment","RDEF6","RCONSC","RCT","RDEF3","AGE"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x3","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"488c5aa37f5c":{"x":{},"y":{},"colour":{},"ymin":{},"ymax":{},"type":"scatter"},"488c41226f07":{"x":{},"y":{},"colour":{}}},"cur_data":"488c5aa37f5c","visdat":{"488c5aa37f5c":["function (y) ","x"],"488c41226f07":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="global-interpretation" class="section level2">
<h2>Global interpretation</h2>
<div id="random-forest-10" class="section level3">
<h3>Random forest</h3>
<p>Create PDP for age and blood pressure using random forest
explainer:</p>
<pre class="r"><code>pdp_age_rf &lt;- model_profile(explainer_rf, &quot;AGE&quot;)
pdp_rsbp_rf &lt;- model_profile(explainer_rf, &quot;RSBP&quot;)</code></pre>
</div>
<div id="neural-network-10" class="section level3">
<h3>Neural network</h3>
<p>Create PDP for age and blood pressure using neural network
explainer:</p>
<pre class="r"><code>pdp_age_nnet &lt;- model_profile(explainer_nnet, &quot;AGE&quot;)
pdp_rsbp_nnet &lt;- model_profile(explainer_nnet, &quot;RSBP&quot;)</code></pre>
</div>
<div id="xgboost-10" class="section level3">
<h3>XGBoost</h3>
<p>Create PDP for age and blood pressure using XGBoost explainer:</p>
<pre class="r"><code>pdp_age_xgb &lt;- model_profile(explainer_xgb, &quot;AGE&quot;)
pdp_rsbp_xgb &lt;- model_profile(explainer_xgb, &quot;RSBP&quot;)</code></pre>
<p>Create PDP profiles for age and blood pressure:</p>
<pre class="r"><code>pdp_age_rsbp &lt;- plot_pdp(
  pdp_age_rf, pdp_rsbp_rf, pdp_age_nnet, pdp_rsbp_nnet, pdp_age_xgb, 
  pdp_rsbp_xgb
)
pdp_age_rsbp</code></pre>
<p><img src="figure/modeling.Rmd/pdp-age-rsbp-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>pdp_age_rsbp2 &lt;- ggplotly(pdp_age_rsbp) %&gt;%
  layout(legend = list(orientation = &quot;h&quot;, xanchor = &quot;center&quot;, x = 0.5, y = 1))
pdp_age_rsbp2</code></pre>
<div id="htmlwidget-5c89bfca271851966cab" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-5c89bfca271851966cab">{"x":{"data":[{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.385186784785038,0.44985070603843,0.462127930215343,0.475566984558626,0.485513740143709,0.491115801353326,0.494079731492766,0.49771933867854,0.499435757742157,0.501531144694026,0.504936974094955,0.506147510616218,0.509390134684541,0.513105482029847,0.518649241718145,0.524739450384686,0.527414410081508,0.529462391698982,0.53155993199025,0.53402156406694,0.539586117413148,0.544345899213704,0.547607977501621,0.553125568932533,0.559799078937294,0.566016463519622,0.570901240539138,0.576160787825789,0.579346909177218,0.580934571841068,0.582402009918979,0.585009688665089,0.591695825459481,0.59861552651163,0.602639895248972,0.605665188134648,0.609264442585168,0.614064996727691,0.619836811549437,0.624818061784532,0.628750263366159,0.632012711878272,0.635893155822022,0.638456817890021,0.640298695854857,0.64758130185446],"text":["_x_:  22.00<br />_yhat_: 0.3851868<br />_label_: NNet","_x_:  41.00<br />_yhat_: 0.4498507<br />_label_: NNet","_x_:  44.00<br />_yhat_: 0.4621279<br />_label_: NNet","_x_:  46.00<br />_yhat_: 0.4755670<br />_label_: NNet","_x_:  48.00<br />_yhat_: 0.4855137<br />_label_: NNet","_x_:  51.00<br />_yhat_: 0.4911158<br />_label_: NNet","_x_:  52.00<br />_yhat_: 0.4940797<br />_label_: NNet","_x_:  53.00<br />_yhat_: 0.4977193<br />_label_: NNet","_x_:  55.00<br />_yhat_: 0.4994358<br />_label_: NNet","_x_:  56.00<br />_yhat_: 0.5015311<br />_label_: NNet","_x_:  57.00<br />_yhat_: 0.5049370<br />_label_: NNet","_x_:  58.00<br />_yhat_: 0.5061475<br />_label_: NNet","_x_:  59.23<br />_yhat_: 0.5093901<br />_label_: NNet","_x_:  60.00<br />_yhat_: 0.5131055<br />_label_: NNet","_x_:  61.00<br />_yhat_: 0.5186492<br />_label_: NNet","_x_:  62.00<br />_yhat_: 0.5247395<br />_label_: NNet","_x_:  63.00<br />_yhat_: 0.5274144<br />_label_: NNet","_x_:  64.00<br />_yhat_: 0.5294624<br />_label_: NNet","_x_:  65.00<br />_yhat_: 0.5315599<br />_label_: NNet","_x_:  66.00<br />_yhat_: 0.5340216<br />_label_: NNet","_x_:  67.00<br />_yhat_: 0.5395861<br />_label_: NNet","_x_:  68.00<br />_yhat_: 0.5443459<br />_label_: NNet","_x_:  69.00<br />_yhat_: 0.5476080<br />_label_: NNet","_x_:  70.00<br />_yhat_: 0.5531256<br />_label_: NNet","_x_:  71.00<br />_yhat_: 0.5597991<br />_label_: NNet","_x_:  72.00<br />_yhat_: 0.5660165<br />_label_: NNet","_x_:  73.00<br />_yhat_: 0.5709012<br />_label_: NNet","_x_:  74.00<br />_yhat_: 0.5761608<br />_label_: NNet","_x_:  75.00<br />_yhat_: 0.5793469<br />_label_: NNet","_x_:  76.00<br />_yhat_: 0.5809346<br />_label_: NNet","_x_:  77.00<br />_yhat_: 0.5824020<br />_label_: NNet","_x_:  78.00<br />_yhat_: 0.5850097<br />_label_: NNet","_x_:  79.00<br />_yhat_: 0.5916958<br />_label_: NNet","_x_:  80.00<br />_yhat_: 0.5986155<br />_label_: NNet","_x_:  81.00<br />_yhat_: 0.6026399<br />_label_: NNet","_x_:  82.00<br />_yhat_: 0.6056652<br />_label_: NNet","_x_:  83.00<br />_yhat_: 0.6092644<br />_label_: NNet","_x_:  84.00<br />_yhat_: 0.6140650<br />_label_: NNet","_x_:  85.00<br />_yhat_: 0.6198368<br />_label_: NNet","_x_:  86.00<br />_yhat_: 0.6248181<br />_label_: NNet","_x_:  87.00<br />_yhat_: 0.6287503<br />_label_: NNet","_x_:  88.00<br />_yhat_: 0.6320127<br />_label_: NNet","_x_:  89.00<br />_yhat_: 0.6358932<br />_label_: NNet","_x_:  90.00<br />_yhat_: 0.6384568<br />_label_: NNet","_x_:  91.29<br />_yhat_: 0.6402987<br />_label_: NNet","_x_:  94.00<br />_yhat_: 0.6475813<br />_label_: NNet"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"NNet","legendgroup":"NNet","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.535049845187272,0.538097958989317,0.53944941348651,0.540414687612715,0.540887098018045,0.541493271808838,0.541916214148844,0.542643278497656,0.543582070156921,0.543983029353407,0.544592860206281,0.544800782591013,0.545644748596138,0.546559089071992,0.546864572684636,0.547833399365539,0.54910600478768,0.550418589593374,0.550903626629265,0.551435264583927,0.5520496987034,0.552507847753583,0.553019056709832,0.554469585918941,0.556755921973446,0.556827083261772,0.559622545610245,0.561123936680879,0.567383578996563],"text":["_x_:  90.00<br />_yhat_: 0.5350498<br />_label_: NNet","_x_: 104.13<br />_yhat_: 0.5380980<br />_label_: NNet","_x_: 110.00<br />_yhat_: 0.5394494<br />_label_: NNet","_x_: 115.84<br />_yhat_: 0.5404147<br />_label_: NNet","_x_: 120.00<br />_yhat_: 0.5408871<br />_label_: NNet","_x_: 126.10<br />_yhat_: 0.5414933<br />_label_: NNet","_x_: 130.00<br />_yhat_: 0.5419162<br />_label_: NNet","_x_: 135.00<br />_yhat_: 0.5426433<br />_label_: NNet","_x_: 140.00<br />_yhat_: 0.5435821<br />_label_: NNet","_x_: 142.01<br />_yhat_: 0.5439830<br />_label_: NNet","_x_: 145.00<br />_yhat_: 0.5445929<br />_label_: NNet","_x_: 146.00<br />_yhat_: 0.5448008<br />_label_: NNet","_x_: 150.00<br />_yhat_: 0.5456447<br />_label_: NNet","_x_: 154.32<br />_yhat_: 0.5465591<br />_label_: NNet","_x_: 155.74<br />_yhat_: 0.5468646<br />_label_: NNet","_x_: 160.00<br />_yhat_: 0.5478334<br />_label_: NNet","_x_: 165.00<br />_yhat_: 0.5491060<br />_label_: NNet","_x_: 170.00<br />_yhat_: 0.5504186<br />_label_: NNet","_x_: 172.12<br />_yhat_: 0.5509036<br />_label_: NNet","_x_: 175.00<br />_yhat_: 0.5514353<br />_label_: NNet","_x_: 180.00<br />_yhat_: 0.5520497<br />_label_: NNet","_x_: 185.00<br />_yhat_: 0.5525078<br />_label_: NNet","_x_: 190.00<br />_yhat_: 0.5530191<br />_label_: NNet","_x_: 200.00<br />_yhat_: 0.5544696<br />_label_: NNet","_x_: 209.74<br />_yhat_: 0.5567559<br />_label_: NNet","_x_: 210.00<br />_yhat_: 0.5568271<br />_label_: NNet","_x_: 220.00<br />_yhat_: 0.5596225<br />_label_: NNet","_x_: 232.32<br />_yhat_: 0.5611239<br />_label_: NNet","_x_: 270.00<br />_yhat_: 0.5673836<br />_label_: NNet"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(67,120,191,0.8)","dash":"solid"},"hoveron":"points","name":"NNet","legendgroup":"NNet","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.242182558164058,0.244036571567322,0.241858173715174,0.312012921883672,0.486672142163392,0.511141082584083,0.496950878038628,0.487466115856366,0.500908490953491,0.505455608197358,0.511264977855478,0.541143752386502,0.546269801504051,0.546608280552781,0.547471271117771,0.545271056082806,0.541788411893662,0.539775574453324,0.553053297369297,0.581534081723832,0.598187884282384,0.587503725690976,0.607016148545899,0.605804868353868,0.597386869297369,0.589289361721612,0.599207748834499,0.652288359002109,0.677861557831058,0.678987803557554,0.712735125846376,0.719367092657343,0.730898945609946,0.718035073704074,0.720326018009768,0.726931573509824,0.793709689227439,0.818757081030081,0.824640894633145,0.853028321928072,0.85812573945499,0.859826232295482,0.861655715478966,0.856523353424354,0.850203162504163,0.851063515068265],"text":["_x_:  22.00<br />_yhat_: 0.2421826<br />_label_: RF","_x_:  41.00<br />_yhat_: 0.2440366<br />_label_: RF","_x_:  44.00<br />_yhat_: 0.2418582<br />_label_: RF","_x_:  46.00<br />_yhat_: 0.3120129<br />_label_: RF","_x_:  48.00<br />_yhat_: 0.4866721<br />_label_: RF","_x_:  51.00<br />_yhat_: 0.5111411<br />_label_: RF","_x_:  52.00<br />_yhat_: 0.4969509<br />_label_: RF","_x_:  53.00<br />_yhat_: 0.4874661<br />_label_: RF","_x_:  55.00<br />_yhat_: 0.5009085<br />_label_: RF","_x_:  56.00<br />_yhat_: 0.5054556<br />_label_: RF","_x_:  57.00<br />_yhat_: 0.5112650<br />_label_: RF","_x_:  58.00<br />_yhat_: 0.5411438<br />_label_: RF","_x_:  59.23<br />_yhat_: 0.5462698<br />_label_: RF","_x_:  60.00<br />_yhat_: 0.5466083<br />_label_: RF","_x_:  61.00<br />_yhat_: 0.5474713<br />_label_: RF","_x_:  62.00<br />_yhat_: 0.5452711<br />_label_: RF","_x_:  63.00<br />_yhat_: 0.5417884<br />_label_: RF","_x_:  64.00<br />_yhat_: 0.5397756<br />_label_: RF","_x_:  65.00<br />_yhat_: 0.5530533<br />_label_: RF","_x_:  66.00<br />_yhat_: 0.5815341<br />_label_: RF","_x_:  67.00<br />_yhat_: 0.5981879<br />_label_: RF","_x_:  68.00<br />_yhat_: 0.5875037<br />_label_: RF","_x_:  69.00<br />_yhat_: 0.6070161<br />_label_: RF","_x_:  70.00<br />_yhat_: 0.6058049<br />_label_: RF","_x_:  71.00<br />_yhat_: 0.5973869<br />_label_: RF","_x_:  72.00<br />_yhat_: 0.5892894<br />_label_: RF","_x_:  73.00<br />_yhat_: 0.5992077<br />_label_: RF","_x_:  74.00<br />_yhat_: 0.6522884<br />_label_: RF","_x_:  75.00<br />_yhat_: 0.6778616<br />_label_: RF","_x_:  76.00<br />_yhat_: 0.6789878<br />_label_: RF","_x_:  77.00<br />_yhat_: 0.7127351<br />_label_: RF","_x_:  78.00<br />_yhat_: 0.7193671<br />_label_: RF","_x_:  79.00<br />_yhat_: 0.7308989<br />_label_: RF","_x_:  80.00<br />_yhat_: 0.7180351<br />_label_: RF","_x_:  81.00<br />_yhat_: 0.7203260<br />_label_: RF","_x_:  82.00<br />_yhat_: 0.7269316<br />_label_: RF","_x_:  83.00<br />_yhat_: 0.7937097<br />_label_: RF","_x_:  84.00<br />_yhat_: 0.8187571<br />_label_: RF","_x_:  85.00<br />_yhat_: 0.8246409<br />_label_: RF","_x_:  86.00<br />_yhat_: 0.8530283<br />_label_: RF","_x_:  87.00<br />_yhat_: 0.8581257<br />_label_: RF","_x_:  88.00<br />_yhat_: 0.8598262<br />_label_: RF","_x_:  89.00<br />_yhat_: 0.8616557<br />_label_: RF","_x_:  90.00<br />_yhat_: 0.8565234<br />_label_: RF","_x_:  91.29<br />_yhat_: 0.8502032<br />_label_: RF","_x_:  94.00<br />_yhat_: 0.8510635<br />_label_: RF"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"RF","legendgroup":"RF","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.599973411754912,0.609415554778555,0.617264672688423,0.646714016428017,0.653876474636475,0.645556873432124,0.652845295787546,0.645337224553225,0.630752982933733,0.630702133366633,0.623255477022977,0.620083026445777,0.609599673243423,0.612912430902431,0.611328816461317,0.612287270895771,0.612856115440116,0.609408433066933,0.611314707819958,0.612222665417915,0.61625526989677,0.60979634043734,0.616608893217893,0.603337900710401,0.605844371656122,0.605844371656122,0.601480613969364,0.599508438034188,0.601859589188589],"text":["_x_:  90.00<br />_yhat_: 0.5999734<br />_label_: RF","_x_: 104.13<br />_yhat_: 0.6094156<br />_label_: RF","_x_: 110.00<br />_yhat_: 0.6172647<br />_label_: RF","_x_: 115.84<br />_yhat_: 0.6467140<br />_label_: RF","_x_: 120.00<br />_yhat_: 0.6538765<br />_label_: RF","_x_: 126.10<br />_yhat_: 0.6455569<br />_label_: RF","_x_: 130.00<br />_yhat_: 0.6528453<br />_label_: RF","_x_: 135.00<br />_yhat_: 0.6453372<br />_label_: RF","_x_: 140.00<br />_yhat_: 0.6307530<br />_label_: RF","_x_: 142.01<br />_yhat_: 0.6307021<br />_label_: RF","_x_: 145.00<br />_yhat_: 0.6232555<br />_label_: RF","_x_: 146.00<br />_yhat_: 0.6200830<br />_label_: RF","_x_: 150.00<br />_yhat_: 0.6095997<br />_label_: RF","_x_: 154.32<br />_yhat_: 0.6129124<br />_label_: RF","_x_: 155.74<br />_yhat_: 0.6113288<br />_label_: RF","_x_: 160.00<br />_yhat_: 0.6122873<br />_label_: RF","_x_: 165.00<br />_yhat_: 0.6128561<br />_label_: RF","_x_: 170.00<br />_yhat_: 0.6094084<br />_label_: RF","_x_: 172.12<br />_yhat_: 0.6113147<br />_label_: RF","_x_: 175.00<br />_yhat_: 0.6122227<br />_label_: RF","_x_: 180.00<br />_yhat_: 0.6162553<br />_label_: RF","_x_: 185.00<br />_yhat_: 0.6097963<br />_label_: RF","_x_: 190.00<br />_yhat_: 0.6166089<br />_label_: RF","_x_: 200.00<br />_yhat_: 0.6033379<br />_label_: RF","_x_: 209.74<br />_yhat_: 0.6058444<br />_label_: RF","_x_: 210.00<br />_yhat_: 0.6058444<br />_label_: RF","_x_: 220.00<br />_yhat_: 0.6014806<br />_label_: RF","_x_: 232.32<br />_yhat_: 0.5995084<br />_label_: RF","_x_: 270.00<br />_yhat_: 0.6018596<br />_label_: RF"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(240,90,113,0.8)","dash":"solid"},"hoveron":"points","name":"RF","legendgroup":"RF","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"x":[22,41,44,46,48,51,52,53,55,56,57,58,59.23,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91.29,94],"y":[0.461347094476223,0.461347094476223,0.461347094476223,0.461347094476223,0.461347094476223,0.466659221202135,0.466659221202135,0.468397112116218,0.491507466137409,0.495477797165513,0.495477797165513,0.542145502194762,0.541508695036173,0.540291048586369,0.541750371679664,0.5435782122612,0.545994399115443,0.54840241022408,0.562914499640465,0.588479363247752,0.600645197294652,0.60119181741029,0.612026188001037,0.613847382701933,0.618019330538809,0.617369991280138,0.631696478761733,0.667218560054898,0.688181133493781,0.699614627584815,0.715560865998268,0.724256526827812,0.727808169461787,0.726493650823832,0.725375243574381,0.739615168329328,0.768370204623789,0.800066973678768,0.805993288252503,0.814128621015698,0.814128621015698,0.814128621015698,0.814128621015698,0.814128621015698,0.814128621015698,0.814128621015698],"text":["_x_:  22.00<br />_yhat_: 0.4613471<br />_label_: XGB","_x_:  41.00<br />_yhat_: 0.4613471<br />_label_: XGB","_x_:  44.00<br />_yhat_: 0.4613471<br />_label_: XGB","_x_:  46.00<br />_yhat_: 0.4613471<br />_label_: XGB","_x_:  48.00<br />_yhat_: 0.4613471<br />_label_: XGB","_x_:  51.00<br />_yhat_: 0.4666592<br />_label_: XGB","_x_:  52.00<br />_yhat_: 0.4666592<br />_label_: XGB","_x_:  53.00<br />_yhat_: 0.4683971<br />_label_: XGB","_x_:  55.00<br />_yhat_: 0.4915075<br />_label_: XGB","_x_:  56.00<br />_yhat_: 0.4954778<br />_label_: XGB","_x_:  57.00<br />_yhat_: 0.4954778<br />_label_: XGB","_x_:  58.00<br />_yhat_: 0.5421455<br />_label_: XGB","_x_:  59.23<br />_yhat_: 0.5415087<br />_label_: XGB","_x_:  60.00<br />_yhat_: 0.5402910<br />_label_: XGB","_x_:  61.00<br />_yhat_: 0.5417504<br />_label_: XGB","_x_:  62.00<br />_yhat_: 0.5435782<br />_label_: XGB","_x_:  63.00<br />_yhat_: 0.5459944<br />_label_: XGB","_x_:  64.00<br />_yhat_: 0.5484024<br />_label_: XGB","_x_:  65.00<br />_yhat_: 0.5629145<br />_label_: XGB","_x_:  66.00<br />_yhat_: 0.5884794<br />_label_: XGB","_x_:  67.00<br />_yhat_: 0.6006452<br />_label_: XGB","_x_:  68.00<br />_yhat_: 0.6011918<br />_label_: XGB","_x_:  69.00<br />_yhat_: 0.6120262<br />_label_: XGB","_x_:  70.00<br />_yhat_: 0.6138474<br />_label_: XGB","_x_:  71.00<br />_yhat_: 0.6180193<br />_label_: XGB","_x_:  72.00<br />_yhat_: 0.6173700<br />_label_: XGB","_x_:  73.00<br />_yhat_: 0.6316965<br />_label_: XGB","_x_:  74.00<br />_yhat_: 0.6672186<br />_label_: XGB","_x_:  75.00<br />_yhat_: 0.6881811<br />_label_: XGB","_x_:  76.00<br />_yhat_: 0.6996146<br />_label_: XGB","_x_:  77.00<br />_yhat_: 0.7155609<br />_label_: XGB","_x_:  78.00<br />_yhat_: 0.7242565<br />_label_: XGB","_x_:  79.00<br />_yhat_: 0.7278082<br />_label_: XGB","_x_:  80.00<br />_yhat_: 0.7264937<br />_label_: XGB","_x_:  81.00<br />_yhat_: 0.7253752<br />_label_: XGB","_x_:  82.00<br />_yhat_: 0.7396152<br />_label_: XGB","_x_:  83.00<br />_yhat_: 0.7683702<br />_label_: XGB","_x_:  84.00<br />_yhat_: 0.8000670<br />_label_: XGB","_x_:  85.00<br />_yhat_: 0.8059933<br />_label_: XGB","_x_:  86.00<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  87.00<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  88.00<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  89.00<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  90.00<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  91.29<br />_yhat_: 0.8141286<br />_label_: XGB","_x_:  94.00<br />_yhat_: 0.8141286<br />_label_: XGB"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGB","legendgroup":"XGB","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[90,104.13,110,115.84,120,126.1,130,135,140,142.01,145,146,150,154.32,155.74,160,165,170,172.12,175,180,185,190,200,209.74,210,220,232.32,270],"y":[0.685240335687995,0.685240335687995,0.685240335687995,0.685240335687995,0.685240335687995,0.679247506242245,0.676742485277355,0.667469298876822,0.644873972646892,0.644997724760324,0.634901554919779,0.634831947926432,0.620530319530517,0.624636356309056,0.624228907041252,0.621746834330261,0.633635113369673,0.626043665874749,0.629510270450264,0.625631254743785,0.631677439939231,0.631280417665839,0.639380291458219,0.626010033898056,0.641536278557032,0.641536278557032,0.641536278557032,0.641536278557032,0.641536278557032],"text":["_x_:  90.00<br />_yhat_: 0.6852403<br />_label_: XGB","_x_: 104.13<br />_yhat_: 0.6852403<br />_label_: XGB","_x_: 110.00<br />_yhat_: 0.6852403<br />_label_: XGB","_x_: 115.84<br />_yhat_: 0.6852403<br />_label_: XGB","_x_: 120.00<br />_yhat_: 0.6852403<br />_label_: XGB","_x_: 126.10<br />_yhat_: 0.6792475<br />_label_: XGB","_x_: 130.00<br />_yhat_: 0.6767425<br />_label_: XGB","_x_: 135.00<br />_yhat_: 0.6674693<br />_label_: XGB","_x_: 140.00<br />_yhat_: 0.6448740<br />_label_: XGB","_x_: 142.01<br />_yhat_: 0.6449977<br />_label_: XGB","_x_: 145.00<br />_yhat_: 0.6349016<br />_label_: XGB","_x_: 146.00<br />_yhat_: 0.6348319<br />_label_: XGB","_x_: 150.00<br />_yhat_: 0.6205303<br />_label_: XGB","_x_: 154.32<br />_yhat_: 0.6246364<br />_label_: XGB","_x_: 155.74<br />_yhat_: 0.6242289<br />_label_: XGB","_x_: 160.00<br />_yhat_: 0.6217468<br />_label_: XGB","_x_: 165.00<br />_yhat_: 0.6336351<br />_label_: XGB","_x_: 170.00<br />_yhat_: 0.6260437<br />_label_: XGB","_x_: 172.12<br />_yhat_: 0.6295103<br />_label_: XGB","_x_: 175.00<br />_yhat_: 0.6256313<br />_label_: XGB","_x_: 180.00<br />_yhat_: 0.6316774<br />_label_: XGB","_x_: 185.00<br />_yhat_: 0.6312804<br />_label_: XGB","_x_: 190.00<br />_yhat_: 0.6393803<br />_label_: XGB","_x_: 200.00<br />_yhat_: 0.6260100<br />_label_: XGB","_x_: 209.74<br />_yhat_: 0.6415363<br />_label_: XGB","_x_: 210.00<br />_yhat_: 0.6415363<br />_label_: XGB","_x_: 220.00<br />_yhat_: 0.6415363<br />_label_: XGB","_x_: 232.32<br />_yhat_: 0.6415363<br />_label_: XGB","_x_: 270.00<br />_yhat_: 0.6415363<br />_label_: XGB"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(139,220,190,0.8)","dash":"solid"},"hoveron":"points","name":"XGB","legendgroup":"XGB","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":27.8953922789539,"l":47.0236612702366},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.480915721887079],"automargin":true,"type":"linear","autorange":false,"range":[18.4,97.6],"tickmode":"array","ticktext":["20","40","60","80"],"tickvals":[20,40,60,80],"categoryorder":"array","categoryarray":["20","40","60","80"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.210868296626984,0.892645592567155],"tickmode":"array","ticktext":["0.4","0.6","0.8"],"tickvals":[0.4,0.6,0.8],"categoryorder":"array","categoryarray":["0.4","0.6","0.8"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"annotations":[{"text":"Average prediction","x":0,"y":0.5,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-90,"xanchor":"right","yanchor":"center","annotationType":"axis","xshift":-30.2864259028643},{"text":"AGE","x":0.24045786094354,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RSBP","x":0.75954213905646,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.480915721887079,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.480915721887079,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.519084278112921,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.519084278112921,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[81,279],"tickmode":"array","ticktext":["100","150","200","250"],"tickvals":[100,150,200,250],"categoryorder":"array","categoryarray":["100","150","200","250"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.519084278112921,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.527540320662236,0.692749860213031],"tickmode":"array","ticktext":["0.56","0.60","0.64","0.68"],"tickvals":[0.56,0.6,0.64,0.68],"categoryorder":"array","categoryarray":["0.56","0.60","0.64","0.68"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"title":{"text":"Model","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022}},"orientation":"h","xanchor":"center","x":0.5,"y":1},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"488c185c5525":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"488c185c5525","visdat":{"488c185c5525":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>export(pdp_age_rsbp2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;pdp-age-rsbp.rds&quot;))</code></pre>
</div>
</div>
<div id="local-interpretation" class="section level2">
<h2>Local interpretation</h2>
<p>Find oldest and youngest patients in the training data:</p>
<pre class="r"><code>train_oldest &lt;- ist_train %&gt;% slice_max(AGE, with_ties = FALSE)
train_youngest &lt;- ist_train %&gt;% slice_min(AGE, with_ties = FALSE)</code></pre>
<div id="random-forest-11" class="section level3">
<h3>Random forest</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_rf &lt;- predict_parts(
  explainer_rf, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_rf &lt;- predict_parts(
  explainer_rf, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
</div>
<div id="neural-network-11" class="section level3">
<h3>Neural network</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_nnet &lt;- predict_parts(
  explainer_nnet, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_nnet &lt;- predict_parts(
  explainer_nnet, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
</div>
<div id="xgboost-11" class="section level3">
<h3>XGBoost</h3>
<p>Compute SHAP attributions:</p>
<pre class="r"><code>local_old_xgb &lt;- predict_parts(
  explainer_xgb, train_oldest, type = &quot;shap&quot;, B = 20
)
local_young_xgb &lt;- predict_parts(
  explainer_xgb, train_youngest, type = &quot;shap&quot;, B = 20
)</code></pre>
<p>Create local profile for the oldest patient in the training data:</p>
<pre class="r"><code>local_profile_old &lt;- plot_local(
  local_old_rf, local_old_nnet, local_old_xgb
)
local_profile_old</code></pre>
<p><img src="figure/modeling.Rmd/local-profile-old-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>local_profile_old2 &lt;- ggplotly(local_profile_old)
local_profile_old2</code></pre>
<div id="htmlwidget-97430cc282ecedb9dc8b" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-97430cc282ecedb9dc8b">{"x":{"data":[{"orientation":"v","width":[0.00297958667441758,0.00704286252692288,0.0164998997879164,0.000448140498792021,0.00308948324109067,0.00359593558324438,0.00271709002967183,0.00502451567268609],"base":[5.55,11.55,13.55,18.55,10.55,15.55,4.55,6.55],"x":[-0.00148979333720879,-0.00352143126346144,-0.00824994989395818,-0.000224070249396011,-0.00154474162054533,-0.00179796779162219,-0.00135854501483592,-0.00251225783634304],"y":[0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.9],"text":["mean_val: -2.979587e-03<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -7.042863e-03<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val: -1.649990e-02<br />variable: RDEF4 = C<br />mean_val > 0: FALSE","mean_val: -4.481405e-04<br />variable: RDEF6 = C<br />mean_val > 0: FALSE","mean_val: -3.089483e-03<br />variable: RDELAY = 8<br />mean_val > 0: FALSE","mean_val: -3.595936e-03<br />variable: RSBP = 130<br />mean_val > 0: FALSE","mean_val: -2.717090e-03<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -5.024516e-03<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.000202437249541837,0.00440910112381141,0.00792711805201601,0.000820927557217649,0.00107794518861846],"base":[5.55,11.55,12.55,4.55,6.55],"x":[-0.000101218624770918,-0.0022045505619057,-0.003963559026008,-0.000410463778608824,-0.000538972594309231],"y":[0.9,0.899999999999999,0.899999999999999,0.9,0.9],"text":["mean_val: -2.024372e-04<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -4.409101e-03<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val: -7.927118e-03<br />variable: RDEF7 = C<br />mean_val > 0: FALSE","mean_val: -8.209276e-04<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -1.077945e-03<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.000320003831449561,0.00338104561757996,0.0190806853209905,0,0.00535650099933136,0.00326017364761153],"base":[1.55,5.55,11.55,0.55,4.55,6.55],"x":[-0.000160001915724781,-0.00169052280878998,-0.00954034266049523,0,-0.00267825049966568,-0.00163008682380577],"y":[0.9,0.9,0.899999999999999,0.9,0.9,0.9],"text":["mean_val: -3.200038e-04<br />variable: RASP3 = N<br />mean_val > 0: FALSE","mean_val: -3.381046e-03<br />variable: RATRIAL = N<br />mean_val > 0: FALSE","mean_val: -1.908069e-02<br />variable: RCT = Y<br />mean_val > 0: FALSE","mean_val:  0.000000e+00<br />variable: RHEP24 = N<br />mean_val > 0: FALSE","mean_val: -5.356501e-03<br />variable: RVISINF = N<br />mean_val > 0: FALSE","mean_val: -3.260174e-03<br />variable: STYPE = PACS<br />mean_val > 0: FALSE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(67,120,191,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.04156306464251,0.00235725475332264,0.0520060896003357,0.0068020314517728,0.0019765915959536,0.00931038697983395,0.0366465672721946,0.0183327075937724,0.00129426660391434,2.97871505694713e-05,3.58682780913611e-05,0.00566078815545712,0.0124823915093819],"base":[20.55,1.55,19.55,9.55,7.55,16.55,17.55,12.55,2.55,0.55,3.55,14.55,8.55],"x":[0.020781532321255,0.00117862737666132,0.0260030448001678,0.0034010157258864,0.000988295797976799,0.00465519348991698,0.0183232836360973,0.00916635379688618,0.00064713330195717,1.48935752847357e-05,1.79341390456805e-05,0.00283039407772856,0.00624119575469096],"y":[0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.9,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  4.156306e-02<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  2.357255e-03<br />variable: RASP3 = N<br />mean_val > 0:  TRUE","mean_val:  5.200609e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  6.802031e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  1.976592e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  9.310387e-03<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  3.664657e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  1.833271e-02<br />variable: RDEF7 = C<br />mean_val > 0:  TRUE","mean_val:  1.294267e-03<br />variable: RDEF8 = C<br />mean_val > 0:  TRUE","mean_val:  2.978715e-05<br />variable: RHEP24 = N<br />mean_val > 0:  TRUE","mean_val:  3.586828e-05<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  5.660788e-03<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  1.248239e-02<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.178008684562219,0.000117550342737122,0.0172809597761729,0.00799964273174184,0.00557834044286212,0.0205945167086922,0.000815330935666214,0.0230729866984733,0.0535783356400038,0.00108938345131953,0.0177964190368062,0.00101789098383397,0.0146279424782377,0.00148736979715295,0.0123736859884528,0.0065441723094083],"base":[20.55,1.55,19.55,9.55,7.55,16.55,13.55,17.55,18.55,2.55,10.55,0.55,15.55,3.55,14.55,8.55],"x":[0.0890043422811093,5.87751713685608e-05,0.00864047988808644,0.00399982136587092,0.00278917022143106,0.0102972583543461,0.000407665467833107,0.0115364933492366,0.0267891678200019,0.000544691725659765,0.00889820951840311,0.000508945491916984,0.00731397123911883,0.000743684898576477,0.00618684299422638,0.00327208615470415],"y":[0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  1.780087e-01<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  1.175503e-04<br />variable: RASP3 = N<br />mean_val > 0:  TRUE","mean_val:  1.728096e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  7.999643e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  5.578340e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  2.059452e-02<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  8.153309e-04<br />variable: RDEF4 = C<br />mean_val > 0:  TRUE","mean_val:  2.307299e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  5.357834e-02<br />variable: RDEF6 = C<br />mean_val > 0:  TRUE","mean_val:  1.089383e-03<br />variable: RDEF8 = C<br />mean_val > 0:  TRUE","mean_val:  1.779642e-02<br />variable: RDELAY = 8<br />mean_val > 0:  TRUE","mean_val:  1.017891e-03<br />variable: RHEP24 = N<br />mean_val > 0:  TRUE","mean_val:  1.462794e-02<br />variable: RSBP = 130<br />mean_val > 0:  TRUE","mean_val:  1.487370e-03<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  1.237369e-02<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  6.544172e-03<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x2","yaxis":"y2","hoverinfo":"text","frame":null},{"orientation":"v","width":[0.110866660868536,0.052170956016005,0.00557757463331985,0.00374669490243598,0.0205809922051907,0.00928227732887318,0.0321900260173471,0.0379965176606624,0.00682221672833021,0.0197290717618358,0.00685026965500467,0.0221639696470972,0.004207090929771,0.0167994512930314,0.0049220751317655],"base":[20.55,19.55,9.55,7.55,16.55,13.55,17.55,18.55,12.55,2.55,10.55,15.55,3.55,14.55,8.55],"x":[0.0554333304342679,0.0260854780080025,0.00278878731665992,0.00187334745121799,0.0102904961025953,0.00464113866443659,0.0160950130086736,0.0189982588303312,0.00341110836416511,0.0098645358809179,0.00342513482750233,0.0110819848235486,0.0021035454648855,0.00839972564651571,0.00246103756588275],"y":[0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.899999999999999,0.9,0.899999999999999,0.899999999999999],"text":["mean_val:  1.108667e-01<br />variable: AGE = 94<br />mean_val > 0:  TRUE","mean_val:  5.217096e-02<br />variable: RCONSC = D<br />mean_val > 0:  TRUE","mean_val:  5.577575e-03<br />variable: RDEF1 = Y<br />mean_val > 0:  TRUE","mean_val:  3.746695e-03<br />variable: RDEF2 = Y<br />mean_val > 0:  TRUE","mean_val:  2.058099e-02<br />variable: RDEF3 = Y<br />mean_val > 0:  TRUE","mean_val:  9.282277e-03<br />variable: RDEF4 = C<br />mean_val > 0:  TRUE","mean_val:  3.219003e-02<br />variable: RDEF5 = C<br />mean_val > 0:  TRUE","mean_val:  3.799652e-02<br />variable: RDEF6 = C<br />mean_val > 0:  TRUE","mean_val:  6.822217e-03<br />variable: RDEF7 = C<br />mean_val > 0:  TRUE","mean_val:  1.972907e-02<br />variable: RDEF8 = C<br />mean_val > 0:  TRUE","mean_val:  6.850270e-03<br />variable: RDELAY = 8<br />mean_val > 0:  TRUE","mean_val:  2.216397e-02<br />variable: RSBP = 130<br />mean_val > 0:  TRUE","mean_val:  4.207091e-03<br />variable: RSLEEP = N<br />mean_val > 0:  TRUE","mean_val:  1.679945e-02<br />variable: SEX = F<br />mean_val > 0:  TRUE","mean_val:  4.922075e-03<br />variable: treatment = yes_asp_low_hep<br />mean_val > 0:  TRUE"],"type":"bar","textposition":"none","marker":{"autocolorscale":false,"color":"rgba(139,220,190,0.5)","line":{"width":1.88976377952756,"color":"transparent"}},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x3","yaxis":"y3","hoverinfo":"text","frame":null},{"x":[-0.0050225491071495,-0.00297958667441758,-0.000139787032243932,-0.00668991103886907,-0.00441413804235824,-0.00312845396345707,-0.00800749714764137,-0.00460593479993898,0,0,-0.00304235141363007,0,-0.00340311083746803,-0.00466353370035588,0,-0.00369414499594756,-0.00361833361703412,-0.00334914915377849,-0.00581230723831438,-5.31400164982543e-07,0,-0.0266654912216885,-0.00704286252692288,0,-0.0134242911363414,0.00441869607784129,0,-0.00966162100257928,-0.0105871933629159,0.00245323870355985,-0.0251054572392416,0.00132681239054511,-0.00110499464801606,-0.0127571169180074,-0.00953108507737588,-0.0030628349720635,9.7693263455767e-05,-0.00662855751610802,0,0.00360484581133691,-0.0247884657156001,-0.00944142797525893,0,0,-0.0230520714273913,-0.0270767815485062,-0.0258667586626999,-0.000189883241709099,-0.0263794064620385,-0.0164998997879164,-0.00833055880985656,0,0,-0.02773530047937,-0.00530039918142344,-0.0276161553896093,-0.0272359539779782,-0.0180478963489747,-0.0260949652894366,-0.016059287819553,-0.0171811299915922,-0.028107694631557,-0.0257237524966313,0.00945084594533219,-0.00745290538839982,0.00217012663430594,0.000817991224969061,-0.00266045888897015,0.0190472261465519,-0.000594519813765459,-4.0513089438754e-08,0.0143456897910461,0.00397147009277621,-0.018777994533609,-0.00609770687170996,0,-6.79078671073086e-09,2.28028354797294e-05,0,-0.0113895685712654,0.00759168515154951,-0.0121565177043716,-0.000448140498792021,-0.00725092872188349,-0.00221343897341464,-0.00794433668339001,-0.00445739046729476,-0.00133755509598665,-0.00496672770884155,2.02761660794692e-08,-6.11404714203623e-05,-0.00297443512365414,0,-0.0012383865443808,-0.00505945379046446,-7.78535048799878e-05,-0.00399357431439973,-0.00308948324109067,-0.00310805987903207,-0.00469643756011318,-0.00481836753014897,-0.00561311951995169,-0.00430004493998637,-0.00187788425437252,-0.00305147873624756,1.0368949450168e-06,-0.00524651824542577,-0.00649100222620091,-0.00384188568615829,-0.00540092021681871,0,-0.00521081019540004,-0.0019516491996463,-0.00621701445233491,-0.00430449483479722,0,-0.00740478000319778,-0.00359593558324438,-0.00609192943915904,-0.00521438953831521,-0.00349417424145915,0,0,0,-0.00586315557801131,-0.00518702470290799,0.00298574655640971,0.000503573337362395,0,-0.00438507653285791,-0.00810133189189854,-0.000298124205026284,-0.000135462979885426,-0.00343274972506935,0.00143897417377881,-0.00882125525153443,-0.00335269719114839,-0.0056135393433675,-0.00314206445257714,0,-0.00512920777485382,0.00228493509729788,-0.00493120956527648,-0.00961880558934824,-0.00459350525544189,-0.00271709002967183,0,-0.0114947052739499,-0.00826596461604445,-0.00876077696862176,-0.00354283064715577,-0.0110191504467186,-0.0122290428875942,0,-0.00643687966988438,-0.000739366039874789,-0.00923031563077459,-0.00595602300535414,-0.0062876246603194,0.00061985302076728,-0.0071913029504429,-0.00502451567268609,-0.00839628177001694,-0.00847628145626811,0.000815097642210549,0.00610128190632042,0,0],"y":[6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x","yaxis":"y","frame":null},{"x":[-0.00116930050634501,6.55976676389169e-06,0.000418401547027547,0.000554254679965394,-0.00123750671906653,0.000149571073969845,-0.000222821194031164,6.55976676389169e-06,0.000568593345834589,-0.00117910779291974,-5.22632574746495e-05,-1.43343051506317e-05,-0.00124157378902279,-0.000202437249541837,0.000477002326309983,6.55976676389169e-06,-0.000262770473776319,0.000299611746368278,6.55976676389169e-06,6.55976676389169e-06,-0.00116930050634501,-0.0138691673507089,-0.0230920391319079,0.00197897720800422,-5.64266960768611e-05,0.000359703828727076,2.64681463660876e-05,0.00033687056586118,0.000207314502795541,-0.0166010645088633,-0.00767987148096483,-0.00403141815262809,0.000602910213369334,0.000207314502795541,0.000180810394658781,-0.00440910112381141,-0.00761013468431471,0.000632036816439085,-0.00180628785289871,-0.000469332487645135,-0.0179865776776673,0.000487891368430748,-0.00362149094022279,-0.00532036424864413,-0.00408883756347311,0.000753319469646074,-0.00402568206615217,-0.00164271657642656,-0.00672906026189557,-0.0202941850484306,-0.0158839814845828,-0.0190716406386777,-0.000911081872452146,-0.00800571826537566,-0.00143287172011664,-0.0012567338840298,-0.0194566623306237,-0.00792711805201601,-0.00143287172011664,-0.00143287172011664,-0.0218651981542105,-0.0180131695503234,-0.00481054246409562,-0.00328479913348712,-0.000820927557217649,0.000168476915051174,-0.000307580174927158,-0.00629024774828346,-0.00415253815264749,0.00212311060335846,0.00425462208871463,-0.00327619992373995,0.0030020492849393,0.0023210960747222,-0.000307580174927158,-0.00247838683627688,-0.00608213400828195,-0.0067713243591524,-0.000307580174927158,0.00121690440269162,0.000689586937600795,0.00198653166561324,3.48583389400137e-05,0.00104258323066631,0.00320841550537254,-0.00283905153196329,-0.00246778497862676,-0.000716507769441432,0.00100549943860795,-0.0063042835505116,0.00415716225384599,-1.90167562434951e-05,-0.000327087669780735,0.000329746261998443,-0.00107794518861846,0.000777899827335005,0.00188974337737091,0.00290647726301874,-0.00320413413724274,-0.00442732164579829,-0.000772685346318691,-0.00408384639938941,-0.00571994313792779,-0.00377491348140035,-0.00117727129527423],"y":[6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x2","yaxis":"y2","frame":null},{"x":[-0.00125722780839999,0.000326667149325832,0.000260672301227727,-0.000274543583925313,-0.000494196548047943,-0.00163472176776558,0.000175711561711145,-0.000320003831449561,-0.000925298750335424,0.000272109192244852,-0.00018552862346688,-0.00142873680007261,6.11761593024562e-05,0.000416646019145595,0.000272381390952647,-0.000231781344502413,0.000478053320220995,-0.00124851783802704,-0.00069714658662845,-0.00034741383268555,6.16197607347102e-05,-0.00429147068796676,-0.00394050919100553,-0.00424366030413059,-0.00183831627206443,-0.00199725203156342,-0.000892157332412324,-0.000836549858961755,-0.00408078758887753,-0.00457316495508031,-0.00338104561757996,-0.000836549858961755,-0.00528444485934365,-0.00461610611025842,-0.00160981670874583,-0.0014242720912393,-0.00275841930408693,-0.005216586388615,-0.00517422886451291,-0.00437542866459306,-0.00516247830378114,-0.00446871297539864,-0.031474533422956,-0.0060223085132397,-0.0307923444660798,-0.00518893965984268,-0.0280754691011573,-0.027279742868514,-0.0280844662440316,-0.0157393211249056,-0.0133472862599129,-0.00295784479446992,-0.0191205114536205,-0.0165110497515507,-0.029731807871871,-0.0190806853209905,-0.0250115496467571,-0.0211466339154782,-0.0249187564131134,-0.00885052565870803,-0.0262498354740202,-0.00430763603266848,-0.0168031437469119,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0.00290945511034335,-0.0105493291411495,-0.00169277032049853,-0.00889120136493537,-0.00297812603511804,-0.0049414539155781,-0.00535650099933136,-0.00911995491729745,-0.0105493291411495,-0.00169277032049853,-0.00886045406510072,-0.00501891498728158,-0.00173091556898619,-0.00902672830572682,-0.00762465913065924,-0.00170935276195239,-0.00169277032049853,-0.00223602591158478,-0.00473075018755809,-0.00211771578139708,-0.00905734269931346,-0.00150024661327286,-0.00500271564794819,-0.00565355321332683,-0.00282072789733556,-0.00135328800420198,-0.00270510458254392,-0.00326017364761153,-0.00374638150940287,-0.000592019326805637,-0.00338223658545544,-0.00600381736689781,-0.00475674865322062,-0.00553085626328342,-0.00150024661327286,-0.00124256300628611,-0.00769683952462308,-0.00197820425435424,-0.00122394314600538,-0.00384010264375745,-0.00232764157404142,-0.00234623652619492],"y":[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7],"hoverinfo":"y","type":"box","fillcolor":"rgba(67,120,191,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"FALSE","legendgroup":"FALSE","showlegend":false,"xaxis":"x3","yaxis":"y3","frame":null},{"x":[0.04156306464251,0.0534055553085793,0.0891016455337094,0.0163029634863917,0.0439955899757326,0.0152601473408466,0.0692371707236816,0.0123913593261419,0.0142713760504426,0.0676565468577883,0.0457318509572762,0.0110878728083212,0.0667259677133545,0.0341085548238178,0.0861182802874785,0.0132282874611516,0.0811584238628058,0.0420161266497248,0.0110878728083212,0.0253701715269522,0.0330055293476825,0.00235725475332264,0.00244693286018527,0.00370925432534308,0.00430618197840127,0.00064794581277261,0.00120326555243699,0.000186138034390271,0.00281174160229036,0.00411773441752761,0,0.0048525478095941,0,0.00344244797811954,0.00454115396789356,0.00069777190489595,0.00220019616303024,0.00187340322817775,0.000875925939758049,0.00100914798644625,0.00396170470023327,0.00426160080495652,0.0677318300122618,0.000190155188737107,0.0845148424646808,0.0675662963038255,0.0714787847473306,0.0693150040657631,0.0693150040657631,0.0413771616332849,0,0.0763712768542655,0.0905193706261986,0.0700940998060415,0.0640048143108823,0.0520060896003357,0,0,0.035341524738789,0.0193644437453027,0.0456885141034963,0.0908765692069935,0.0763721001330973,0.00118758470308733,0.0156229280186791,1.01223444959331e-07,0.00429508003654633,0.0068020314517728,0.00982720807103832,-0.00121676260315917,0.009247171419967,0.00684539378100057,3.21259349678193e-07,0.0126440335046591,0.0106643422182997,0.0109042240249487,0.0147411542722581,0.0054406571122978,0.00837971605158405,0.00688030015261309,0.00100584134601156,0.00733217139193454,0.0122388417915454,3.21259349678193e-07,0,0.00225319895031006,0.00494287086586409,0.000529306629907356,0.00164042061305936,0.00294436000979315,0.000953822375106994,0.00214406357818586,0.00254738000090959,0.00301059048593455,0.00170745407015593,0.00202102604139065,0.00166121896165583,0.00192546711011476,0.0019765915959536,0.00150836475519789,0.00270592823228144,0.00242639810426903,0.00206700016319883,0.00254296097173656,0,0.0126275365081,0,0.015704938330243,0.0102454890301339,0.0227172148566949,0.00683774751103328,0.00199818167914934,0.0134983169051835,0.00931038697983395,0,0.012770691882519,0.0143456398269208,0.0171428258872235,0.000580772685452868,0.00408083020060346,0.00344020921702104,0.00686760929206842,0.015860714908117,0.0143456398269208,0.0105183184297623,0.00262506261953188,0.0806434962755352,6.81685430325984e-09,0.0491573085025254,0.00715271893935165,0.028038881882592,0.0366465672721946,0.0285040786560689,0.0383064816825449,0.0134134700137172,0.0494663203553196,0.0350113744609699,0.035168162672871,0.0545160385413441,0.0486236329917614,0.0567271757003751,0.037623268471173,0.0265195596440608,0.0340808143066055,0.0267777788485997,0.0358757874530897,0.0473249892285318,0.0234127873952156,0.0256960102785195,0.0184596896885815,0.0227201265056238,0.0203191511944102,0.0252482520616418,0.0178651701625375,0.00411215102055607,0.0253736888737057,0.0216174431981324,0.022059167621258,0.0129555611893954,0.0289570986442922,0.0022160575760195,0.0240833971587987,0.00492843438610635,0.000102201512172995,0.0131084668582664,0.0353681906469179,0.0183327075937724,0.0180511059032957,0.00297896971382339,0.00188447094356425,-0.00684616516018344,-0.0054960760038546,-0.00915576489600167,0,0,-0.00389469509581652,0.0117100958609396,-0.00160693718568383,0.0104824375272324,-0.00875169929904507,0.0129313513231517,0.00129426660391434,0.0103528343509244,0.0232499697497327,0.000239769906678733,-0.0266929443741762,0,0.014499714717001,0,-2.70708244749507e-05,9.18275455674689e-11,0.000257480445755465,3.57006500347756e-05,0.000129532642062391,-5.71822345718509e-05,0.000193144866053263,2.97871505694713e-05,0,6.09596497783693e-05,-2.61212615394468e-05,0.000193144866053263,0,-9.59927431327667e-05,-0.000128841200672913,0,0.000198148116905661,-3.0728038458383e-05,6.2651564779026e-05,-0.000169083579010021,0,0.00694653038593762,0.00391804187222722,0.00206817864209718,0.000970129968682176,0.00336957157154183,-0.00288832916874016,-0.00850103142128777,0,0,0.00354086557227873,-7.84096788175592e-05,-0.00444045380757541,-0.000209614221100551,0,0,0,0.00756347254698242,-0.0007028988640847,3.58682780913611e-05,0,-0.0108386878363138,0.00735234789356798,0.00675300720553385,0.00675300720553385,0.00610886696641622,0.00754673933272354,0.00194212150589623,0.00734861036120227,0.00675300720553385,0.00623922886986561,0,0.00566078815545712,0.0033623956586003,0,0.00611600898881604,0.0058313711453386,0.00654542854094298,0.00566738423570612,0.00913470615635592,0.00693845223541922,0,0.0128230796016898,0.0114278124241669,0.0075266711950952,0.0171217621311702,0.00306443888100472,0.0173838093279305,0.0103166423800788,-0.00054439708464793,0.0137000650547946,0.0173838093279305,0.00806164901503925,0.0127016651739488,0.0224029562126763,0.0128747748440382,0.00286042811316489,7.50108673619465e-07,0.0175859164620896,0.0179763865903544,0.0124823915093819,0.0186886531258891,0.0217302275763102,0.0173838093279305],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x","yaxis":"y","frame":null},{"x":[0.178008684562219,0.167034958042848,0.118791806486759,0.189448320338554,0.146215147836048,0.181277208048673,0.209095421291941,0.194182521179824,0.193051091079717,0.204765328690584,0.183481434764215,0.193770986862587,0.222131985141114,0.150084974773769,0.134946946667683,0.148745389881013,0.198332075108241,0.110258922776689,0.203988421760051,0.201152365562442,0.209418384951621,0.000405041724957922,0.000135568513119577,-0.0017217918581256,0.00115091196056938,0.00130597907720731,-0.00215561353531468,0.00011376832391774,0.00266128680195743,0.000135568513119466,-0.000203769889812189,0.000135568513119577,8.51749137645852e-05,0.000839722574963009,-0.00139902177713769,0.000770544336615719,0.000117550342737122,-0.000238379592953142,-0.000241228503436886,0.000539212795626742,-0.000103104550535305,0.000135568513119466,0.00429274264769874,0.0159530753462603,0.0643050251457321,0.00349038052973905,0.00429274264769874,0.0034873921915467,0.00765600366996133,0.00991097498023508,0.00406532544229321,0.00349038052973905,0.0635658852869677,0.0172809597761729,0.00218585758265044,0.000222754068089359,0.00583696674438283,0.0643050251457321,-0.00013486718780098,0.00139463598435896,0.00394997866564906,0.0757584717942408,0.00759044430828304,0.00691590288558219,0.00871486528130117,0.00535721673046741,0.00670743065041524,0.00899746715869165,0.00553811612949728,0.0105009160947571,0.00928830946952308,0.0062622965550807,0.00742334142614764,0.0196619667767444,0.00544198655652739,0.0089266374619873,0.00911114711940142,0.00473004214970318,0.00799964273174184,0.00795457164312852,0.0049726542691193,0.00676209046460508,0.00761569385829586,0.00911020195386081,0.00535921199386946,0.0102362424666361,0.00516129608972171,0.00479966365024675,0.00534938732105272,0.00634719751822521,0.00519150995789108,0.00454542013703829,0.00557834044286212,0.00313069596017856,0.00290692252758573,0.00305495550974777,0.0111566198500237,0.00278087411252492,0.00763014748452062,0.00565499090519139,0.00737827313195383,0.0059751538791627,0.00661749035302239,0.00547287307970612,0.00281788292894336,0.00615192298792888,0.00631658372401822,0.0287793442567312,0.00631658372401811,0.0396707613612497,0.0344791317991208,0.0359392983211314,0.00631658372401811,0.00631658372401822,0.0358692376217885,0.0215732330149605,0.0244875591912946,0.0205945167086922,0.0249135722614767,0.0161716917153141,0.0356851144320532,0.0492508709969168,0.00589317216432739,0.00630820179981995,0.0148363715811237,0.00661451577253336,0.000253523942044365,0.000561652378234023,0.000449686952584183,0.00151892763253914,0.000815330935666214,0.00122606763984323,-1.91324285530037e-05,0.000667060520868845,0.000700225792590992,0.000227359887035483,-1.51620852422152e-05,-0.000232362414067988,0.000240112863327147,0.00048952876164976,0.002600795590464,0.00176545435249875,0.000253523942044365,0.00014373651534727,0.00424349337089858,0.000584029622386018,0.000648095876831345,0.0304464504458127,0.0248739129007534,0.0232408746400182,0.0075671855840953,0.0230729866984733,0.0191472363217444,0.00206994587450127,0.0103970045766513,0.0173616372815718,0.0150877894295534,0.00973826843710224,0.0382554805374412,0.0538958782531852,0.0162094367306649,0.0161939295540061,0.0340295766490556,0.0376599520741648,0.0213505840329091,0.0322530542950732,0.0186291974465443,0.0330523389046167,0.0627436141644231,0.0292730161905635,0.0190081100629206,0.041652136610555,0.0899719495397703,0.040861538975278,0.0535783356400038,0.0268360926407574,0.041785824715453,0.0643277667303541,0.0658818487028034,0.067745582205695,0.0398820895394693,0.0643277667303541,0.0532093665768957,0.0667341590180147,0.0415150218889468,0.0557645310957264,0.088067008408663,0.0430989409784417,0.0688803480249909,0.00282517053322451,0.00333084726457533,0.00334085348567859,1.65694849368903e-05,-0.000990499379548204,0.00347875605322767,-0.00316708124641796,-0.00401272608182224,0.00332881123775808,-0.00244151233444234,-0.00125736783462738,-0.00221889730976821,-0.00215531119350354,0.00273131710369323,0.00341937554873062,0.00108938345131953,0,0.00375442547612748,0.00366822490353835,0.00402337199769787,0.00411334131733188,0.0280613417235501,0.0248675910237316,0.00159719164055905,0.018616445602907,0.0162718474006557,0.0116960656872281,0.0319791281483337,0.0219183343078205,0.0211616021733368,0.0146172895314113,0.0219982667053549,0.0238582026290846,0.0111124578288572,0.0239904753106466,0.0192564267304609,0.0036885710216249,0.00828307087308544,0.0189782960641561,0.0177964190368062,0.0249164644636217,0.00905931186969822,0.000826764268692104,0.00193878188745167,0.000918071441030621,0.000659855108852914,0.000728117545719553,0.000787643545715699,0.000918071441030621,0.00213099666368621,0.00163796722390019,0.000671684488575908,0.00253241088559975,0.0014381124342131,0.000317214470822336,0.000913336643110774,0.000329446064139982,0.000822435632475749,0.000859792899843947,0.00101789098383397,0.000728117545719553,0.000704412735790361,0.000494586750308335,0.0136611627641875,0.00666148650304987,0.00308161685658037,0.0236553207340926,0.0118244239381448,0.0196167519130529,0.014836628918134,0.0322469711633524,0.00212219322627483,0.0125930559985042,0.0315442188965878,0.0295360388801351,0.00874289076852852,0.002939731779801,0.0264545306693631,0.026888837990241,-0.00360142800186536,0.0269463581506767,0.0146279424782377,-0.00319223307466743,0.00600029149057935,0.00259089257033862,0.00248445320876078,0.00247853029502076,0.00259008933445892,-0.0001267139242358,3.91642371234679e-05,0,0.00418543682588868,0.00116035629215294,0.00154127707812113,0,0.000711551454700143,0.000598073824458645,0.000811391194244671,0,0.00148736979715295,0.0040787474106716,0.00029509463649402,0.00236553243282478,0.00214300307119175,0.00180051600084397,0.0105287583913495,0.0114408133027485,0.0130990501642834,0.0123736859884528,0.00986369396719244,0.00823055515710402,0.0131923706719261,0.0123962860997118,0.0107415764912121,0.0126367005301954,0.0158178741994158,0.012038549663003,0.00886778829366297,0.0123919810449512,0.0136817667957245,0.0130966549040529,0.0110640856653066,0.0127614628406902,0.012608299562035,0.00894299766276807,0.0240724543617219,-0.00439661439548467,0.0035974957561874,0.0065441723094083,0.00500035910396701,0.00345959318863831,0.000746242965812938,0.015168598003875,0.0121719086469086,0.0157632751359429,0.0191525957885652,0.00528620003457836,0.0223028997403635,0.0035974957561874,0.00267387328819546,0.00236282776585262,-0.00176825768578681,-0.00254091763638042,0.00357485063527341,0.0130267623674512,0.00300494998603595,0.00869930774198269],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x2","yaxis":"y2","frame":null},{"x":[0.110866660868536,0.0928029890183044,0.0581140727994003,0.146277069252625,0.087260264134898,0.0872689206682623,0.123052775599171,0.156094684899559,0.0855813493691493,0.130120950289418,0.0870132343069741,0.163368036876821,0.165455826359961,0.0797711184028395,0.137750000168865,0.0779664949541123,0.0567823410164511,0.149881587879673,0.101355110797434,0.0761037847969366,0.155312605779862,0.0672703132036063,0.0458129006682327,0.017659404849954,0.0437891321099274,0.09158614318025,0.065362337243583,0.0883408414346571,0.0750616171177336,0.0284600244229524,0.0527754874951573,0.0207717506073785,0.070169828844368,0.017659404849954,0.0284581159692225,0.026831584954064,0.0214151423315874,0.052170956016005,0.0328551671771826,0.0868493426338641,0.0680717343434626,0.0942188468829623,0.00391829013688705,0.00557757463331985,0.00482190171604213,0.00541752499579817,0.00256358562498937,0.00230711417506202,0.00767062162795806,0.00765068999575802,0.00432805790981339,0.00193822032530355,0.0099816791232642,0.00852363741394602,0.00250349093212288,0.00868381250856043,0.00866033885432493,0.00767062162795806,0.00281536183116349,0.00885866882833419,0.00249687993339653,0.00307037347775641,0.00767062162795806,0.00477134891169329,0.00429327267632096,0.00521570624941115,0.00374669490243598,0.00562806136406546,0.00170807018821773,0.00513051136643905,0.00134180607572842,0.00572449383230844,0.00193570739706383,0.00355976126523305,0.00553819168435066,0.0019867213594974,0.00312479404032062,0.00129512147896493,0.00118090210172939,0.0045899134455113,0.00398837818435616,0.00440294500277438,0.00491213953562364,0.00460605188910967,0.0159776358656128,0.0220716421685179,0.0131213729970331,0.0205809922051907,0.0166441991439213,0.0236789837205353,0.0235830758068353,0.0155236967486322,0.0317873164248427,0.0316142661336798,0.0106924701707422,0.0320833074594182,0.0318565880472476,0.00645499941064787,0.0282477577754539,0.0191724320327857,0.0106305559627364,0.0093691537235443,0.00869491352881624,0.0326894257956187,0.0277260511871915,0.00231639923033666,0.00327202090151812,0.0121872827570897,0.00928227732887318,0.0140833112196698,0.0121872827570897,0.0107939337792945,0.0135549025911479,0.0117948873256368,0.0116349898547521,0.0139247584075235,0.00333918161614211,0.00923166049877855,0.0127801566151223,0.00746318404277668,0.00233172274767568,0.0114709326505943,0.0144827714897204,0.012048806245751,0.00447124657261866,0.00227611527422511,0.0436631189632086,0.0407873421293784,0.0543198127261534,0.0491531543262607,0.0543902074855701,0.0321900260173471,0.0327048407773876,0.0266065812417179,0.013445716318688,0.0489820150968024,0.0221232177225368,0.010808247057368,0.0443475789067392,0.0111495152362907,0.0271239049119044,0.0373381136512009,0.0179775855123845,0.0505036299521479,0.0118980524211623,0.0321139439725949,0.0143639419374461,0.0570335728944478,0.0575504179775128,0.0379965176606624,0.0551868737593793,0.0325811070501371,0.0491884169576055,0.0411324125345329,0.0454532065111112,0.0184064966018254,0.0227915068746222,0.0124960943076314,0.055640148153697,0.0357082364130386,0.0512239916966929,0.0140099948429592,0.0126727956195115,0.05583563193668,0.0460593926994559,0.0117932446898333,0.0415864660704656,0.0435803456221091,0.0070804949115375,0.00281340096542293,0.00707777887419858,0.00926545175992544,0.00116492612368857,0.011217889834179,0.0103741288198695,0.00916563831514117,0.01137106601996,0.00116492612368857,0.00817351699901792,0.00682221672833021,0.00117663521341349,0.00608729989520407,0.0107590370151721,0.0100620047422805,0.00578480936402226,0.00443373155663385,0.00322682424326248,0.00950787973430001,0.00653689405568625,0.024689147751181,0.0283029897867515,0.0286627976208893,0.0146378202285107,0.026279947162489,0.0077024310645335,0.0286627976208893,0.0293622289909152,0.00508915867558724,0.00542198302653285,0.0248558735583554,0.0186447990887171,0.00662143797133075,0.0197290717618358,0.00508915867558724,0.0198515436880877,0.0288993133823916,0.0294649865255628,0.00530420657404784,0.0286095421978493,0.0284292716465064,0.0127077826336787,0.00927854356364111,0.0123473728216815,0.00639254901878561,0.00655976348113996,0.00243538444720581,0.000943872085215847,0.00685026965500467,0.0106815953003161,0.000897560594467661,0.0133005509807378,0.00135078649484599,0.00705612958856905,0.00147316679114107,0.00494698914712832,0.00927497128584032,0.00410293162265463,0.0153054639075287,0.00114044613468278,0.0128924640712842,0.00391706912954815,0.0249943137779811,0.0339291349512256,0.0288712134796573,0.0240792102145123,0.0177317825139232,0.0107755412513244,0.00746444649532796,0.0288355701125115,0.0135687416264619,0.0179786533511002,0.0334217219447863,0.0221639696470972,0.032463976625983,0.00748847703837707,0.00820617219867625,0.0353657057856376,0.0185698746810816,0.0353657057856376,0.0305790281908874,0.0266558317333166,0.00693429118353583,0.00361154401001484,0.00232625043741896,0.00644826733591397,0.00548571980973767,0.00315125762965562,0.00552297331686002,0.00503463868008325,0.00137816328126339,0.00475466834128702,0.00402800569652906,0.00590505808966546,0.00302228459724529,0.00180182541902485,0.00565592233640066,0.00254906344827555,0.00105376927448164,0.00613942147848945,0.004207090929771,0.00524931063240197,0.00449722366673599,0.00652645111393524,0.0133654090817529,0.0208648950304109,0.0213294851691421,0.0265829252451115,0.0287304655282213,0.0298753467459046,0.010594030301855,0.00656935782239665,0.0248359915604897,0.00772482939892638,0.00672833486555191,0.026033115009818,0.00632554414592479,0.0167994512930314,0.00811010404726153,0.0274250025008385,0.00739893943761027,0.00614614236784916,0.0230627529249789,0.0140085166398947,0.0202778380366895,0.00103467955653158,0.00142990522162645,0.0025967968635956,0.0057409810996546,0.0049220751317655,0.000625034396430801,0.00827427861435504,0.00787100206609848,0.00699728271454225,0.00476588436834091,0.00630482892864237,0.00792989818889744,0.00827427861435504,0.00745820367312378,0.00967262804497349,0.00986375240201764,0.00103467955653158,0.00297130404702728,0.0025629848160349,0.00103467955653158,0.00199841990599914],"y":[21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"hoverinfo":"y","type":"box","fillcolor":"rgba(139,220,190,1)","marker":{"opacity":null,"outliercolor":"rgba(0,0,0,1)","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"},"size":5.66929133858268},"line":{"color":"rgba(51,51,51,1)","width":1.88976377952756},"name":"TRUE","legendgroup":"TRUE","showlegend":false,"xaxis":"x3","yaxis":"y3","frame":null}],"layout":{"margin":{"t":39.9103362391034,"r":7.97011207970112,"b":43.8356164383562,"l":184.109589041096},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"domain":[0,0.232413082973481],"automargin":true,"type":"linear","autorange":false,"range":[-0.0340569078234846,0.096825782398921],"tickmode":"array","ticktext":["-0.03","0.00","0.03","0.06","0.09"],"tickvals":[-0.03,0,0.03,0.06,0.09],"categoryorder":"array","categoryarray":["-0.03","0.00","0.03","0.06","0.09"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y","title":"","hoverformat":".2f"},"annotations":[{"text":"contribution","x":0.5,"y":0,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis","yshift":-23.9103362391034},{"text":"NNet","x":0.116206541486741,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"RF","x":0.5,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"XGB","x":0.883793458513259,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(26,26,26,1)","family":"","size":12.7521793275218},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x","title":"","hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.232413082973481,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.232413082973481,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.434253583693185,"x1":0.565746416306815,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.434253583693185,"x1":0.565746416306815,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.767586917026518,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,217,217,1)","line":{"color":"transparent","width":0.724555643609193,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.767586917026518,"x1":1,"y0":0,"y1":25.5043586550436,"yanchor":1,"ysizemode":"pixel"}],"xaxis2":{"type":"linear","autorange":false,"range":[-0.035353240345559,0.234393186354765],"tickmode":"array","ticktext":["0.00","0.05","0.10","0.15","0.20"],"tickvals":[0,0.05,0.1,0.15,0.2],"categoryorder":"array","categoryarray":["0.00","0.05","0.10","0.15","0.20"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.434253583693185,0.565746416306815],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y2","title":"","hoverformat":".2f"},"yaxis2":{"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x2","title":"","hoverformat":".2f"},"xaxis3":{"type":"linear","autorange":false,"range":[-0.0413210514121019,0.175302344349107],"tickmode":"array","ticktext":["0.00","0.05","0.10","0.15"],"tickvals":[0,0.05,0.1,0.15],"categoryorder":"array","categoryarray":["0.00","0.05","0.10","0.15"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0.767586917026518,1],"gridcolor":"rgba(255,255,255,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"y3","title":"","hoverformat":".2f"},"yaxis3":{"type":"linear","autorange":false,"range":[0.4,21.6],"tickmode":"array","ticktext":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"categoryorder":"array","categoryarray":["RHEP24 = N","RASP3 = N","RDEF8 = C","RSLEEP = N","RVISINF = N","RATRIAL = N","STYPE = PACS","RDEF2 = Y","treatment = yes_asp_low_hep","RDEF1 = Y","RDELAY = 8","RCT = Y","RDEF7 = C","RDEF4 = C","SEX = F","RSBP = 130","RDEF3 = Y","RDEF5 = C","RDEF6 = C","RCONSC = D","AGE = 94"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.98505603985056,"tickwidth":0.724555643609193,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(190,190,190,1)","gridwidth":0.724555643609193,"zeroline":false,"anchor":"x3","title":"","hoverformat":".2f"},"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":2.06156048675734,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"488c2addc88":{"x":{},"y":{},"fill":{},"type":"bar"},"488c28bf67c6":{"x":{},"y":{},"fill":{}}},"cur_data":"488c2addc88","visdat":{"488c2addc88":["function (y) ","x"],"488c28bf67c6":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>export(local_profile_old2, here(&quot;output&quot;, &quot;rds-files&quot;, &quot;local-profile-old.rds&quot;))</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.0.3 (2020-10-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
 [1] DALEXtra_2.1.1     DALEX_2.3.0.9000   yardstick_0.0.9    workflowsets_0.1.0
 [5] workflows_0.2.4    tune_0.1.6         rsample_0.1.1      recipes_0.1.17    
 [9] parsnip_0.1.7      modeldata_0.1.1    infer_1.0.0        dials_0.0.10      
[13] scales_1.1.1       broom_0.7.10       tidymodels_0.1.4   patchwork_1.1.1   
[17] plotly_4.10.0      ggpubr_0.4.0       rio_0.5.29         forcats_0.5.1     
[21] stringr_1.4.0      dplyr_1.0.7        purrr_0.3.4        readr_2.1.1       
[25] tidyr_1.1.4        tibble_3.1.6       ggplot2_3.3.5      tidyverse_1.3.1   
[29] here_1.0.1         doFuture_0.12.0    future_1.23.0      foreach_1.5.1     
[33] tictoc_1.0.1       conflicted_1.1.0   workflowr_1.7.0   

loaded via a namespace (and not attached):
  [1] readxl_1.3.1       backports_1.4.1    tidytext_0.3.2    
  [4] plyr_1.8.6         lazyeval_0.2.2     splines_4.0.3     
  [7] crosstalk_1.2.0    listenv_0.8.0      SnowballC_0.7.0   
 [10] digest_0.6.29      htmltools_0.5.2    fansi_0.5.0       
 [13] magrittr_2.0.1     memoise_2.0.1      tzdb_0.2.0        
 [16] openxlsx_4.2.5     globals_0.14.0     modelr_0.1.8      
 [19] gower_0.2.2        hardhat_0.1.6      colorspace_2.0-2  
 [22] rappdirs_0.3.3     rvest_1.0.2        haven_2.4.3       
 [25] xfun_0.29          callr_3.7.0        crayon_1.4.2      
 [28] jsonlite_1.7.2     survival_3.2-13    iterators_1.0.13  
 [31] glue_1.6.0         gtable_0.3.0       ipred_0.9-12      
 [34] car_3.0-12         future.apply_1.8.1 abind_1.4-5       
 [37] DBI_1.1.2          rstatix_0.7.0      Rcpp_1.0.7        
 [40] viridisLite_0.4.0  reticulate_1.22    GPfit_1.0-8       
 [43] foreign_0.8-81     lava_1.6.10        prodlim_2019.11.13
 [46] htmlwidgets_1.5.4  httr_1.4.2         ellipsis_0.3.2    
 [49] farver_2.1.0       pkgconfig_2.0.3    nnet_7.3-16       
 [52] sass_0.4.0         dbplyr_2.1.1       utf8_1.2.2        
 [55] labeling_0.4.2     tidyselect_1.1.1   rlang_0.4.12      
 [58] DiceDesign_1.9     later_1.3.0        munsell_0.5.0     
 [61] cellranger_1.1.0   tools_4.0.3        cachem_1.0.6      
 [64] xgboost_1.5.0.2    cli_3.1.0          generics_0.1.1    
 [67] ranger_0.13.1      evaluate_0.14      fastmap_1.1.0     
 [70] yaml_2.2.1         processx_3.5.2     knitr_1.37        
 [73] fs_1.5.2           zip_2.2.0          whisker_0.4       
 [76] xml2_1.3.3         tokenizers_0.2.1   compiler_4.0.3    
 [79] rstudioapi_0.13    png_0.1-7          curl_4.3.2        
 [82] ggsignif_0.6.3     reprex_2.0.1       lhs_1.1.3         
 [85] bslib_0.3.1        stringi_1.7.6      iBreakDown_2.0.1  
 [88] highr_0.9          ps_1.6.0           lattice_0.20-45   
 [91] Matrix_1.4-0       vctrs_0.3.8        pillar_1.6.4      
 [94] lifecycle_1.0.1    furrr_0.2.3        jquerylib_0.1.4   
 [97] data.table_1.14.2  httpuv_1.6.4       R6_2.5.1          
[100] promises_1.2.0.1   renv_0.14.0        janeaustenr_0.1.5 
[103] parallelly_1.30.0  codetools_0.2-18   MASS_7.3-54       
[106] assertthat_0.2.1   rprojroot_2.0.2    withr_2.4.3       
[109] parallel_4.0.3     hms_1.1.1          grid_4.0.3        
[112] rpart_4.1-15       timeDate_3043.102  class_7.3-19      
[115] rmarkdown_2.11     ingredients_2.2.0  carData_3.0-4     
[118] git2r_0.29.0       pROC_1.18.0        getPass_0.2-2     
[121] lubridate_1.8.0   </code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
